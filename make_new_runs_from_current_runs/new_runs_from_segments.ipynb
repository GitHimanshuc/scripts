{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import re\n",
    "import subprocess\n",
    "import sys\n",
    "import stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_home = \"/home/hchaudha/spec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_regex_in_file(file_path, regex_pattern):\n",
    "    # Read the content of the file\n",
    "    with open(file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Try to compile the regex pattern\n",
    "    try:\n",
    "        pattern = re.compile(regex_pattern)\n",
    "    except re.error:\n",
    "        print(\"Invalid regex pattern.\")\n",
    "        return False\n",
    "\n",
    "    # Search for matches\n",
    "    if pattern.search(content):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def replace_current_file(file_path, original_str, replaced_str,**kwargs):\n",
    "    matched_strings = []\n",
    "\n",
    "    def callback(match):\n",
    "        matched_strings.append(match.group(0))  # Store the matched string\n",
    "        return replaced_str  # Replace with the new string\n",
    "\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = file.read()\n",
    "\n",
    "    # Use re.sub with callback to replace and collect matched strings\n",
    "    data, replaced_status = re.subn(original_str, callback, data, **kwargs)   \n",
    "\n",
    "    if replaced_status != 0:\n",
    "        print(f\"\"\"\n",
    "Replaced in File: {file_path}\n",
    "Original String: {original_str}\n",
    "Replaced String: {replaced_str}\n",
    "Matched Strings: {matched_strings}\n",
    "\"\"\")\n",
    "    else:\n",
    "        raise Exception(f\"\"\"\n",
    "!!!!FAILED TO REPLACE!!!!\n",
    "File path: {file_path}\n",
    "Original String: {original_str}\n",
    "Replaced String: {replaced_str}\n",
    "\"\"\")\n",
    "\n",
    "    with open(file_path, 'w') as file:\n",
    "        file.write(data)\n",
    "\n",
    "def is_continuous(lst:list):\n",
    "    # my_list = [\"AZ\", \"BA\", \"BB\", \"BC\"]\n",
    "    # print(is_continuous(my_list))  # Should return True\n",
    "\n",
    "    # my_list = [\"AA\", \"AB\", \"AC\", \"AD\"]\n",
    "    # print(is_continuous(my_list))  # Should return True\n",
    "\n",
    "    # my_list = [\"AA\", \"AB\", \"AD\", \"AC\"]\n",
    "    # print(is_continuous(my_list))  # Should return False\n",
    "\n",
    "    for i in range(len(lst) - 1):\n",
    "        current = lst[i]\n",
    "        next_elem = lst[i + 1]\n",
    "\n",
    "        # Determine the next expected element\n",
    "        if current[1] == 'Z':\n",
    "            # If the second character is Z, the next expected should start the next sequence\n",
    "            expected_next_first = chr(ord(current[0]) + 1)\n",
    "            expected_next_second = 'A'\n",
    "        else:\n",
    "            # Otherwise, continue by incrementing the second character\n",
    "            expected_next_first = current[0]\n",
    "            expected_next_second = chr(ord(current[1]) + 1)\n",
    "\n",
    "        expected_next_elem = expected_next_first + expected_next_second\n",
    "\n",
    "        # If the next element is not the expected one, return False\n",
    "        if next_elem != expected_next_elem:\n",
    "            return False\n",
    "\n",
    "    return True  # All elements are continuous\n",
    "\n",
    "def verify_data_dict(data_dict:dict):\n",
    "  for new_folder_name in data_dict.keys():\n",
    "    data = data_dict[new_folder_name]\n",
    "    if not data['new_run_parent'].exists():\n",
    "      raise Exception(f\"\"\"{data['new_run_parent']=} does not exist!\"\"\")\n",
    "    if not data['old_Ev_path'].exists():\n",
    "      raise Exception(f\"\"\"{data['old_Ev_path']=} does not exist!\"\"\")\n",
    "    \n",
    "    if data[\"Ev_is_present\"]:\n",
    "      if data[\"copy_ID\"]:\n",
    "        raise Exception(\"When Ev_is_present is set to true copy_ID and copy_bin should be false.\")\n",
    "      if data[\"copy_bin\"]:\n",
    "        raise Exception(\"When Ev_is_present is set to true copy_ID and copy_bin should be false.\")\n",
    "\n",
    "      Ev_parent_folder_path = data['new_run_parent']/new_folder_name\n",
    "      if not Ev_parent_folder_path.exists():\n",
    "        raise Exception(f\"Ev_is_present is set to true but {Ev_parent_folder_path=} does not exist.\")\n",
    "\n",
    "      Ev_folder_path = Ev_parent_folder_path/\"Ev\"\n",
    "      if not Ev_folder_path.exists():\n",
    "        raise Exception(f\"Ev_is_present is set to true but {Ev_folder_path=} does not exist.\")\n",
    "\n",
    "    if data[\"copy_ID\"]:\n",
    "      old_ID_path = data['old_Ev_path'].parent/\"ID\"\n",
    "      if not old_ID_path.exists():\n",
    "        raise Exception(f\"ID folder marked for copy but {old_ID_path=} does not exist.\")    \n",
    "    \n",
    "    if data[\"copy_bin\"]:\n",
    "      old_bin_path = data['old_Ev_path']/\"bin\"\n",
    "      if not old_bin_path.exists():\n",
    "        raise Exception(f\"bin folder marked for copy but {old_bin_path=} does not exist.\")    \n",
    "      \n",
    "    levs_to_copy = data[\"levs_to_copy\"]\n",
    "    for lev_dict in levs_to_copy:\n",
    "      segments_to_copy = lev_dict[\"segments_to_copy\"]\n",
    "\n",
    "      # Check that the segments are continuous and sorted\n",
    "      if not is_continuous(segments_to_copy):\n",
    "        raise Exception(f\"{segments_to_copy=} is not a continuous list!\")\n",
    "\n",
    "      if lev_dict[\"this_lev_is_continuation\"]:\n",
    "        # Make sure that the new lev name and the old lev name are the same\n",
    "        if lev_dict[\"old_Lev_name\"] != lev_dict[\"new_Lev_name\"]:\n",
    "          raise Exception(f'{lev_dict[\"this_lev_is_continuation\"]=} is set to true but the old lev name {lev_dict[\"old_Lev_name\"]=} is different from the new one {lev_dict[\"new_Lev_name\"]=}.')\n",
    "\n",
    "        if (\"new_Lev_for_AMR_tolerance\" in lev_dict) or (\"new_Lev_for_GrDomain_and_AmrDriver\" in lev_dict):\n",
    "          raise Exception(f'{lev_dict[\"this_lev_is_continuation\"]=} is set to true but keys new_Lev_for_AMR_tolerance or new_Lev_for_GrDomain_and_AmrDriver are defined!')\n",
    "\n",
    "        if (\"AH_factor\" in lev_dict):\n",
    "          raise Exception(f'{lev_dict[\"this_lev_is_continuation\"]=} is set to true but key AH_factor is defined!')\n",
    "\n",
    "      else:\n",
    "        # Check the values of new new_Lev_for_AMR_tolerance and new_Lev_for_GrDomain_and_AmrDriver\n",
    "        new_Lev_for_AMR_tolerance = lev_dict[\"new_Lev_for_AMR_tolerance\"]\n",
    "        new_Lev_for_GrDomain_and_AmrDriver = lev_dict[\"new_Lev_for_GrDomain_and_AmrDriver\"]\n",
    "        # TODO deal with 45 55 etc as 4.5  5.5\n",
    "        if (isinstance(new_Lev_for_AMR_tolerance,int)) or (isinstance(new_Lev_for_AMR_tolerance,float)):\n",
    "          pass\n",
    "        else:\n",
    "          raise Exception(f\"{new_Lev_for_AMR_tolerance=} should be a float or an int.\")\n",
    "\n",
    "        if not isinstance(new_Lev_for_GrDomain_and_AmrDriver,int):\n",
    "          raise Exception(f\"{new_Lev_for_GrDomain_and_AmrDriver=} should be an int.\")\n",
    "        # If this_lev_is_continuation is False and levs have same name then print a warning\n",
    "        if lev_dict[\"old_Lev_name\"] == lev_dict[\"new_Lev_name\"]:\n",
    "          if data[\"new_run_parent\"]/new_folder_name == data[\"old_Ev_path\"].parent:\n",
    "            print(f'\\nWARNING!!\\n {lev_dict[\"this_lev_is_continuation\"]=} is set to false but the new lev name {lev_dict[\"old_Lev_name\"]=} is same as the old one {lev_dict[\"new_Lev_name\"]=}.')\n",
    "\n",
    "\n",
    "      for folder in segments_to_copy:\n",
    "        # Check that the levs we want to copy exist\n",
    "        old_folder_path = data['old_Ev_path']/(lev_dict[\"old_Lev_name\"]+\"_\"+folder)\n",
    "        if not old_folder_path.exists():\n",
    "          raise Exception(f\"{old_folder_path=} does not exist\")\n",
    "\n",
    "        # Check that the files being replace exist\n",
    "        if folder == segments_to_copy[-1]:\n",
    "          files_to_change_in_the_new_lev = lev_dict[\"files_to_change_in_the_new_lev\"]\n",
    "          for file_name in files_to_change_in_the_new_lev:\n",
    "            file_path = old_folder_path/file_name\n",
    "            if not file_path.exists():\n",
    "              raise Exception(f\"{file_path=} is supposed to be change in the new lev but it does not exist in the old folders lev.\")\n",
    "\n",
    "            # Check that the lists original_str and replaced_str have the same length\n",
    "            original_str = files_to_change_in_the_new_lev[file_name][\"original_str\"]\n",
    "            replaced_str = files_to_change_in_the_new_lev[file_name][\"replaced_str\"]\n",
    "            if len(original_str) != len(replaced_str):\n",
    "              raise Exception(f\"{original_str=} and {replaced_str=} have different lengths!\")\n",
    "            for string_to_be_replaced in original_str:\n",
    "              if not check_regex_in_file(file_path,string_to_be_replaced):\n",
    "                raise Exception(f\"{string_to_be_replaced=} not found in the file {file_path=}!\")\n",
    "\n",
    "def MakeNextSegment(EV_folder_path:Path, previous_segment_path:Path):\n",
    "  command = f\"cd {EV_folder_path} && {spec_home}/Support/bin/MakeNextSegment -d {previous_segment_path} -t . -S\"\n",
    "  status = subprocess.run(command, capture_output=True, shell=True, text=True)\n",
    "  if status.returncode == 0:\n",
    "    print(f\"Succesfully ran MakeNextSegment in {EV_folder_path}: \\n {status.stdout}\")\n",
    "  else:\n",
    "    sys.exit(\n",
    "        f\"MakeNextSegment failed in {EV_folder_path} with error: \\n {status.stdout} \\n {status.stderr}\")\n",
    "    \n",
    "def get_next_segment(lst):\n",
    "    # my_list = [\"AA\", \"AB\", \"AC\", \"AD\", \"BA\"]\n",
    "    # print(get_next_segment(my_list))  # Should return \"BB\"\n",
    "\n",
    "    # my_list = [\"AZ\"]\n",
    "    # print(get_next_segment(my_list))  # Should return \"BA\"\n",
    "\n",
    "    # my_list = []\n",
    "    # print(get_next_segment(my_list))  # Should return \"AA\"\n",
    "\n",
    "    if not lst:\n",
    "        return \"AA\"  # Return \"AA\" if the list is empty\n",
    "\n",
    "    # Sort the list to ensure that elements are in the correct order\n",
    "    lst.sort()\n",
    "\n",
    "    # Retrieve the last element from the sorted list\n",
    "    last_elem = lst[-1]\n",
    "\n",
    "    # Determine the next element\n",
    "    if last_elem[1] == 'Z':\n",
    "        # If the second character is 'Z', increment the first character and set the second to 'A'\n",
    "        next_first = chr(ord(last_elem[0]) + 1)\n",
    "        next_second = 'A'\n",
    "    else:\n",
    "        # Otherwise, simply increment the second character\n",
    "        next_first = last_elem[0]\n",
    "        next_second = chr(ord(last_elem[1]) + 1)\n",
    "\n",
    "    next_elem = next_first + next_second\n",
    "    return next_elem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_or_copy(source_path: Path, destination_path: Path, link_or_copy_folders: str):\n",
    "    if link_or_copy_folders == \"link\":\n",
    "        # Create a symbolic link\n",
    "        if not destination_path.exists():\n",
    "            destination_path.symlink_to(source_path)\n",
    "            print(f\"Created a symbolic link from {source_path} to {destination_path}\")\n",
    "        else:\n",
    "            print(f\"Destination {destination_path} already exists. Cannot create a link.\")\n",
    "    \n",
    "    elif link_or_copy_folders == \"copy\":\n",
    "        # Copy the directory using shutil when using pathlib\n",
    "        if not destination_path.exists():\n",
    "            shutil.copytree(source_path, destination_path)\n",
    "            print(f\"Copied {source_path} to {destination_path}\")\n",
    "            # When copying add write permission as well\n",
    "            add_write_permission(destination_path)\n",
    "        else:\n",
    "            print(f\"Destination {destination_path} already exists. Cannot copy.\")\n",
    "    \n",
    "    else:\n",
    "        print(\"Invalid option. Please use 'link' or 'copy'.\")\n",
    "\n",
    "def add_write_permission(target_dir:Path):\n",
    "  if not target_dir.exists():\n",
    "    raise Exception(f\"Trying to change the permissions of the folder {target_dir} which does not exist.\")\n",
    "  if target_dir.is_symlink():\n",
    "    raise Exception(f\"Trying to get write permission on a symlink folder {target_dir}. This should not be happening.\")\n",
    "  else:\n",
    "    command = f\"chmod u+w -R {target_dir.resolve(strict=True)}\"\n",
    "    status = subprocess.run(command, capture_output=True, shell=True, text=True)\n",
    "    if status.returncode == 0:\n",
    "      print(f\"Succesfully added execute permission to {target_dir}\")\n",
    "    else:\n",
    "      sys.exit(\n",
    "          f\"{command}\\nfailed with error: \\n {status.stderr}\")\n",
    "\n",
    "def copy_all_files(src:Path, dst:Path, exclude_files:list[str]):\n",
    "  if not src.exists():\n",
    "    raise Exception(f\"{src=} does not exist\")\n",
    "  if not dst.exists():\n",
    "    raise Exception(f\"{dst=} does not exist\")\n",
    "\n",
    "  # Iterate through the source directory\n",
    "  for path in src.iterdir():\n",
    "    if path.is_dir():\n",
    "      # If it's a directory, do not copy\n",
    "      continue\n",
    "    else:\n",
    "      excluded_file = False\n",
    "      for excluded in exclude_files:\n",
    "        if excluded in str(path):\n",
    "          excluded_file = True\n",
    "          continue\n",
    "      # If it's not an excluded file, copy it\n",
    "      if not excluded_file:\n",
    "        shutil.copy2(path, dst)\n",
    "\n",
    "def change_AmrTolerances(segement_path:Path, new_lev:int, AH_factor:float=1):\n",
    "  file_path = segement_path/\"AmrTolerances.input\"\n",
    "\n",
    "  TruncationErrorMax = 0.000216536 * 4**(-new_lev)\n",
    "  replace_current_file(file_path,r\"TruncationErrorMax=.*;\",f'TruncationErrorMax={TruncationErrorMax};')\n",
    "\n",
    "  ProjectedConstraintsMax = 0.216536 * 4**(-new_lev)\n",
    "  replace_current_file(file_path,r\"ProjectedConstraintsMax=.*;\",f'ProjectedConstraintsMax={ProjectedConstraintsMax};')\n",
    "  TruncationErrorMaxA = TruncationErrorMax*1.e-4\n",
    "  replace_current_file(file_path,r\"TruncationErrorMaxA=.*;\",f'TruncationErrorMaxA={TruncationErrorMaxA};')\n",
    "  TruncationErrorMaxB = TruncationErrorMax*1.e-4\n",
    "  replace_current_file(file_path,r\"TruncationErrorMaxB=.*;\",f'TruncationErrorMaxB={TruncationErrorMaxB};')\n",
    "\n",
    "  AhMaxRes = TruncationErrorMax / AH_factor\n",
    "  replace_current_file(file_path,r\"AhMaxRes=.*;\",f'AhMaxRes={AhMaxRes};')\n",
    "  AhMinRes = AhMaxRes / 10.0\n",
    "  replace_current_file(file_path,r\"AhMinRes=.*;\",f'AhMinRes={AhMinRes};')\n",
    "\n",
    "  AhMaxTrunc = TruncationErrorMax / AH_factor\n",
    "  replace_current_file(file_path,r\"AhMaxTrunc=.*;\",f'AhMaxTrunc={AhMaxTrunc};')\n",
    "  AhMinTrunc = AhMaxTrunc / 100.0\n",
    "  replace_current_file(file_path,r\"AhMinTrunc=.*;\",f'AhMinTrunc={AhMinTrunc};')\n",
    "\n",
    "def change_GrDomain_and_AmrDriver_Level(segement_path:Path, new_lev:int):\n",
    "  AmrDriver_path = segement_path/\"AmrDriver.input\"\n",
    "  replace_current_file(AmrDriver_path,r\"Level\\s? =\\s? \\d;\",f\"Level = {new_lev};\")\n",
    "\n",
    "  GrDomain_path = segement_path/\"GrDomain.input\"\n",
    "  # There is also a WarningLevel = 0; That should not be changed\n",
    "  replace_current_file(GrDomain_path,r\"Level\\s?=\\s? \\d;\",f\"Level = {new_lev};\")\n",
    "\n",
    "def create_new_folder(folder_name:str,data_dict:dict):\n",
    "  folder_dict = data_dict[folder_name]\n",
    "  new_run_parent:Path = folder_dict[\"new_run_parent\"]\n",
    "  new_run_path = new_run_parent/folder_name\n",
    "  old_Ev_path:Path = folder_dict[\"old_Ev_path\"]\n",
    "  link_or_copy_folders = folder_dict[\"link_or_copy_folders\"]\n",
    "  copy_ID = folder_dict[\"copy_ID\"]\n",
    "  old_ID_path = old_Ev_path/\"ID\"\n",
    "  copy_bin = folder_dict[\"copy_bin\"]\n",
    "  old_bin_path = old_Ev_path/\"bin\"\n",
    "\n",
    "  levs_to_copy = folder_dict[\"levs_to_copy\"]\n",
    "  \n",
    "  new_run_path.mkdir(exist_ok=True)\n",
    "  new_Ev_path = new_run_path/\"Ev\"\n",
    "  new_ID_path = new_run_path/\"ID\"\n",
    "  new_bin_path = new_run_path/\"Ev/bin\"\n",
    "  new_Ev_path.mkdir(exist_ok=True)\n",
    "  if copy_ID:\n",
    "    link_or_copy(old_ID_path,new_ID_path,link_or_copy_folders)\n",
    "  if copy_bin:\n",
    "    link_or_copy(old_bin_path,new_bin_path,link_or_copy_folders)\n",
    "\n",
    "  levs_to_copy = folder_dict[\"levs_to_copy\"]\n",
    "  for lev_dict in levs_to_copy:\n",
    "    segments_to_copy = lev_dict[\"segments_to_copy\"]\n",
    "\n",
    "    for segment in segments_to_copy:\n",
    "      old_segment_path = folder_dict['old_Ev_path']/(lev_dict[\"old_Lev_name\"]+\"_\"+segment)\n",
    "      new_segment_path = new_Ev_path/(lev_dict[\"new_Lev_name\"]+\"_\"+segment)\n",
    "      link_or_copy(old_segment_path,new_segment_path,link_or_copy_folders)\n",
    "\n",
    "    # Get the last segment copied or linked\n",
    "    last_segment_path = new_Ev_path/(lev_dict[\"new_Lev_name\"]+\"_\"+segments_to_copy[-1])\n",
    "    last_segment_bin_path = new_Ev_path/(lev_dict[\"new_Lev_name\"]+\"_\"+segments_to_copy[-1])/\"bin\"\n",
    "\n",
    "    # Make the next segment\n",
    "    new_segment_path = new_Ev_path/(lev_dict[\"new_Lev_name\"]+\"_\"+get_next_segment(segments_to_copy))\n",
    "    new_segment_path.mkdir()\n",
    "    # Copy the bin folder\n",
    "    link_or_copy(last_segment_bin_path,new_segment_path/\"bin\",\"copy\")\n",
    "    copy_all_files(last_segment_path, new_segment_path, [\"SpEC.\"])\n",
    "\n",
    "    # Add user write permission\n",
    "    add_write_permission(new_segment_path)\n",
    "\n",
    "    # Change the Restart option in the Evolution.input\n",
    "    last_segment_checkpoint_folder_path = last_segment_path/\"Run/Checkpoints/\"\n",
    "    if not last_segment_checkpoint_folder_path.exists():\n",
    "      raise Exception(f\"{last_segment_checkpoint_folder_path=} does not exist!\")\n",
    "\n",
    "    if lev_dict[\"this_lev_is_continuation\"]:\n",
    "      # For continuation runs just change the FromLastStep\n",
    "      check_regex_in_file(new_segment_path/\"Evolution.input\",r\"Restart\\s*=\\s*FromLastStep\\(.*\\);\")\n",
    "      replace_current_file(new_segment_path/\"Evolution.input\",r\"Restart\\s*=\\s*FromLastStep\\(.*\\);\",f\"Restart    = FromLastStep(FilenamePrefix={last_segment_checkpoint_folder_path}/;);\")\n",
    "    else:\n",
    "      check_regex_in_file(new_segment_path/\"Evolution.input\",r\"Restart\\s*=\\s*FromLastStep\\(.*\\);\")\n",
    "      replace_current_file(new_segment_path/\"Evolution.input\",r\"Restart\\s*=\\s*FromLastStep\\(.*\\);\",f\"Restart    = FromLastStep(FilenamePrefix={last_segment_checkpoint_folder_path}/;GrGlobalVarsCheckpoint = Interpolated(FlagAllSubdomainsAsChanged = yes; ResetFilterFunctionsForAMR = yes; StartAmrWithMinimumExtents = yes; ResolutionChanger=Spectral; Interpolator =ParallelAdaptive(TopologicalInterpolator=CardinalInterpolator;); DomainFile=GrDomain.input; DomainDir={last_segment_path}/Run/););\")\n",
    "\n",
    "      # Change the Submit.sh run name\n",
    "      replace_current_file(new_segment_path/\"MakeSubmit.input\",r\"Jobname.*\",f'Jobname = {folder_name}.{lev_dict[\"new_Lev_name\"]}')\n",
    "      replace_current_file(new_segment_path/\"Submit.sh\",r\"#SBATCH -J.*\",f'#SBATCH -J {folder_name}.{lev_dict[\"new_Lev_name\"]}')\n",
    "\n",
    "      change_AmrTolerances(new_segment_path, lev_dict['new_Lev_for_AMR_tolerance'], lev_dict['AH_factor'])\n",
    "      change_GrDomain_and_AmrDriver_Level(new_segment_path, lev_dict['new_Lev_for_GrDomain_and_AmrDriver'])\n",
    "\n",
    "    # Replace the text in files\n",
    "    files_to_change_in_the_new_lev = lev_dict[\"files_to_change_in_the_new_lev\"]\n",
    "    for file_name in files_to_change_in_the_new_lev:\n",
    "      file_path = new_segment_path/file_name\n",
    "      if not file_path.exists():\n",
    "        raise Exception(f\"{file_path=} is supposed to be change in the new segment but it does not exist.\")\n",
    "\n",
    "      original_str_list = files_to_change_in_the_new_lev[file_name][\"original_str\"]\n",
    "      replaced_str_list = files_to_change_in_the_new_lev[file_name][\"replaced_str\"]\n",
    "\n",
    "      for original_str, replaced_str in zip(original_str_list,replaced_str_list):\n",
    "        replace_current_file(file_path, original_str, replaced_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ev is always made, the idea is to make things simple and consistent\n",
    "data_dict={\n",
    "  \"6_set2_test\":{\n",
    "    \"spec_home\": Path(\"/home/hchaudha/spec\"),\n",
    "    \"new_run_parent\":Path(\"/groups/sxs/hchaudha/spec_runs/\"),\n",
    "    \"old_Ev_path\":Path(\"/groups/sxs/hchaudha/spec_runs/6_set2_test/Ev\"),\n",
    "    \"link_or_copy_folders\":\"link\",\n",
    "    \"Ev_is_present\":True,\n",
    "    \"copy_ID\":False,\n",
    "    \"copy_bin\":False,\n",
    "    \"levs_to_copy\":[\n",
    "      {\n",
    "        \"old_Lev_name\":\"Lev3\",\n",
    "        \"new_Lev_name\":\"Lev45\",\n",
    "        \"this_lev_is_continuation\": False,\n",
    "        \"new_Lev_for_AMR_tolerance\":4.5,\n",
    "        \"new_Lev_for_GrDomain_and_AmrDriver\":5,\n",
    "        \"AH_factor\":1.0,\n",
    "        \"segments_to_copy\":[\"AA\"],\n",
    "        \"files_to_change_in_the_new_lev\":{\n",
    "          \"Evolution.input\":{\n",
    "          \"original_str\": [\n",
    "            r\"FinalTime = \\d*;\",\n",
    "            r\"Tolerance =\\s*([^;]*);\"\n",
    "          ],\n",
    "          \"replaced_str\": [\n",
    "            \"FinalTime = 4000;\",\n",
    "            f\"Tolerance = { 0.000216536/2000 * 4**(-4.5)};\"\n",
    "          ]\n",
    "          },\n",
    "          \"Submit.sh\":{\n",
    "            \"original_str\": [\n",
    "              \"#SBATCH --constraint=skylake\"\n",
    "            ],\n",
    "            \"replaced_str\": [\n",
    "              \"#SBATCH --constraint=skylake\\n#SBATCH --reservation=sxs_standing\"\n",
    "            ]\n",
    "          }\n",
    "        },\n",
    "      },\n",
    "      {\n",
    "        \"old_Lev_name\":\"Lev3\",\n",
    "        \"new_Lev_name\":\"Lev3\",\n",
    "        \"this_lev_is_continuation\": True,\n",
    "        \"AH_factor\":1.0,\n",
    "        \"segments_to_copy\":[\"AA\"],\n",
    "        \"files_to_change_in_the_new_lev\":{\n",
    "          \"Evolution.input\":{\n",
    "          \"original_str\": [\n",
    "            r\"FinalTime = \\d*;\",\n",
    "            r\"Tolerance =\\s*([^;]*);\"\n",
    "          ],\n",
    "          \"replaced_str\": [\n",
    "            \"FinalTime = 4000;\",\n",
    "            f\"Tolerance = { 0.000216536/2000 * 4**(-3)};\"\n",
    "          ]\n",
    "          },\n",
    "          \"Submit.sh\":{\n",
    "            \"original_str\": [\n",
    "              \"#SBATCH --constraint=skylake\"\n",
    "            ],\n",
    "            \"replaced_str\": [\n",
    "              \"#SBATCH --constraint=skylake\\n#SBATCH --reservation=sxs_standing\"\n",
    "            ]\n",
    "          }\n",
    "        },\n",
    "      },\n",
    "      {\n",
    "        \"old_Lev_name\":\"Lev3\",\n",
    "        \"new_Lev_name\":\"Lev55\",\n",
    "        \"this_lev_is_continuation\": False,\n",
    "        \"new_Lev_for_AMR_tolerance\":5.5,\n",
    "        \"new_Lev_for_GrDomain_and_AmrDriver\":6,\n",
    "        \"AH_factor\":1.0,\n",
    "        \"segments_to_copy\":[\"AA\"],\n",
    "        \"files_to_change_in_the_new_lev\":{\n",
    "          \"Evolution.input\":{\n",
    "          \"original_str\": [\n",
    "            r\"FinalTime = \\d*;\",\n",
    "            r\"Tolerance =\\s*([^;]*);\"\n",
    "          ],\n",
    "          \"replaced_str\": [\n",
    "            \"FinalTime = 4000;\",\n",
    "            f\"Tolerance = { 0.000216536/2000 * 4**(-5.5)};\"\n",
    "          ]\n",
    "          },\n",
    "          \"Submit.sh\":{\n",
    "            \"original_str\": [\n",
    "              \"#SBATCH --constraint=skylake\"\n",
    "            ],\n",
    "            \"replaced_str\": [\n",
    "              \"#SBATCH --constraint=skylake\\n#SBATCH --reservation=sxs_standing\"\n",
    "            ]\n",
    "          }\n",
    "        },\n",
    "      }\n",
    "    ],\n",
    "  }\n",
    "}\n",
    "# Ev is always made, the idea is to make things simple and consistent\n",
    "data_dict={\n",
    "  \"L01_main_test\":{\n",
    "    \"spec_home\": Path(\"/home/hchaudha/spec\"),\n",
    "    \"new_run_parent\":Path(\"/groups/sxs/hchaudha/spec_runs/del\"),\n",
    "    \"old_Ev_path\":Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev\"),\n",
    "    \"link_or_copy_folders\":\"link\",\n",
    "    \"Ev_is_present\":False,\n",
    "    \"copy_ID\":False,\n",
    "    \"copy_bin\":False,\n",
    "    \"levs_to_copy\":[\n",
    "      {\n",
    "        \"old_Lev_name\":\"Lev2\",\n",
    "        \"new_Lev_name\":\"Lev45\",\n",
    "        \"this_lev_is_continuation\": False,\n",
    "        \"new_Lev_for_AMR_tolerance\":4.5,\n",
    "        \"new_Lev_for_GrDomain_and_AmrDriver\":5,\n",
    "        \"AH_factor\":1.0,\n",
    "        \"segments_to_copy\":[\"AA\"],\n",
    "        \"files_to_change_in_the_new_lev\":{\n",
    "          \"Evolution.input\":{\n",
    "          \"original_str\": [\n",
    "            r\"FinalTime = \\d*;\",\n",
    "            r\"Tolerance =\\s*([^;]*);\"\n",
    "          ],\n",
    "          \"replaced_str\": [\n",
    "            \"FinalTime = 4000;\",\n",
    "            f\"Tolerance = { 0.000216536/2000 * 4**(-4.5)};\"\n",
    "          ]\n",
    "          },\n",
    "          \"Submit.sh\":{\n",
    "            \"original_str\": [\n",
    "              \"#SBATCH --constraint=skylake\"\n",
    "            ],\n",
    "            \"replaced_str\": [\n",
    "              \"#SBATCH --constraint=skylake\\n#SBATCH --reservation=sxs_standing\"\n",
    "            ]\n",
    "          }\n",
    "        },\n",
    "      },\n",
    "      {\n",
    "        \"old_Lev_name\":\"Lev2\",\n",
    "        \"new_Lev_name\":\"Lev3\",\n",
    "        \"this_lev_is_continuation\": False,\n",
    "        \"new_Lev_for_AMR_tolerance\":3,\n",
    "        \"new_Lev_for_GrDomain_and_AmrDriver\":3,\n",
    "        \"AH_factor\":1.0,\n",
    "        \"segments_to_copy\":[\"AA\"],\n",
    "        \"files_to_change_in_the_new_lev\":{\n",
    "          \"Evolution.input\":{\n",
    "          \"original_str\": [\n",
    "            r\"FinalTime = \\d*;\",\n",
    "            r\"Tolerance =\\s*([^;]*);\"\n",
    "          ],\n",
    "          \"replaced_str\": [\n",
    "            \"FinalTime = 4000;\",\n",
    "            f\"Tolerance = { 0.000216536/2000 * 4**(-3)};\"\n",
    "          ]\n",
    "          },\n",
    "          \"Submit.sh\":{\n",
    "            \"original_str\": [\n",
    "              \"#SBATCH --constraint=skylake\"\n",
    "            ],\n",
    "            \"replaced_str\": [\n",
    "              \"#SBATCH --constraint=skylake\\n#SBATCH --reservation=sxs_standing\"\n",
    "            ]\n",
    "          }\n",
    "        },\n",
    "      },\n",
    "      {\n",
    "        \"old_Lev_name\":\"Lev2\",\n",
    "        \"new_Lev_name\":\"Lev55\",\n",
    "        \"this_lev_is_continuation\": False,\n",
    "        \"new_Lev_for_AMR_tolerance\":5.5,\n",
    "        \"new_Lev_for_GrDomain_and_AmrDriver\":6,\n",
    "        \"AH_factor\":1.0,\n",
    "        \"segments_to_copy\":[\"AA\"],\n",
    "        \"files_to_change_in_the_new_lev\":{\n",
    "          \"Evolution.input\":{\n",
    "          \"original_str\": [\n",
    "            r\"FinalTime = \\d*;\",\n",
    "            r\"Tolerance =\\s*([^;]*);\"\n",
    "          ],\n",
    "          \"replaced_str\": [\n",
    "            \"FinalTime = 4000;\",\n",
    "            f\"Tolerance = { 0.000216536/2000 * 4**(-5.5)};\"\n",
    "          ]\n",
    "          },\n",
    "          \"Submit.sh\":{\n",
    "            \"original_str\": [\n",
    "              \"#SBATCH --constraint=skylake\"\n",
    "            ],\n",
    "            \"replaced_str\": [\n",
    "              \"#SBATCH --constraint=skylake\\n#SBATCH --reservation=sxs_standing\"\n",
    "            ]\n",
    "          }\n",
    "        },\n",
    "      },\n",
    "      {\n",
    "        \"old_Lev_name\":\"Lev2\",\n",
    "        \"new_Lev_name\":\"Lev2\",\n",
    "        \"this_lev_is_continuation\": True,\n",
    "        \"segments_to_copy\":[\"AA\"],\n",
    "        \"files_to_change_in_the_new_lev\":{\n",
    "          \"Evolution.input\":{\n",
    "          \"original_str\": [\n",
    "            r\"FinalTime = \\d*;\",\n",
    "            r\"Tolerance =\\s*([^;]*);\"\n",
    "          ],\n",
    "          \"replaced_str\": [\n",
    "            \"FinalTime = 4000;\",\n",
    "            f\"Tolerance = { 0.000216536/2000 * 4**(-5.5)};\"\n",
    "          ]\n",
    "          },\n",
    "          \"Submit.sh\":{\n",
    "            \"original_str\": [\n",
    "              \"#SBATCH --constraint=skylake\"\n",
    "            ],\n",
    "            \"replaced_str\": [\n",
    "              \"#SBATCH --constraint=skylake\\n#SBATCH --reservation=sxs_standing\"\n",
    "            ]\n",
    "          }\n",
    "        },\n",
    "      }\n",
    "    ],\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_data_dict(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key in data_dict:\n",
    "#   create_new_folder(key,data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use same ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ev is always made, the idea is to make things simple and consistent\n",
    "data_dict = {\n",
    "    \"6_set2_test7\": {\n",
    "        \"new_run_parent\": Path(\"/resnick/groups/sxs/hchaudha/spec_runs/del\"),\n",
    "        \"old_ID_path\": Path(\"/resnick/groups/sxs/hchaudha/spec_runs/32_RM_set1_L3/ID\"),\n",
    "        \"bin_dir_path\": None,  # If None then ID.parent/Ev/bin will be used\n",
    "        \"input_files_source\": None,  # If None then ID.parent()/Ev/*input files will be used\n",
    "        \"files_to_change\": [  # All file paths should be relative to the new_Ev.parent() i.e. the base folder\n",
    "            {\n",
    "                \"Ev/DoMultipleRuns.input\": {\n",
    "                    \"original_str\": [\n",
    "                        r\"FinalTime = \\d*;\",\n",
    "                        r\"TruncationErrorMax/\\d*;\",\n",
    "                        r\"MinLev = \\d*;\",\n",
    "                        r\"MaxLev = \\d*;\",\n",
    "                        r\"PBandJ = \\d*;\",\n",
    "                    ],\n",
    "                    \"replaced_str\": [\n",
    "                        \"FinalTime = 4000;\",\n",
    "                        \"TruncationErrorMax/2000;\",\n",
    "                        \"MinLev = 3;\",\n",
    "                        \"MaxLev = 3;\",\n",
    "                        \"PBandJ = 0;\",\n",
    "                    ],\n",
    "                },\n",
    "                \"Ev/bin/Machines.pm\": {\n",
    "                    \"original_str\": [r\"sub\\s+HeaderSBATCH_CaltechHPC\\s*\\{.*?^\\}\"],\n",
    "                    \"replaced_str\": [\n",
    "                        r\"\"\"sub HeaderSBATCH_CaltechHPC {\n",
    "  my ($ppn) = @_;\n",
    "  my $header = HeaderSBATCH($ppn);\n",
    "  if($ppn == 32) {\n",
    "      $header .= \"#SBATCH --constraint=skylake\\n#SBATCH --cpus-per-task=1\\n\";\n",
    "  } elsif($ppn == 56) {\n",
    "      $header .= \"#SBATCH --constraint=cascadelake\\n#SBATCH --cpus-per-task=1\\n\";\n",
    "  } elsif($ppn == 64) {\n",
    "      $header .= \"#SBATCH --constraint=icelake\\n#SBATCH --cpus-per-task=1\\n\";\n",
    "  } else {\n",
    "      die \"Unexpected ppn $ppn\\n\";\n",
    "  }\n",
    "  # Hello world\n",
    "  return $header;\n",
    "}\"\"\"\n",
    "                    ],\n",
    "                },\n",
    "                \"Ev/ConstraintDamping.input\": {\n",
    "                    \"original_str\": [\n",
    "                        re.escape(\"\"\"     EvaluateScalarFormula\n",
    "     (Output=GhGamma0;\n",
    "      Coords=GridToDistorted::MappedCoords;\n",
    "      S = InvExpansionFactor;\n",
    "      A = CDamping_distA_squared;\n",
    "      B = CDamping_distB_squared;\n",
    "      O = CDamping_distOrigin_squared;\n",
    "      Formula =\n",
    "      __CDamping_gamma0_AmpA__ *exp(-A/sqr(__CDamping_gamma0_WidthA__*S))\n",
    "      +__CDamping_gamma0_AmpB__ *exp(-B/sqr(__CDamping_gamma0_WidthB__*S))\n",
    "      +__CDamping_gamma0_AmpOrigin__\n",
    "      *exp(-O/sqr(__CDamping_gamma0_WidthOrigin__*S))\n",
    "      +__CDamping_gamma0_Asymptotic__;\n",
    "      ),\"\"\"),\n",
    "                        re.escape(\"\"\"     EvaluateScalarFormula\n",
    "     (Output=GhGamma2;\n",
    "      Coords=GridToDistorted::MappedCoords;\n",
    "      S = InvExpansionFactor;\n",
    "      A = CDamping_distA_squared;\n",
    "      B = CDamping_distB_squared;\n",
    "      O = CDamping_distOrigin_squared;\n",
    "      Formula =\n",
    "      __CDamping_gamma2_AmpA__ *exp(-A/sqr(__CDamping_gamma2_WidthA__*S))\n",
    "      +__CDamping_gamma2_AmpB__ *exp(-B/sqr(__CDamping_gamma2_WidthB__*S))\n",
    "      +__CDamping_gamma2_AmpOrigin__\n",
    "                              *exp(-O/sqr(__CDamping_gamma2_WidthOrigin__*S))\n",
    "      +__CDamping_gamma2_Asymptotic__;\n",
    "      )\"\"\"),\n",
    "                    ],\n",
    "                    \"replaced_str\": [\n",
    "                        r\"\"\"     EvaluateScalarFormula\n",
    "     (Output=GhGamma0;\n",
    "      Coords=GridToDistorted::MappedCoords;\n",
    "      S = InvExpansionFactor;\n",
    "      A = CDamping_distA_squared;\n",
    "      B = CDamping_distB_squared;\n",
    "      O = CDamping_distOrigin_squared;\n",
    "      Formula =\n",
    "      __CDamping_gamma0_AmpA__ *exp(-A/sqr(__CDamping_gamma0_WidthA__*S))\n",
    "      +__CDamping_gamma0_AmpB__ *exp(-B/sqr(__CDamping_gamma0_WidthB__*S))\n",
    "      +__CDamping_gamma0_AmpOrigin__\n",
    "      *exp(-O/sqr(__CDamping_gamma0_WidthOrigin__*S))\n",
    "      +__CDamping_gamma0_Asymptotic__;\n",
    "      ),\"\"\",\n",
    "                        r\"\"\"     EvaluateScalarFormula\n",
    "     (Output=GhGamma2;\n",
    "      Coords=GridToDistorted::MappedCoords;\n",
    "      S = InvExpansionFactor;\n",
    "      A = CDamping_distA_squared;\n",
    "      B = CDamping_distB_squared;\n",
    "      O = CDamping_distOrigin_squared;\n",
    "      Formula =\n",
    "      __CDamping_gamma2_AmpA__ *exp(-A/sqr(__CDamping_gamma2_WidthA__*S))\n",
    "      +__CDamping_gamma2_AmpB__ *exp(-B/sqr(__CDamping_gamma2_WidthB__*S))\n",
    "      +__CDamping_gamma2_AmpOrigin__\n",
    "                              *exp(-O/sqr(__CDamping_gamma2_WidthOrigin__*S))\n",
    "      +__CDamping_gamma2_Asymptotic__;\n",
    "      )\"\"\",\n",
    "                    ],\n",
    "                },\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ev is always made, the idea is to make things simple and consistent\n",
    "data_dict = {\n",
    "    \"6_set2_test7\": {\n",
    "        \"new_run_parent\": Path(\"/resnick/groups/sxs/hchaudha/spec_runs/del\"),\n",
    "        \"old_ID_path\": Path(\"/resnick/groups/sxs/hchaudha/spec_runs/32_RM_set1_L3/ID\"),\n",
    "        \"bin_dir_path\": None,  # If None then ID.parent/Ev/bin will be used\n",
    "        \"input_files_source\": None,  # If None then ID.parent()/Ev/*input files will be used\n",
    "        \"files_to_change\": [  # All file paths should be relative to the new_Ev.parent() i.e. the base folder\n",
    "            {\n",
    "                \"Ev/DoMultipleRuns.input\": {\n",
    "                    \"original_str\": [\n",
    "                        r\"FinalTime = \\d*;\",\n",
    "                        r\"TruncationErrorMax/\\d*;\",\n",
    "                        r\"MinLev = \\d*;\",\n",
    "                        r\"MaxLev = \\d*;\",\n",
    "                        r\"PBandJ = \\d*;\",\n",
    "                    ],\n",
    "                    \"replaced_str\": [\n",
    "                        \"FinalTime = 4000;\",\n",
    "                        \"TruncationErrorMax/2000;\",\n",
    "                        \"MinLev = 3;\",\n",
    "                        \"MaxLev = 3;\",\n",
    "                        \"PBandJ = 0;\",\n",
    "                    ],\n",
    "                },\n",
    "                \"Ev/bin/Machines.pm\": {\n",
    "                    \"original_str\": [r\"sub\\s+HeaderSBATCH_CaltechHPC\\s*\\{.*?^\\}\"],\n",
    "                    \"replaced_str\": [\n",
    "                        r\"\"\"sub HeaderSBATCH_CaltechHPC {\n",
    "  my ($ppn) = @_;\n",
    "  my $header = HeaderSBATCH($ppn);\n",
    "  if($ppn == 32) {\n",
    "      $header .= \"#SBATCH --reservation=sxs_standing\\n#SBATCH --cpus-per-task=1\\n\";\n",
    "  } elsif($ppn == 56) {\n",
    "      $header .= \"#SBATCH --reservation=sxs_standing\\n#SBATCH --cpus-per-task=1\\n\";\n",
    "  } elsif($ppn == 64) {\n",
    "      $header .= \"#SBATCH --reservation=sxs_standing\\n#SBATCH --cpus-per-task=1\\n\";\n",
    "  } else {\n",
    "      die \"Unexpected ppn $ppn\\n\";\n",
    "  }\n",
    "  # Hello world\n",
    "  return $header;\n",
    "}\"\"\"\n",
    "                    ],\n",
    "                },\n",
    "                \"Ev/ConstraintDamping.input\": {\n",
    "                    \"original_str\": [\n",
    "                        re.escape(\"\"\"     EvaluateScalarFormula\n",
    "     (Output=GhGamma0;\n",
    "      Coords=GridToDistorted::MappedCoords;\n",
    "      S = InvExpansionFactor;\n",
    "      A = CDamping_distA_squared;\n",
    "      B = CDamping_distB_squared;\n",
    "      O = CDamping_distOrigin_squared;\n",
    "      Formula =\n",
    "      __CDamping_gamma0_AmpA__ *exp(-A/sqr(__CDamping_gamma0_WidthA__*S))\n",
    "      +__CDamping_gamma0_AmpB__ *exp(-B/sqr(__CDamping_gamma0_WidthB__*S))\n",
    "      +__CDamping_gamma0_AmpOrigin__\n",
    "      *exp(-O/sqr(__CDamping_gamma0_WidthOrigin__*S))\n",
    "      +__CDamping_gamma0_Asymptotic__;\n",
    "      ),\"\"\"),\n",
    "                        re.escape(\"\"\"     EvaluateScalarFormula\n",
    "     (Output=GhGamma2;\n",
    "      Coords=GridToDistorted::MappedCoords;\n",
    "      S = InvExpansionFactor;\n",
    "      A = CDamping_distA_squared;\n",
    "      B = CDamping_distB_squared;\n",
    "      O = CDamping_distOrigin_squared;\n",
    "      Formula =\n",
    "      __CDamping_gamma2_AmpA__ *exp(-A/sqr(__CDamping_gamma2_WidthA__*S))\n",
    "      +__CDamping_gamma2_AmpB__ *exp(-B/sqr(__CDamping_gamma2_WidthB__*S))\n",
    "      +__CDamping_gamma2_AmpOrigin__\n",
    "                              *exp(-O/sqr(__CDamping_gamma2_WidthOrigin__*S))\n",
    "      +__CDamping_gamma2_Asymptotic__;\n",
    "      )\"\"\"),\n",
    "                    ],\n",
    "                    \"replaced_str\": [\n",
    "                        r\"\"\"     EvaluateScalarFormula\n",
    "     (Output=GhGamma0;\n",
    "      Coords=GridToDistorted::MappedCoords;\n",
    "      S = InvExpansionFactor;\n",
    "      A = CDamping_distA_squared;\n",
    "      B = CDamping_distB_squared;\n",
    "      O = CDamping_distOrigin_squared;\n",
    "      Formula =\n",
    "      __CDamping_gamma0_AmpA__ *exp(-A/sqr(__CDamping_gamma0_WidthA__*S))\n",
    "      +__CDamping_gamma0_AmpB__ *exp(-B/sqr(__CDamping_gamma0_WidthB__*S))\n",
    "      +__CDamping_gamma0_AmpOrigin__\n",
    "      *exp(-O/sqr(__CDamping_gamma0_WidthOrigin__*S))\n",
    "      +__CDamping_gamma0_Asymptotic__;\n",
    "      ),\"\"\",\n",
    "                        r\"\"\"     EvaluateScalarFormula\n",
    "     (Output=GhGamma2;\n",
    "      Coords=GridToDistorted::MappedCoords;\n",
    "      S = InvExpansionFactor;\n",
    "      A = CDamping_distA_squared;\n",
    "      B = CDamping_distB_squared;\n",
    "      O = CDamping_distOrigin_squared;\n",
    "      Formula =\n",
    "      __CDamping_gamma2_AmpA__ *exp(-A/sqr(__CDamping_gamma2_WidthA__*S))\n",
    "      +__CDamping_gamma2_AmpB__ *exp(-B/sqr(__CDamping_gamma2_WidthB__*S))\n",
    "      +__CDamping_gamma2_AmpOrigin__\n",
    "                              *exp(-O/sqr(__CDamping_gamma2_WidthOrigin__*S))\n",
    "      +__CDamping_gamma2_Asymptotic__;\n",
    "      )\"\"\",\n",
    "                    ],\n",
    "                },\n",
    "            },\n",
    "        ],\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder_name in data_dict.keys():\n",
    "    assert data_dict[folder_name][\"new_run_parent\"].exists(), (\n",
    "        f\"{data_dict[folder_name]['new_run_parent']} does not exist!\"\n",
    "    )\n",
    "\n",
    "    base_folder_path = data_dict[folder_name][\"new_run_parent\"] / folder_name\n",
    "    base_folder_path.mkdir(exist_ok=False)\n",
    "\n",
    "    # Copy the ID folder\n",
    "    new_ID_path = base_folder_path / \"ID\"\n",
    "    old_ID_path = data_dict[folder_name][\"old_ID_path\"]\n",
    "    if old_ID_path.exists():\n",
    "        shutil.copytree(old_ID_path, new_ID_path, symlinks=True)\n",
    "    else:\n",
    "        raise Exception(f\"{old_ID_path} does not exist!\")\n",
    "\n",
    "    # Add write permission to the ID folder\n",
    "    add_write_permission(new_ID_path)\n",
    "\n",
    "    new_bin_path = new_ID_path / \"bin\"\n",
    "    old_bin_path = data_dict[folder_name][\"bin_dir_path\"]\n",
    "    if old_bin_path is None:\n",
    "        old_bin_path = old_ID_path.parent / \"Ev/bin\"\n",
    "    if not old_bin_path.exists():\n",
    "        raise Exception(f\"{old_bin_path} does not exist!\")\n",
    "\n",
    "    # Copy the bin folder\n",
    "    shutil.copytree(old_bin_path, new_bin_path)\n",
    "\n",
    "    # Create the new Ev folder\n",
    "    new_Ev_path = base_folder_path / \"Ev\"\n",
    "    new_Ev_path.mkdir(exist_ok=False)\n",
    "\n",
    "    # Copy the bin dir into the new Ev folder\n",
    "    new_Ev_bin_path = new_Ev_path / \"bin\"\n",
    "    shutil.copytree(old_bin_path, new_Ev_bin_path)\n",
    "\n",
    "    # Copy the input files\n",
    "    input_files_source = data_dict[folder_name][\"input_files_source\"]\n",
    "    if input_files_source is None:\n",
    "        input_files_source = old_ID_path.parent / \"Ev\"\n",
    "    if not input_files_source.exists():\n",
    "        raise Exception(f\"{input_files_source=}folder does not exist!\")\n",
    "\n",
    "    # Copy the input files to the new Ev folder\n",
    "    for file in input_files_source.glob(\"*.input\"):\n",
    "        shutil.copy2(file, new_Ev_path)\n",
    "\n",
    "    # Make DoMultipleRuns.input executable\n",
    "    DMR = new_Ev_path / \"DoMultipleRuns.input\"\n",
    "    DMRR = new_Ev_path / \"DoMultipleRunsRingdown.input\"\n",
    "\n",
    "    for i in [DMR, DMRR]:\n",
    "        current_permissions = i.stat().st_mode\n",
    "        # Add execute permission for the user and group\n",
    "        new_permissions = current_permissions | stat.S_IXUSR | stat.S_IXGRP\n",
    "        i.chmod(new_permissions)\n",
    "\n",
    "    # Symlink Ev/bin/EvolveHyperbolicSystem to SpEC\n",
    "    new_SpEC_symlink = new_Ev_path / \"SpEC\"\n",
    "    new_SpEC_symlink.symlink_to(\"bin/EvolveHyperbolicSystem\")\n",
    "\n",
    "    new_StartJob_sh_path = new_Ev_path / \"StartJob.sh\"\n",
    "    with open(new_StartJob_sh_path, \"w\") as f:\n",
    "        f.write(\"\"\"#!/bin/bash\n",
    ". bin/this_machine.env || echo 'Not using env file.'\n",
    "# Only applicable for bbh2 runs:\n",
    "# For PBandJ (Perform Branching after Junk) only EccRedLev should be started\n",
    "# with StartJob.sh. ProhibitStartJobReruns.txt gets generated at Eccentricity\n",
    "# Reduction restart, and safeguards against starting Levs != EccRedLev from t=0\n",
    "# for PBandJ.\n",
    "if test -f ProhibitStartJobReruns.txt; then\n",
    "    echo\n",
    "    echo \"ERROR: ProhibitStartJobReruns.txt exists. See below:\"\n",
    "    cat ProhibitStartJobReruns.txt\n",
    "    echo\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "bin/DoMultipleRuns -L -c 'sbatch ./Submit.sh'\"\"\")\n",
    "    # Make StartJob.sh executable\n",
    "    current_permissions = new_StartJob_sh_path.stat().st_mode\n",
    "    # Add execute permission for the user and group\n",
    "    new_permissions = current_permissions | stat.S_IXUSR | stat.S_IXGRP\n",
    "    new_StartJob_sh_path.chmod(new_permissions)\n",
    "\n",
    "    # Add write permission to the new Ev folder and the new bin folder\n",
    "    add_write_permission(base_folder_path)\n",
    "\n",
    "    print(\n",
    "        f\"\\n\\nCreated new run folder at {base_folder_path}. Making changes to the input files now....\\n\\n\"\n",
    "    )\n",
    "\n",
    "    for file in data_dict[folder_name][\"files_to_change\"]:\n",
    "        for file_name, changes in file.items():\n",
    "            file_path = base_folder_path / file_name\n",
    "            if not file_path.exists():\n",
    "                raise Exception(f\"{file_path} does not exist!\")\n",
    "            original_str = changes[\"original_str\"]\n",
    "            replaced_str = changes[\"replaced_str\"]\n",
    "            for or_str, re_str in zip(original_str, replaced_str):\n",
    "                replace_current_file(\n",
    "                    file_path, or_str, re_str, flags=re.DOTALL | re.MULTILINE\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sxs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
