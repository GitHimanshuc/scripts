{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scri\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from spherical_functions import LM_index as lm\n",
    "from scipy.interpolate import interp1d\n",
    "import json\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import itertools\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams[\"figure.figsize\"] = (12,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average_valid(array,avg_len):\n",
    "    return np.convolve(array,np.ones(avg_len),'valid')/avg_len\n",
    "\n",
    "def load_and_pickle(data_path:Path, reload_data:bool=False, data_type:str='abd', options:dict={}):\n",
    "  if not data_path.exists():\n",
    "    raise Exception(f\"{data_path} does not exist!\")\n",
    "\n",
    "  saved_data_path = data_path.parent/\"saved.pkl\"\n",
    "  \n",
    "  if saved_data_path.exists() and reload_data == False:\n",
    "    with open(saved_data_path, 'rb') as f:\n",
    "      saved_data = pickle.load(f)\n",
    "      print(f\"Saved data loaded: {saved_data_path}\")\n",
    "  else:\n",
    "    saved_data = {}\n",
    "    if data_type == 'abd':\n",
    "      saved_data['abd']= scri.create_abd_from_h5(\n",
    "          file_name=str(data_path),\n",
    "          file_format=\"spectrecce_v1\",\n",
    "          **options\n",
    "        )\n",
    "      with open(saved_data_path, 'wb') as f:\n",
    "        pickle.dump(saved_data,f)\n",
    "      print(f\"Data loaded and saved at : {saved_data_path}\")\n",
    "\n",
    "  return saved_data\n",
    "\n",
    "def load_bondi_constraints(data_path:Path):\n",
    "  if not data_path.exists():\n",
    "    raise Exception(f\"{data_path} does not exist!\")\n",
    "  saved_data_path = data_path.parent/\"saved.pkl\"\n",
    "  if not saved_data_path.exists():\n",
    "    raise Exception(f\"{saved_data_path} does not exist\")\n",
    "  else:\n",
    "    with open(saved_data_path, 'rb') as f:\n",
    "      saved_data = pickle.load(f)\n",
    "      if 'bondi_violation_norms' in saved_data:\n",
    "        print(f\"bondi_violation_norms loaded for {data_path}\")\n",
    "      else:\n",
    "        print(f\"Computing bondi_violation_norms for: {data_path}\")\n",
    "        saved_data['bondi_violation_norms'] = saved_data['abd'].bondi_violation_norms\n",
    "        with open(saved_data_path, 'wb') as f:\n",
    "          pickle.dump(saved_data,f)\n",
    "\n",
    "        print(f\"Saved bondi_violation_norms for: {data_path}\")\n",
    "    return saved_data\n",
    "\n",
    "def add_bondi_constraints(abd_data:dict):\n",
    "  for key in abd_data:\n",
    "    abd_data[key]['bondi_violation_norms'] = abd_data[key][\"abd\"].bondi_violation_norms\n",
    "    print(f\"bondi_violation_norms computed for {key}\")\n",
    "\n",
    "def create_diff_dict_cce(WT_data_dict:dict, l:int, m:int, base_key:str, t_interpolate:np.ndarray):\n",
    "  h = WT_data_dict[base_key]['abd'].h.interpolate(t_interpolate)\n",
    "  diff_dict = {\"t\": h.t}\n",
    "  y_base = h.data[:,  lm(l,m,h.ell_min)]\n",
    "  y_norm = np.linalg.norm(y_base)\n",
    "  for key in WT_data_dict:\n",
    "    if key == base_key:\n",
    "      continue\n",
    "    h = WT_data_dict[key]['abd'].h.interpolate(t_interpolate)\n",
    "    y_inter = h.data[:,  lm(l,m,h.ell_min)]\n",
    "    diff_dict[key+\"_diff\"] = y_inter-y_base\n",
    "    diff_dict[key+\"_absdiff\"] = np.abs(y_inter-y_base)\n",
    "    diff_dict[key+\"_rel_diff\"] = (y_inter-y_base)/y_norm\n",
    "    diff_dict[key+\"_rel_absdiff\"] = np.abs(y_inter-y_base)/y_norm\n",
    "  return diff_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_interpolate = np.linspace(-1000,4000,num=5000)\n",
    "data_path = Path(\"/groups/sxs/hchaudha/spec_runs/6_segs/6_set1_L3/GW_data_lev3/BondiCceR0100/red_cce.h5\")\n",
    "data = load_and_pickle(data_path,options = {'t_interpolate':t_interpolate})\n",
    "data = load_bondi_constraints(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple ABDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cce_data= {}\n",
    "# cce_data[\"high_accuracy_Lev0_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev0/BondiCceR0257/red_cce.h5\")\n",
    "# cce_data[\"high_accuracy_Lev1_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev1/BondiCceR0257/red_cce.h5\")\n",
    "# cce_data[\"high_accuracy_Lev2_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev2/BondiCceR0257/red_cce.h5\")\n",
    "# cce_data[\"high_accuracy_Lev3_R0258\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/GW_data_lev3/BondiCceR0258/red_cce.h5\")\n",
    "# cce_data[\"high_accuracy_Lev4_R0258\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/GW_data_lev4/BondiCceR0258/red_cce.h5\")\n",
    "# cce_data[\"high_accuracy_Lev5_R0258\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/GW_data_lev5/BondiCceR0258/red_cce.h5\")\n",
    "# cce_data[\"master_Lev0_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev/GW_data/BondiCceR0257/red_cce.h5\")\n",
    "# cce_data[\"master_Lev1_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev/GW_data_lev1/BondiCceR0257/red_cce.h5\")\n",
    "# cce_data[\"master_Lev2_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev/GW_data_lev2/BondiCceR0257/red_cce.h5\")\n",
    "# cce_data[\"master_Lev3_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_master/Ev/GW_data_lev3/BondiCceR0257/red_cce.h5\")\n",
    "# cce_data[\"master_Lev4_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_master/Ev/GW_data_lev4/BondiCceR0257/red_cce.h5\")\n",
    "# cce_data[\"master_Lev5_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_master/Ev/GW_data_lev5/BondiCceR0257/red_cce.h5\")\n",
    "# cce_data[\"Lev5_bg_ah100_cd_01_uamr_full_R0258\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_bg_ah100_cd_01_uamr_full/GW_data/BondiCceR0258/red_cce.h5\")\n",
    "# cce_data[\"Lev5_bg_ah100_cd_01_uamr_full_R0686\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_bg_ah100_cd_01_uamr_full/GW_data/BondiCceR0686/red_cce.h5\")\n",
    "# cce_data[\"Lev5_bg_ah100_lapse_uamr_fullR0258\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_bg_ah100_lapse_uamr_full/GW_data/BondiCceR0258/red_cce.h5\")\n",
    "# cce_data[\"Lev5_bg_ah100_lapse_uamr_full_R0100\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_bg_ah100_lapse_uamr_full/GW_data/BondiCceR0100/red_cce.h5\")\n",
    "# cce_data[\"high_accuracy_Lev5_R0258_ZeroNonSmooth\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/ZeroNonSmooth/red_Lev5_R0258_VolumeData.h5\")\n",
    "# cce_data[\"high_accuracy_Lev5_R0258_NoIncomingRadiation\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/NoIncomingRadiation/red_Lev5_R0258_VolumeData.h5\")\n",
    "# cce_data[\"high_accuracy_Lev5_R0258_InverseCubic\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/InverseCubic/red_Lev5_R0258_VolumeData.h5\")\n",
    "# cce_data[\"high_accuracy_Lev5_R0258_ConformalFactor10\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/ConformalFactor10/red_Lev5_R0258_VolumeData.h5\")\n",
    "# cce_data[\"high_accuracy_Lev5_R0258_ConformalFactor7\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/ConformalFactor7/red_Lev5_R0258_VolumeData.h5\")\n",
    "# cce_data[\"high_accuracy_Lev5_R0258_ConformalFactor3\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/ConformalFactor3/red_Lev5_R0258_VolumeData.h5\")\n",
    "\n",
    "# cce_data[\"Lev01_test_ode_Lev2_257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev2/BondiCceR0257/red_cce.h5\")\n",
    "# cce_data[\"Lev01_test_ode_Lev1_257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev1/BondiCceR0257/red_cce.h5\")\n",
    "\n",
    "# cce_data[\"Lev01_test_Lev2_257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev/GW_data_lev2/BondiCceR0257/red_cce.h5\")\n",
    "\n",
    "levs,run_sets,radius= [],[],[]\n",
    "# levs = [0,1,2,3,4,5,6]\n",
    "# levs = [4,5,6]\n",
    "levs = [0,1,2,3]\n",
    "# run_sets = [1,2,3]\n",
    "run_sets = [1]\n",
    "# radius = [250]\n",
    "# radius = [100,150,200,250,300,350,500,700,900]\n",
    "radius = [250,350,700,900]\n",
    "\n",
    "for l,s,r in itertools.product(levs,run_sets,radius):\n",
    "  if s == 2 and (l == 0 or l==1):\n",
    "    continue\n",
    "  if l <= 3:\n",
    "    cce_data[f\"6_set{s}_L3s{l}_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/6_segs/6_set{s}_L3/GW_data_lev{l}/BondiCceR0{r}/red_cce.h5\")\n",
    "  else:\n",
    "    cce_data[f\"6_set{s}_L6s{l}_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/6_segs/6_set{s}_L6/GW_data_lev{l}/BondiCceR0{r}/red_cce.h5\")\n",
    "\n",
    "\n",
    "fail_flag=False\n",
    "for key in cce_data:\n",
    "  if not cce_data[key].exists():\n",
    "    fail_flag = True\n",
    "    print(f\"{cce_data[key]} does not exist!\")\n",
    "  if fail_flag:\n",
    "    raise Exception(\"Some paths do not exist!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_interpolate = np.linspace(-1000,10000,num=5000)\n",
    "# t_interpolate = np.linspace(-1000,4000,num=5000)\n",
    "\n",
    "abd_data = {}\n",
    "for key in cce_data:\n",
    "  abd_data[key] = load_and_pickle(cce_data[key],options = {'t_interpolate':t_interpolate})\n",
    "  abd_data[key] = load_bondi_constraints(cce_data[key])\n",
    "\n",
    "print(abd_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bondi_norms_to_plot = [0,1,2,3,4,5]\n",
    "bondi_norms_to_plot = [5]\n",
    "\n",
    "t_min = -10000\n",
    "t_min = 2000\n",
    "# t_min = 2500\n",
    "t_max = 10000\n",
    "# t_max = 7751.5\n",
    "# t_max = 7000\n",
    "t_max = 4000\n",
    "# t_max = 3500\n",
    "\n",
    "labels = None\n",
    "# labels={\n",
    "# #  \"high_accuracy_Lev5_R0258\" : \"Lev5_ode_tol_R0258\",\n",
    "#  \"6_set1_L3s3_200\" : \"Lev3_variant_R0200\",\n",
    "#  \"6_set1_L3s3_250\" : \"Lev3_variant_R0250\",\n",
    "#  \"6_set1_L3s3_300\" : \"Lev3_variant_R0300\",\n",
    "#  \"6_set1_L3s2_200\" : \"Lev2_variant_R0200\",\n",
    "#  \"6_set1_L3s2_250\" : \"Lev2_variant_R0250\",\n",
    "#  \"6_set1_L3s2_300\" : \"Lev2_variant_R0300\",\n",
    "# }\n",
    "\n",
    "for key in abd_data:\n",
    "  violation_dict = abd_data[key]['bondi_violation_norms']\n",
    "  if \"Factor\" in key:\n",
    "    continue\n",
    "  # if \"L3s2\" not in key:\n",
    "  #   continue\n",
    "  # if \"Lev2\" not in key:\n",
    "  #   continue\n",
    "\n",
    "  t_arr = abd_data[key][\"abd\"].t\n",
    "  trimmed_indices = (t_arr>t_min) & (t_arr<t_max)\n",
    "  t_arr = t_arr[trimmed_indices]\n",
    "\n",
    "  for i in bondi_norms_to_plot:\n",
    "    if labels is None:\n",
    "      plt.semilogy(t_arr,violation_dict[i][trimmed_indices],label=f\"{key}_{i}\")\n",
    "    else:\n",
    "      plt.semilogy(t_arr,violation_dict[i][trimmed_indices],label=f\"{labels[key]}_{i}\")\n",
    "\n",
    "  plt.xlabel('t')\n",
    "  plt.ylabel(\"bondi violations\")\n",
    "  plt.legend()\n",
    "  plt.tight_layout()\n",
    "  # plt.show()\n",
    "  # plt.savefig(Path(\"/home/hchaudha/notes/spec_accuracy/CCE/new_set_L3\")/f\"violations_alllll_{bondi_norms_to_plot}_t={t_min}-{t_max}.png\")\n",
    "  # plt.savefig(Path(\"/home/hchaudha/notes/spec_accuracy/CCE/\")/f\"{bondi_norms_to_plot}_t={t_min}-{t_max}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot cce waveform diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in abd_data.keys():\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes_to_plot = [(3,2)]\n",
    "modes_to_plot = [(2,2)]\n",
    "\n",
    "base_key = 'high_accuracy_Lev5_R0258'\n",
    "base_key = 'high_accuracy_Lev2_R0257'\n",
    "# base_key = '6_set1_L6s4_250'\n",
    "# base_key = '6_set3_L6s6_250'\n",
    "# base_key = '6_set1_L3s3_250'\n",
    "base_key = '6_set1_L3s2_250'\n",
    "radius = int(base_key[-3:])\n",
    "\n",
    "plot_vals = [\"_diff\",\"_absdiff\",\"_rel_diff\",\"_rel_absdiff\"]\n",
    "plot_vals = [\"_absdiff\",\"_rel_absdiff\"]\n",
    "# plot_vals = [\"_rel_absdiff\"]\n",
    "\n",
    "t_min = 0\n",
    "# t_min = 2000\n",
    "# t_min = 2500\n",
    "# t_min = 1190\n",
    "t_min = 1210\n",
    "t_max = 10000\n",
    "# t_max = 7751.5\n",
    "# t_max = 7000\n",
    "t_max = 4000\n",
    "t_max = 3500\n",
    "t_interpolate = np.linspace(t_min,t_max,num=5000)\n",
    "\n",
    "def filter(key):\n",
    "  if key == base_key:\n",
    "    return True\n",
    "  # if '257' not in key:\n",
    "  #   return True\n",
    "  # if not re.search(r\"Lev[3,4,5]\",key):\n",
    "  #   return True\n",
    "  if not re.search(r\"s[0,1,2]\",key):\n",
    "    return True\n",
    "  # if 's3' in key:\n",
    "  #   return True\n",
    "\n",
    "num_colors_required = len(modes_to_plot)*(len(abd_data)-1)\n",
    "\n",
    "num_colors_required = 0\n",
    "for mode,key in itertools.product(modes_to_plot,abd_data):\n",
    "  if filter(key):\n",
    "    continue\n",
    "  num_colors_required = num_colors_required + 1\n",
    "\n",
    "if num_colors_required <=10:\n",
    "  cmap = plt.get_cmap('tab10')\n",
    "  color = [cmap(i) for i in range(num_colors_required )]\n",
    "elif num_colors_required <=20:\n",
    "  cmap = plt.get_cmap('tab20')\n",
    "  color = [cmap(i) for i in range(num_colors_required )]\n",
    "else:\n",
    "  color=plt.cm.hsv(np.linspace(0, 1, num_colors_required))\n",
    "  # color=plt.cm.gist_rainbow(np.linspace(0, 1, num_colors_required))\n",
    "\n",
    "i=-1\n",
    "plt.close()\n",
    "for mode,key in itertools.product(modes_to_plot,abd_data):\n",
    "  l,m = mode\n",
    "  if filter(key):\n",
    "    continue\n",
    "\n",
    "  diff_dict = create_diff_dict_cce(abd_data,l=l,m=m,base_key=base_key,t_interpolate=t_interpolate)\n",
    "  t_arr = diff_dict[\"t\"]\n",
    "\n",
    "  i = i+1\n",
    "  for plot_val in plot_vals:\n",
    "    match plot_val:\n",
    "      case \"_rel_absdiff\":\n",
    "        plt.semilogy(t_arr,diff_dict[key+plot_val],label=f\"{key}_{mode}\"+plot_val,linestyle=\"-\",color=color[i])\n",
    "      case \"_absdiff\":\n",
    "        # plt.semilogy(t_arr,diff_dict[key+plot_val],label=f\"{key}_{mode}\"+plot_val,linestyle=\":\",color=color[i])\n",
    "        plt.semilogy(t_arr,diff_dict[key+plot_val],linestyle=\":\",color=color[i])\n",
    "      case \"_diff\":\n",
    "        plt.semilogy(t_arr,diff_dict[key+plot_val],label=f\"{key}_{mode}\"+plot_val,linestyle=\"--\",color=color[i])\n",
    "      case \"_rel_diff\":\n",
    "        plt.semilogy(t_arr,diff_dict[key+plot_val],label=f\"{key}_{mode}\"+plot_val,linestyle=\"-.\",color=color[i])\n",
    "\n",
    "    plt.xlabel('t')\n",
    "    plt.ylabel(\"diff\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.title(f\"CCE waveform diff {modes_to_plot} {base_key=}\")\n",
    "    # plt.show()\n",
    "    # plt.savefig(Path(\"/home/hchaudha/notes/spec_accuracy/CCE/new_set_L3\")/f\"violations_alllll_{bondi_norms_to_plot}_t={t_min}-{t_max}.png\")\n",
    "    # plt.savefig(Path(\"/home/hchaudha/notes/spec_accuracy/CCE/\")/f\"{bondi_norms_to_plot}_t={t_min}-{t_max}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finite radius waveform comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_radii(h5_file_path:Path):\n",
    "  radii = set()\n",
    "  with h5py.File(h5_file_path,'r') as f:\n",
    "    names = []\n",
    "    f.visit(names.append)\n",
    "  for name in names:\n",
    "    if \"Version\" in name:\n",
    "      continue\n",
    "    radii.add(name[1:5])\n",
    "  radii = list(radii)\n",
    "  radii.sort()\n",
    "  return radii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GW_data_path= {}\n",
    "# GW_data_path[\"master_Lev0\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev/GW_data\")\n",
    "# GW_data_path[\"master_Lev1\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev/GW_data_lev1\")\n",
    "# GW_data_path[\"master_Lev2\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev/GW_data_lev2\")\n",
    "# GW_data_path[\"master_Lev3\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_master/Ev/GW_data_lev3\")\n",
    "# GW_data_path[\"master_Lev4\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_master/Ev/GW_data_lev4\")\n",
    "# GW_data_path[\"master_Lev5\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_master/Ev/GW_data_lev5\")\n",
    "\n",
    "GW_data_path[\"high_accuracy_Lev0\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev0/rh_FiniteRadii_CodeUnits\")\n",
    "GW_data_path[\"high_accuracy_Lev1\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev1/rh_FiniteRadii_CodeUnits\")\n",
    "GW_data_path[\"high_accuracy_Lev2\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev2/rh_FiniteRadii_CodeUnits\")\n",
    "# GW_data_path[\"high_accuracy_Lev0\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/Lev0_AC/Run/GW2/\")\n",
    "# GW_data_path[\"high_accuracy_Lev1\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/Lev1_AC/Run/GW2/\")\n",
    "# GW_data_path[\"high_accuracy_Lev2\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/Lev2_AC/Run/GW2/\")\n",
    "GW_data_path[\"high_accuracy_Lev3\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/GW_data_lev3/rh_FiniteRadii_CodeUnits\")\n",
    "GW_data_path[\"high_accuracy_Lev4\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/GW_data_lev4/rh_FiniteRadii_CodeUnits\")\n",
    "# GW_data_path[\"high_accuracy_Lev45\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/Lev45_AC/Run/GW2/\")\n",
    "GW_data_path[\"high_accuracy_Lev5\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/GW_data_lev5/rh_FiniteRadii_CodeUnits\")\n",
    "# GW_data_path[\"high_accuracy_Lev55\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/Lev55_AC/Run/GW2/\")\n",
    "\n",
    "\n",
    "levs,run_sets,radius= [],[],[]\n",
    "levs = [0,1,2,3,4,5,6]\n",
    "# levs = [0,1,2,3]\n",
    "# levs = [4,5,6]\n",
    "# levs = [0]\n",
    "run_sets = [3]\n",
    "# run_sets = [1]\n",
    "\n",
    "for l,s in itertools.product(levs,run_sets):\n",
    "  if s == 2 and (l == 0 or l==1):\n",
    "    continue\n",
    "  if l <= 3:\n",
    "    GW_data_path[f\"6_set{s}_L3s{l}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/6_segs/6_set{s}_L3/GW_data_lev{l}/rh_FiniteRadii_CodeUnits\")\n",
    "  else:\n",
    "    GW_data_path[f\"6_set{s}_L6s{l}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/6_segs/6_set{s}_L6/GW_data_lev{l}/rh_FiniteRadii_CodeUnits\")\n",
    "\n",
    "file = \"rh_FiniteRadii_CodeUnits.h5\"\n",
    "for key in GW_data_path:\n",
    "  GW_data_path[key] = GW_data_path[key]/file\n",
    "  if not GW_data_path[key].exists():\n",
    "    raise Exception(f\"{key}, {GW_data_path[key]} does not exists!\")\n",
    "radii_list = extract_radii(list(GW_data_path.values())[0])\n",
    "print(radii_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = radii_list[-1]\n",
    "# radius = radii_list[4]\n",
    "GW_data = {}\n",
    "for key in GW_data_path:\n",
    "  GW_data[key] = scri.SpEC.read_from_h5(\n",
    "      f\"{GW_data_path[key]}/R{radius}.dir\",\n",
    "      dataType = scri.h,\n",
    "      frameType = scri.Inertial,\n",
    "      r_is_scaled_out = True,\n",
    "      m_is_scaled_out = True,\n",
    "      )\n",
    "  print(f\"{key} loaded!\")\n",
    "\n",
    "print(GW_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "l, m = 2,2\n",
    "t_max = 2700\n",
    "t_interpolate = np.linspace(1200+int(radius),t_max+int(radius),num=5000)\n",
    "\n",
    "base_key = 'master_Lev5'\n",
    "# base_key = 'master_Lev2'\n",
    "base_key = 'high_accuracy_Lev5'\n",
    "# base_key = 'high_accuracy_Lev2'\n",
    "# base_key = '6_set3_L6s6'\n",
    "# base_key = '6_set3_L6s5'\n",
    "# base_key = '6_set1_L3s3'\n",
    "# base_key = '6_set2_L3s2'\n",
    "base_h = GW_data[base_key].interpolate(t_interpolate)\n",
    "\n",
    "def np_abs_func(x):\n",
    "  return np.abs(np.real(x))\n",
    "  # return np.abs(x)\n",
    "\n",
    "for key in GW_data:\n",
    "  # if 'L6' not in key:\n",
    "  #   continue\n",
    "  if not re.search(r'Lev[3,4,5]',key):\n",
    "    continue\n",
    "  if key == base_key:\n",
    "    continue\n",
    "  h = GW_data[key].interpolate(t_interpolate)\n",
    "  shited_time = h.t - int(radius)\n",
    "  diff = h.data[:, lm(l,m,h.ell_min)] - base_h.data[:, lm(l,m,h.ell_min)]\n",
    "  diff = np_abs_func(diff)\n",
    "  diff_normalize = diff/np_abs_func(base_h.data[:, lm(l,m,h.ell_min)])\n",
    "  plt.plot(shited_time,diff,label=f'{key}_{l=}_{m=}')\n",
    "  # plt.plot(shited_time,diff_normalize,label=f'{key}_rel_{l=}_{m=}')\n",
    "  # plt.plot(shited_time,base_h.data[:, lm(l,m,h.ell_min)],label=f'{key}_rel2_{l=}_{m=}')\n",
    "  # plt.plot(shited_time,np_abs_func(base_h.data[:, lm(l,m,h.ell_min)]),label=f'{key}_rel2_{l=}_{m=}')\n",
    "  # plt.semilogy(h.t,h.energy_flux(),label=f'{key}')\n",
    "\n",
    "plt.title(f\"diff:{base_key}  {l=},{m=}, {radius=}\")\n",
    "plt.xlabel('t')\n",
    "plt.ylabel(\"diff\")\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(Path(\"/home/hchaudha/notes/spec_accuracy/del/LevVariations\")/f\"L05_finite_radius_{base_key}_{l=}_{m=}_{radius}_{t_max=}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# World tube data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_columns(num_cols:int,beta_type=False):\n",
    "  if beta_type:\n",
    "    num_cols = num_cols*2\n",
    "  L_max = int(np.sqrt((num_cols-1)/2))-1\n",
    "  # print(L_max,np.sqrt((num_cols-1)/2)-1)\n",
    "  col_names = ['t(M)']\n",
    "  for l in range(0,L_max+1):\n",
    "    for m in range(-l,l+1):\n",
    "      if beta_type:\n",
    "        if m==0:\n",
    "          col_names.append(f\"Re({l},{m})\")\n",
    "        elif m < 0:\n",
    "          continue\n",
    "        else:\n",
    "          col_names.append(f\"Re({l},{m})\")\n",
    "          col_names.append(f\"Im({l},{m})\")\n",
    "      else:\n",
    "        col_names.append(f\"Re({l},{m})\")\n",
    "        col_names.append(f\"Im({l},{m})\")\n",
    "  return col_names\n",
    "\n",
    "\n",
    "def WT_to_pandas(horizon_path:Path):\n",
    "    assert(horizon_path.exists())\n",
    "    df_dict = {}\n",
    "    beta_type_list = ['Beta.dat', 'DuR.dat', 'R.dat', 'W.dat']\n",
    "    with h5py.File(horizon_path,'r') as hf:\n",
    "        # Not all horizon files may have AhC\n",
    "        for key in hf.keys():\n",
    "            if key == \"VersionHist.ver\":\n",
    "              continue \n",
    "            if key in beta_type_list:\n",
    "              df_dict[key] = pd.DataFrame(hf[key], columns=generate_columns(hf[key].shape[1],beta_type=True))\n",
    "            else:\n",
    "              df_dict[key] = pd.DataFrame(hf[key], columns=generate_columns(hf[key].shape[1]))\n",
    "\n",
    "\n",
    "    return df_dict\n",
    "\n",
    "\n",
    "def create_diff_dict(WT_data_dict:dict, mode:str, variable:str, base_key:str):\n",
    "  diff_dict = {\"t(M)\":WT_data_dict[base_key][variable]['t(M)']}\n",
    "  y_base = WT_data_dict[base_key][variable][mode]\n",
    "  y_norm = np.linalg.norm(y_base)\n",
    "  for key in WT_data_dict:\n",
    "    if key == base_key:\n",
    "      continue\n",
    "    y = WT_data_dict[key][variable][mode]\n",
    "    t = WT_data_dict[key][variable]['t(M)']\n",
    "    y_interpolator = interp1d(t, y, kind='cubic',fill_value='extrapolate')\n",
    "    y_inter = y_interpolator(diff_dict['t(M)'])\n",
    "    diff_dict[key+\"_diff\"] = y_inter-y_base\n",
    "    diff_dict[key+\"_absdiff\"] = np.abs(y_inter-y_base)\n",
    "    diff_dict[key+\"_rel_diff\"] = (y_inter-y_base)/y_norm\n",
    "    diff_dict[key+\"_rel_absdiff\"] = np.abs(y_inter-y_base)/y_norm\n",
    "  return diff_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_data= {}\n",
    "WT_data[\"high_accuracy_Lev0_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev0/BondiCceR0257/BondiCceR0257.h5\")\n",
    "WT_data[\"high_accuracy_Lev1_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev1/BondiCceR0257/BondiCceR0257.h5\")\n",
    "WT_data[\"high_accuracy_Lev2_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev2/BondiCceR0257/BondiCceR0257.h5\")\n",
    "WT_data[\"high_accuracy_Lev3_R0258\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/GW_data_lev3/BondiCceR0258/BondiCceR0258.h5\")\n",
    "WT_data[\"high_accuracy_Lev4_R0258\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/GW_data_lev4/BondiCceR0258/BondiCceR0258.h5\")\n",
    "WT_data[\"high_accuracy_Lev5_R0258\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/GW_data_lev5/BondiCceR0258/BondiCceR0258.h5\")\n",
    "# WT_data[\"master_Lev0_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev/GW_data/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"master_Lev1_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev/GW_data_lev1/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"master_Lev2_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev/GW_data_lev2/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"master_Lev3_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_master/Ev/GW_data_lev3/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"master_Lev4_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_master/Ev/GW_data_lev4/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"master_Lev5_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_master/Ev/GW_data_lev5/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"Lev5_bg_ah100_cd_01_uamr_full_R0258\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_bg_ah100_cd_01_uamr_full/GW_data/BondiCceR0258/BondiCceR0258.h5\")\n",
    "# WT_data[\"Lev5_bg_ah100_cd_01_uamr_full_R0686\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_bg_ah100_cd_01_uamr_full/GW_data/BondiCceR0686/BondiCceR0686.h5\")\n",
    "# WT_data[\"Lev5_bg_ah100_lapse_uamr_fullR0258\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_bg_ah100_lapse_uamr_full/GW_data/BondiCceR0258/BondiCceR0258.h5\")\n",
    "# WT_data[\"Lev5_bg_ah100_lapse_uamr_full_R0100\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_bg_ah100_lapse_uamr_full/GW_data/BondiCceR0100/BondiCceR0100.h5\")\n",
    "# WT_data[\"high_accuracy_Lev5_R0258_ZeroNonSmooth\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/ZeroNonSmooth/red_Lev5_R0258_VolumeData.h5\")\n",
    "# WT_data[\"high_accuracy_Lev5_R0258_NoIncomingRadiation\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/NoIncomingRadiation/red_Lev5_R0258_VolumeData.h5\")\n",
    "# WT_data[\"high_accuracy_Lev5_R0258_InverseCubic\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/InverseCubic/red_Lev5_R0258_VolumeData.h5\")\n",
    "# WT_data[\"high_accuracy_Lev5_R0258_ConformalFactor10\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/ConformalFactor10/red_Lev5_R0258_VolumeData.h5\")\n",
    "# WT_data[\"high_accuracy_Lev5_R0258_ConformalFactor7\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/ConformalFactor7/red_Lev5_R0258_VolumeData.h5\")\n",
    "# WT_data[\"high_accuracy_Lev5_R0258_ConformalFactor3\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/ConformalFactor3/red_Lev5_R0258_VolumeData.h5\")\n",
    "\n",
    "# WT_data[\"Lev01_test_ode_Lev2_257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev2/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"Lev01_test_ode_Lev1_257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev1/BondiCceR0257/BondiCceR0257.h5\")\n",
    "\n",
    "# WT_data[\"Lev01_test_Lev2_257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev/GW_data_lev2/BondiCceR0257/BondiCceR0257.h5\")\n",
    "\n",
    "levs,run_sets,radius= [],[],[]\n",
    "levs = [0,1,2,3,4,5,6]\n",
    "# levs = [4,5,6]\n",
    "# levs = [0,1,2,3]\n",
    "# levs = [0]\n",
    "# run_sets = [1,2,3]\n",
    "# run_sets = [1,3]\n",
    "run_sets = [1]\n",
    "radius = [250]\n",
    "# radius = [100,150,200,250,300,350,500,700,900]\n",
    "# radius = [100,250,900]\n",
    "\n",
    "for l,s,r in itertools.product(levs,run_sets,radius):\n",
    "  if s == 2 and (l == 0 or l==1):\n",
    "    continue\n",
    "  if l <= 3:\n",
    "    WT_data[f\"6_set{s}_L3s{l}_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/6_segs/6_set{s}_L3/GW_data_lev{l}/BondiCceR0{r}/BondiCceR0{r}.h5\")\n",
    "  else:\n",
    "    WT_data[f\"6_set{s}_L6s{l}_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/6_segs/6_set{s}_L6/GW_data_lev{l}/BondiCceR0{r}/BondiCceR0{r}.h5\")\n",
    "\n",
    "\n",
    "fail_flag=False\n",
    "for key in WT_data:\n",
    "  if not WT_data[key].exists():\n",
    "    fail_flag = True\n",
    "    print(f\"{WT_data[key]} does not exist!\")\n",
    "  if fail_flag:\n",
    "    raise Exception(\"Some paths do not exist!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_data_dict = {}\n",
    "for key in WT_data:\n",
    "  WT_data_dict[key] = WT_to_pandas(WT_data[key])\n",
    "  print(f\"{key} loaded!\")\n",
    "\n",
    "print(WT_data_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_plot = ['Beta.dat', 'DrJ.dat', 'DuR.dat', 'H.dat', 'J.dat', 'Q.dat', 'R.dat', 'U.dat', 'W.dat']\n",
    "variables_to_plot = ['DrJ.dat', 'J.dat', 'Q.dat', 'R.dat']\n",
    "variables_to_plot = ['R.dat']\n",
    "\n",
    "modes_to_plot = ['Re(2,2)','Im(2,2)','Re(2,0)']\n",
    "modes_to_plot = ['Re(2,2)']\n",
    "\n",
    "base_key = 'high_accuracy_Lev5_R0258'\n",
    "# base_key = '6_set1_L6s6_250'\n",
    "base_key = '6_set1_L6s6_250'\n",
    "# base_key = '6_set3_L3s3_250'\n",
    "# base_key = '6_set1_L3s2_250'\n",
    "radius = int(base_key[-3:])\n",
    "\n",
    "plot_vals = [\"_diff\",\"_absdiff\",\"_rel_diff\",\"_rel_absdiff\"]\n",
    "plot_vals = [\"_absdiff\",\"_rel_absdiff\"]\n",
    "# plot_vals = [\"_rel_absdiff\"]\n",
    "\n",
    "t_min = -10000\n",
    "# t_min = 2000\n",
    "t_min = 2500\n",
    "t_min = 1190\n",
    "t_min = 1210\n",
    "t_max = 10000\n",
    "# t_max = 7751.5\n",
    "# t_max = 7000\n",
    "t_max = 4000\n",
    "# t_max = 3500\n",
    "\n",
    "\n",
    "\n",
    "num_colors_required = len(list(itertools.product(variables_to_plot,modes_to_plot)))*(len(WT_data_dict)-1)\n",
    "\n",
    "num_colors_required = 0\n",
    "for variable,mode,key in itertools.product(variables_to_plot,modes_to_plot,WT_data_dict):\n",
    "  if key == base_key:\n",
    "    continue\n",
    "  if '250' not in key:\n",
    "    continue\n",
    "  num_colors_required = num_colors_required + 1\n",
    "\n",
    "if num_colors_required <=10:\n",
    "  cmap = plt.get_cmap('tab10')\n",
    "  color = [cmap(i) for i in range(num_colors_required )]\n",
    "elif num_colors_required <=20:\n",
    "  cmap = plt.get_cmap('tab20')\n",
    "  color = [cmap(i) for i in range(num_colors_required )]\n",
    "else:\n",
    "  color=plt.cm.hsv(np.linspace(0, 1, num_colors_required))\n",
    "  # color=plt.cm.gist_rainbow(np.linspace(0, 1, num_colors_required))\n",
    "\n",
    "i=-1\n",
    "plt.close()\n",
    "for variable,mode,key in itertools.product(variables_to_plot,modes_to_plot,WT_data_dict):\n",
    "  if key == base_key:\n",
    "    continue\n",
    "  if '250' not in key:\n",
    "    continue\n",
    "  # if not re.search(r\"Lev[3,4,5]\",key):\n",
    "  #   continue\n",
    "\n",
    "  diff_dict = create_diff_dict(WT_data_dict,variable=variable,mode=mode,base_key=base_key)\n",
    "  t_arr = diff_dict[\"t(M)\"]\n",
    "  trimmed_indices = (t_arr>t_min) & (t_arr<t_max)\n",
    "  t_arr = t_arr[trimmed_indices]\n",
    "\n",
    "  i = i+1\n",
    "  for plot_val in plot_vals:\n",
    "    match plot_val:\n",
    "      case \"_rel_absdiff\":\n",
    "        plt.semilogy(t_arr,diff_dict[key+plot_val][trimmed_indices],label=f\"{key}_{variable}_{mode}\"+plot_val,linestyle=\"-\",color=color[i])\n",
    "      case \"_absdiff\":\n",
    "        # plt.semilogy(t_arr,diff_dict[key+plot_val][trimmed_indices],label=f\"{key}_{variable}_{mode}\"+plot_val,linestyle=\":\",color=color[i])\n",
    "        plt.semilogy(t_arr,diff_dict[key+plot_val][trimmed_indices],linestyle=\":\",color=color[i])\n",
    "      case \"_diff\":\n",
    "        plt.semilogy(t_arr,diff_dict[key+plot_val][trimmed_indices],label=f\"{key}_{variable}_{mode}\"+plot_val,linestyle=\"--\",color=color[i])\n",
    "      case \"_rel_diff\":\n",
    "        plt.semilogy(t_arr,diff_dict[key+plot_val][trimmed_indices],label=f\"{key}_{variable}_{mode}\"+plot_val,linestyle=\"-.\",color=color[i])\n",
    "    \n",
    "\n",
    "    plt.xlabel('t')\n",
    "    plt.ylabel(\"diff\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.title(f\"Diff {base_key}\")\n",
    "    # plt.show()\n",
    "    # plt.savefig(Path(\"/home/hchaudha/notes/spec_accuracy/CCE/new_set_L3\")/f\"violations_alllll_{bondi_norms_to_plot}_t={t_min}-{t_max}.png\")\n",
    "    # plt.savefig(Path(\"/home/hchaudha/notes/spec_accuracy/CCE/\")/f\"{bondi_norms_to_plot}_t={t_min}-{t_max}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No base diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_plot = ['Beta.dat', 'DrJ.dat', 'DuR.dat', 'H.dat', 'J.dat', 'Q.dat', 'R.dat', 'U.dat', 'W.dat']\n",
    "# variables_to_plot = ['Beta.dat']\n",
    "\n",
    "l,m = 2,2\n",
    "modes_to_plot = ['Re(2,2)','Im(2,2)','Re(2,0)']\n",
    "modes_to_plot = ['Re(2,2)']\n",
    "\n",
    "t_min = -10000\n",
    "# t_min = 2000\n",
    "t_min = 2500\n",
    "t_min = 1200\n",
    "t_max = 10000\n",
    "# t_max = 7751.5\n",
    "# t_max = 7000\n",
    "t_max = 4000\n",
    "t_max = 3500\n",
    "\n",
    "labels = None\n",
    "# labels={\n",
    "# #  \"high_accuracy_Lev5_R0258\" : \"Lev5_ode_tol_R0258\",\n",
    "#  \"6_set1_L3s3_200\" : \"Lev3_variant_R0200\",\n",
    "#  \"6_set1_L3s3_250\" : \"Lev3_variant_R0250\",\n",
    "#  \"6_set1_L3s3_300\" : \"Lev3_variant_R0300\",\n",
    "#  \"6_set1_L3s2_200\" : \"Lev2_variant_R0200\",\n",
    "#  \"6_set1_L3s2_250\" : \"Lev2_variant_R0250\",\n",
    "#  \"6_set1_L3s2_300\" : \"Lev2_variant_R0300\",\n",
    "# }\n",
    "\n",
    "for key in WT_data_dict:\n",
    "  data_dict = WT_data_dict[key]\n",
    "  if \"s3\" not in key:\n",
    "    continue\n",
    "\n",
    "  t_arr = data_dict[variables_to_plot[0]][\"t(M)\"]\n",
    "  trimmed_indices = (t_arr>t_min) & (t_arr<t_max)\n",
    "  t_arr = t_arr[trimmed_indices]\n",
    "\n",
    "  for i,mode in itertools.product(variables_to_plot, modes_to_plot):\n",
    "    if labels is None:\n",
    "      plt.plot(t_arr,data_dict[i][mode][trimmed_indices],label=f\"{key}_{i}_{mode}\")\n",
    "    else:\n",
    "      plt.plot(t_arr,data_dict[i][mode][trimmed_indices],label=f\"{labels[key]}_{i}_{mode}\")\n",
    "\n",
    "  plt.xlabel('t')\n",
    "  plt.legend()\n",
    "  plt.tight_layout()\n",
    "  # plt.show()\n",
    "  # plt.savefig(Path(\"/home/hchaudha/notes/spec_accuracy/CCE/new_set_L3\")/f\"violations_alllll_{bondi_norms_to_plot}_t={t_min}-{t_max}.png\")\n",
    "  # plt.savefig(Path(\"/home/hchaudha/notes/spec_accuracy/CCE/\")/f\"{bondi_norms_to_plot}_t={t_min}-{t_max}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WT data modes plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modes vs time plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_regex(regex,col_list,exclude=False):\n",
    "  filtered_set = set()\n",
    "  if type(regex) is list:\n",
    "    for reg in regex:\n",
    "      for i in col_list:\n",
    "        if re.search(reg,i):\n",
    "          filtered_set.add(i)\n",
    "  else:\n",
    "    for i in col_list:\n",
    "      if re.search(regex,i):\n",
    "        filtered_set.add(i)\n",
    "\n",
    "  filtered_list = list(filtered_set)\n",
    "  if exclude:\n",
    "    col_list_copy = list(col_list.copy())\n",
    "    for i in filtered_list:\n",
    "      if i in col_list_copy:\n",
    "        col_list_copy.remove(i)\n",
    "    filtered_list = col_list_copy\n",
    "\n",
    "  # Restore the original order\n",
    "  filtered_original_ordered_list = []\n",
    "  for i in list(col_list):\n",
    "    if i in filtered_list:\n",
    "      filtered_original_ordered_list.append(i)\n",
    "  return filtered_original_ordered_list\n",
    "\n",
    "def limit_by_col_val(min_val,max_val,col_name,df):\n",
    "  filter = (df[col_name]>=min_val) &(df[col_name] <=max_val)\n",
    "  return df[filter]\n",
    "\n",
    "def abs_mean_value_upto_l(pd_series,L_max:int):\n",
    "  idx = pd_series.index\n",
    "  abs_cum_sum = 0\n",
    "  num = 0\n",
    "  for i in idx:\n",
    "    L = int(i.split(\",\")[0][3:])\n",
    "    if L > L_max:\n",
    "      continue\n",
    "    else:\n",
    "      abs_cum_sum = abs_cum_sum+abs(pd_series[i])\n",
    "      num = num +1\n",
    "  return abs_cum_sum/num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_data= {}\n",
    "# WT_data[\"high_accuracy_Lev0_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev0/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"high_accuracy_Lev1_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev1/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"high_accuracy_Lev2_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev2/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"high_accuracy_Lev3_R0258\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/GW_data_lev3/BondiCceR0258/BondiCceR0258.h5\")\n",
    "# WT_data[\"high_accuracy_Lev4_R0258\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/GW_data_lev4/BondiCceR0258/BondiCceR0258.h5\")\n",
    "# WT_data[\"high_accuracy_Lev5_R0258\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/GW_data_lev5/BondiCceR0258/BondiCceR0258.h5\")\n",
    "# WT_data[\"master_Lev0_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev/GW_data/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"master_Lev1_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev/GW_data_lev1/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"master_Lev2_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev/GW_data_lev2/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"master_Lev3_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_master/Ev/GW_data_lev3/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"master_Lev4_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_master/Ev/GW_data_lev4/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"master_Lev5_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_master/Ev/GW_data_lev5/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"Lev5_bg_ah100_cd_01_uamr_full_R0258\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_bg_ah100_cd_01_uamr_full/GW_data/BondiCceR0258/BondiCceR0258.h5\")\n",
    "# WT_data[\"Lev5_bg_ah100_cd_01_uamr_full_R0686\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_bg_ah100_cd_01_uamr_full/GW_data/BondiCceR0686/BondiCceR0686.h5\")\n",
    "# WT_data[\"Lev5_bg_ah100_lapse_uamr_fullR0258\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_bg_ah100_lapse_uamr_full/GW_data/BondiCceR0258/BondiCceR0258.h5\")\n",
    "# WT_data[\"Lev5_bg_ah100_lapse_uamr_full_R0100\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_bg_ah100_lapse_uamr_full/GW_data/BondiCceR0100/BondiCceR0100.h5\")\n",
    "# WT_data[\"high_accuracy_Lev5_R0258_ZeroNonSmooth\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/ZeroNonSmooth/red_Lev5_R0258_VolumeData.h5\")\n",
    "# WT_data[\"high_accuracy_Lev5_R0258_NoIncomingRadiation\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/NoIncomingRadiation/red_Lev5_R0258_VolumeData.h5\")\n",
    "# WT_data[\"high_accuracy_Lev5_R0258_InverseCubic\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/InverseCubic/red_Lev5_R0258_VolumeData.h5\")\n",
    "# WT_data[\"high_accuracy_Lev5_R0258_ConformalFactor10\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/ConformalFactor10/red_Lev5_R0258_VolumeData.h5\")\n",
    "# WT_data[\"high_accuracy_Lev5_R0258_ConformalFactor7\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/ConformalFactor7/red_Lev5_R0258_VolumeData.h5\")\n",
    "# WT_data[\"high_accuracy_Lev5_R0258_ConformalFactor3\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/ConformalFactor3/red_Lev5_R0258_VolumeData.h5\")\n",
    "\n",
    "# WT_data[\"Lev01_test_ode_Lev2_257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev2/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"Lev01_test_ode_Lev1_257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev1/BondiCceR0257/BondiCceR0257.h5\")\n",
    "\n",
    "# WT_data[\"Lev01_test_Lev2_257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev/GW_data_lev2/BondiCceR0257/BondiCceR0257.h5\")\n",
    "\n",
    "levs,run_sets,radius= [],[],[]\n",
    "levs = [0,1,2,3]\n",
    "# levs = [4,5,6]\n",
    "# levs = [0,1,2,3]\n",
    "levs = [6]\n",
    "# run_sets = [1,2,3]\n",
    "# run_sets = [1,3]\n",
    "run_sets = [1]\n",
    "# radius = [250]\n",
    "radius = [100,150,200,250,300,350,500,700,900]\n",
    "# radius = [100,250,900]\n",
    "\n",
    "for l,s,r in itertools.product(levs,run_sets,radius):\n",
    "  if s == 2 and (l == 0 or l==1):\n",
    "    continue\n",
    "  if l <= 3:\n",
    "    WT_data[f\"6_set{s}_L3s{l}_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/6_segs/6_set{s}_L3/GW_data_lev{l}/BondiCceR0{r}/BondiCceR0{r}.h5\")\n",
    "  else:\n",
    "    WT_data[f\"6_set{s}_L6s{l}_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/6_segs/6_set{s}_L6/GW_data_lev{l}/BondiCceR0{r}/BondiCceR0{r}.h5\")\n",
    "\n",
    "\n",
    "fail_flag=False\n",
    "for key in WT_data:\n",
    "  if not WT_data[key].exists():\n",
    "    fail_flag = True\n",
    "    print(f\"{WT_data[key]} does not exist!\")\n",
    "  if fail_flag:\n",
    "    raise Exception(\"Some paths do not exist!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_data_dict = {}\n",
    "for key in WT_data:\n",
    "  WT_data_dict[key] = WT_to_pandas(WT_data[key])\n",
    "  print(f\"{key} loaded!\")\n",
    "\n",
    "print(WT_data_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = WT_data_dict['6_set1_L3s0_250']['Beta.dat']\n",
    "data2 = WT_data_dict['6_set1_L3s3_250']['Beta.dat']\n",
    "diff = data2 - data1\n",
    "diff['t(M)'] = data2['t(M)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = WT_data_dict['6_set1_L3s0_250']['W.dat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minT = 0\n",
    "minT = 1200\n",
    "\n",
    "maxT = 40000\n",
    "maxT = 4000\n",
    "data1 = limit_by_col_val(minT,maxT,'t(M)',data1)\n",
    "data = limit_by_col_val(minT,maxT,'t(M)',diff)\n",
    "\n",
    "min_clip_val = 1e-25\n",
    "\n",
    "domain_col_list = filter_by_regex(regex=[\"Re\"],col_list=data.columns)\n",
    "domain_col_list = filter_by_regex(regex=[r\"Re\\(\\d6\"],col_list=domain_col_list)\n",
    "\n",
    "visual_data = data[domain_col_list]\n",
    "visual_data = np.abs(visual_data)\n",
    "min_val = visual_data.min().min()\n",
    "print(f\"Minimum value in the filtered data: {min_val}\")\n",
    "if min_val < min_clip_val:\n",
    "  print(f\"Min value is too small {min_val}, clipping at {min_clip_val}\")\n",
    "  small_number_mask = visual_data < min_clip_val\n",
    "  visual_data[small_number_mask] = min_clip_val\n",
    "visual_data = np.log10(visual_data)\n",
    "\n",
    "column_names = list(visual_data.columns)\n",
    "\n",
    "vmin_log,vmax_log = -11,-1\n",
    "vmin_log,vmax_log = None,None\n",
    "if vmin_log is None:\n",
    "  vmin_log = visual_data.min().min()\n",
    "if vmax_log is None:\n",
    "  vmax_log = visual_data.max().max()\n",
    "\n",
    "print(vmin_log,vmax_log)\n",
    "\n",
    "plt.figure(figsize=(45, 10))\n",
    "imshow_plot = plt.imshow(\n",
    "    visual_data[column_names], \n",
    "    aspect='auto', \n",
    "    # cmap='RdYlGn_r', \n",
    "    cmap='viridis', \n",
    "    origin='lower',\n",
    "    vmin=vmin_log, \n",
    "    vmax=vmax_log\n",
    ")\n",
    "\n",
    "plt.xticks(\n",
    "    ticks=np.arange(len(visual_data.columns)), \n",
    "    labels=[i.split(\" \")[-1] for i in column_names], \n",
    "    rotation=90\n",
    ")\n",
    "\n",
    "ytick_step = len(data) // 10  # Show about 10 ticks\n",
    "plt.yticks(\n",
    "    ticks=np.arange(0, len(data), ytick_step), \n",
    "    labels=data['t(M)'][::ytick_step].astype(int)\n",
    ")\n",
    "\n",
    "colorbar = plt.colorbar(imshow_plot)\n",
    "\n",
    "plt.ylabel('t(M)')\n",
    "plt.title(f'{key}')\n",
    "plt.tight_layout()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean/Max of modes over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_dict = {}\n",
    "L_max_for_mean = 50\n",
    "variables = ['Beta.dat', 'DrJ.dat', 'DuR.dat', 'H.dat', 'J.dat', 'Q.dat', 'R.dat', 'U.dat', 'W.dat']\n",
    "variables = ['H.dat', 'R.dat']\n",
    "variables = ['H.dat']\n",
    "r1 = '100'\n",
    "# run_keys = [f'6_set1_L6s6_{r1}']\n",
    "# run_keys = [f'6_set1_L6s5_{r1}']\n",
    "# run_keys = [f'6_set1_L6s4_{r1}',f'6_set1_L6s5_{r1}',f'6_set1_L6s6_{r1}']\n",
    "run_keys = [f'6_set1_L3s0_{r1}',f'6_set1_L3s1_{r1}',f'6_set1_L3s2_{r1}',f'6_set1_L3s3_{r1}']\n",
    "r1='250'\n",
    "run_keys = run_keys+[f'6_set1_L3s0_{r1}',f'6_set1_L3s1_{r1}',f'6_set1_L3s2_{r1}',f'6_set1_L3s3_{r1}']\n",
    "r1='900'\n",
    "run_keys = run_keys+[f'6_set1_L3s0_{r1}',f'6_set1_L3s1_{r1}',f'6_set1_L3s2_{r1}',f'6_set1_L3s3_{r1}']\n",
    "run_keys = WT_data_dict.keys()\n",
    "# run_keys = ['high_accuracy_Lev0_R0257', 'high_accuracy_Lev1_R0257', 'high_accuracy_Lev2_R0257',]\n",
    "# run_keys = ['high_accuracy_Lev3_R0258', 'high_accuracy_Lev4_R0258', 'high_accuracy_Lev5_R0258',]\n",
    "\n",
    "minT = 0\n",
    "minT = 3200\n",
    "\n",
    "maxT = 40000\n",
    "maxT = 4000\n",
    "\n",
    "reduced_dict = {}\n",
    "flattened_dict = {}\n",
    "for run_key in run_keys:\n",
    "\n",
    "  column_names = None\n",
    "  reduced_dict[run_key] = {}\n",
    "\n",
    "  for var in variables:\n",
    "\n",
    "    data = limit_by_col_val(minT,maxT,'t(M)',WT_data_dict[run_key][var])\n",
    "\n",
    "    domain_col_list = filter_by_regex(regex=[\"Re\"],col_list=data.columns)\n",
    "    domain_col_list = filter_by_regex(regex=[r\"Re\\(\\d\\d?,\\d\\d?\\)\"],col_list=domain_col_list)\n",
    "    # domain_col_list = filter_by_regex(regex=[r\"Re\\(\\d\\d,\\d\\d?\\)\"],col_list=domain_col_list)\n",
    "\n",
    "    if column_names is None and var == \"R.dat\":\n",
    "      column_names = domain_col_list\n",
    "\n",
    "    visual_data = data[domain_col_list]\n",
    "    visual_data = np.abs(visual_data)\n",
    "    min_val = visual_data.min().min()\n",
    "    # print(f\"Minimum value in the filtered data: {min_val}\")\n",
    "\n",
    "    reduced_dict[run_key][var] = {\n",
    "      \"mean\" : visual_data.mean(),\n",
    "      \"rel_mean\" : visual_data.mean()/abs_mean_value_upto_l( visual_data.mean(),L_max_for_mean),\n",
    "      # \"run_mean\" : visual_data.mean().cumsum()/range(1,1+len( visual_data.mean())),\n",
    "      \"max\" : visual_data.max(),\n",
    "      \"rel_max\" : visual_data.max()/abs_mean_value_upto_l( visual_data.max(),L_max_for_mean),\n",
    "      # \"run_max\" : visual_data.max().cumsum()/range(1,1+len( visual_data.max())),\n",
    "    }\n",
    "\n",
    "\n",
    "  for key,val in reduced_dict[run_key].items():\n",
    "    for key1,val1 in val.items():\n",
    "      flattened_dict[f\"{key[:-4]}_{key1}_{run_key}\"] = val1\n",
    "\n",
    "sorted_keys = sorted(flattened_dict.keys())\n",
    "flattened_dict = {key: flattened_dict[key] for key in sorted_keys}\n",
    "\n",
    "df = None\n",
    "for key,val in flattened_dict.items():\n",
    "  if df is None:\n",
    "    df = pd.DataFrame([val],index=[key])\n",
    "  else:\n",
    "    df = pd.concat([df,pd.DataFrame([val],index=[key])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfT = df.T\n",
    "for col in dfT.columns:\n",
    "  if \"max\" not in col:\n",
    "    continue\n",
    "  if \"rel_\" in col:\n",
    "    continue\n",
    "  plt.plot(dfT[col],label = col)\n",
    "\n",
    "plt.title(f'{run_key} t(M)={minT},{maxT}')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.grid(False)\n",
    "plt.yscale('log')\n",
    "plt.xticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = dfT.columns\n",
    "cols_new = [i for i in cols if \"run_max\" in i]\n",
    "a = np.arange(1,len(cols_new)+1)\n",
    "one_over_x = 2.8e-7/a\n",
    "\n",
    "plt.plot(dfT[cols_new].loc['Re(16,16)'])\n",
    "plt.plot(one_over_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mode(name):\n",
    "  return int(name.split(\"(\")[-1].split(\")\")[0])\n",
    "def get_radii(name):\n",
    "  return int(name.split('_')[-1])\n",
    "def sort_by_power_modes(col_names):\n",
    "  col_name_copy = list(col_names).copy()\n",
    "  return sorted(col_name_copy, key=lambda x: int(get_mode(x)))\n",
    "\n",
    "def add_L_mode_power(df:pd.DataFrame,L:int, ReOrIm:str):\n",
    "  column_names = df.columns\n",
    "\n",
    "  n = 0\n",
    "  power = 0\n",
    "  for m in range(-L,L+1):\n",
    "    col_name = f'{ReOrIm}({L},{m})'\n",
    "    # print(col_name)\n",
    "    if col_name in column_names:\n",
    "      power = power + df[col_name]*df[col_name]\n",
    "      n = n + 1\n",
    "  if n != 0:\n",
    "    power = power/n\n",
    "    df[f'pow_{ReOrIm}({L})'] = power\n",
    "  return power\n",
    "\n",
    "def add_all_L_mode_power(df:pd.DataFrame,L_max:int):\n",
    "  local_df = df.copy()\n",
    "  total_power_Re = 0\n",
    "  total_power_Im = 0\n",
    "  for l in range(0,L_max+1):\n",
    "    total_power_Re = total_power_Re + add_L_mode_power(local_df,l,\"Re\")\n",
    "    total_power_Im = total_power_Im + add_L_mode_power(local_df,l,\"Im\")\n",
    "    local_df[f\"pow_cum_Re({l})\"] = total_power_Re\n",
    "    local_df[f\"pow_cum_Im({l})\"] = total_power_Im\n",
    "  return local_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_dict = {}\n",
    "L_max_for_mean = 50\n",
    "variables = ['Beta.dat', 'DrJ.dat', 'DuR.dat', 'H.dat', 'J.dat', 'Q.dat', 'R.dat', 'U.dat', 'W.dat']\n",
    "variables = ['H.dat', 'R.dat']\n",
    "variables = ['Beta.dat']\n",
    "# r1 = '100'\n",
    "# run_keys = [f'6_set1_L6s6_{r1}']\n",
    "# run_keys = [f'6_set1_L6s5_{r1}']\n",
    "# run_keys = [f'6_set1_L6s4_{r1}',f'6_set1_L6s5_{r1}',f'6_set1_L6s6_{r1}']\n",
    "# run_keys = [f'6_set1_L3s0_{r1}',f'6_set1_L3s1_{r1}',f'6_set1_L3s2_{r1}',f'6_set1_L3s3_{r1}']\n",
    "# r1='250'\n",
    "# run_keys = run_keys+[f'6_set1_L3s0_{r1}',f'6_set1_L3s1_{r1}',f'6_set1_L3s2_{r1}',f'6_set1_L3s3_{r1}']\n",
    "# r1='900'\n",
    "# run_keys = run_keys+[f'6_set1_L3s0_{r1}',f'6_set1_L3s1_{r1}',f'6_set1_L3s2_{r1}',f'6_set1_L3s3_{r1}']\n",
    "run_keys = WT_data_dict.keys()\n",
    "# run_keys = ['high_accuracy_Lev0_R0257', 'high_accuracy_Lev1_R0257', 'high_accuracy_Lev2_R0257',]\n",
    "# run_keys = ['high_accuracy_Lev3_R0258', 'high_accuracy_Lev4_R0258', 'high_accuracy_Lev5_R0258',]\n",
    "\n",
    "minT = 0\n",
    "minT = 3200\n",
    "\n",
    "maxT = 40000\n",
    "maxT = 4000\n",
    "\n",
    "power_dict = {}\n",
    "flattened_dict = {}\n",
    "for run_key in run_keys:\n",
    "\n",
    "  column_names = None\n",
    "  power_dict[run_key] = {}\n",
    "\n",
    "  for var in variables:\n",
    "\n",
    "    data = limit_by_col_val(minT,maxT,'t(M)',WT_data_dict[run_key][var])\n",
    "\n",
    "    power_dict[run_key][var] = add_all_L_mode_power(data,16)\n",
    "  \n",
    "  for key,val in power_dict[run_key].items():\n",
    "    for key1,val1 in val.items():\n",
    "      if \"pow\" in key1:\n",
    "        flattened_dict[f\"{key[:-4]}_{key1}_{run_key}\"] = val1\n",
    "\n",
    "sorted_keys = sort_by_power_modes(flattened_dict.keys())\n",
    "flattened_dict = {key: flattened_dict[key] for key in sorted_keys}\n",
    "flattened_dict['t(M)'] = val['t(M)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "minY,maxY = 1e-40,1e-10\n",
    "avg_len = 1\n",
    "# avg_len = 1000\n",
    "\n",
    "last_val_list = []\n",
    "r_list = [100,150,200,250,300,350,500,700,900]\n",
    "r_list = [250]\n",
    "L_list =  [0,1,2,3,4,5,6]\n",
    "L_list =  list(range(0,17))\n",
    "\n",
    "for col in flattened_dict:\n",
    "  if 'cum_' in col:\n",
    "    continue\n",
    "  if 'Re' not in col:\n",
    "    continue\n",
    "  # if 't(M)' == col:\n",
    "  #   continue\n",
    "  L = get_mode(col)\n",
    "  r = get_radii(col)\n",
    "  # if \"pow_Re\" not in col:\n",
    "  #   continue\n",
    "  if (r not in r_list) or (L not in L_list):\n",
    "    continue\n",
    "\n",
    "  x = flattened_dict['t(M)'][avg_len-1:]\n",
    "  y = moving_average_valid(flattened_dict[col],avg_len=avg_len)\n",
    "  last_val_list.append(y[-1])\n",
    "  plt.plot(x,y,label = col)\n",
    "\n",
    "plt.title(f'Power in modes, var={variables}, avg_len={avg_len}')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.grid(False)\n",
    "plt.yscale('log')\n",
    "plt.ylabel(f\"Power in modes\")\n",
    "# plt.ylim((minY,maxY))\n",
    "plt.xlabel(\"t(M)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(L_list, last_val_list)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "one_over_x = last_val_list[0]*1e2/np.array(r_list)\n",
    "one_over_x2 = last_val_list[0]*1e4/np.array(r_list)**2\n",
    "\n",
    "# Define the fitting function\n",
    "def fitting_func(r, a, b):\n",
    "    return a / r**b\n",
    "popt, pcov = curve_fit(fitting_func, r_list, last_val_list,p0=[last_val_list[0],2])\n",
    "a_fit, b_fit = popt\n",
    "\n",
    "# Create a smooth curve for the fitted function\n",
    "fit_vals = fitting_func(r_list, a_fit, b_fit)\n",
    "\n",
    "plt.plot(r_list,last_val_list, label=f\"power in mode L={L_list}\",marker='x')\n",
    "# plt.plot(r_list,one_over_x, label=\"1/x\",marker='x')\n",
    "# plt.plot(r_list,one_over_x2, label=\"1/(x*x)\",marker='x')\n",
    "plt.plot(r_list,fit_vals,label=f'Fit: a/r^b, a={a_fit:.2e}, b={b_fit:.2f}', linestyle='--')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.xlabel('r(M)')\n",
    "plt.ylabel('power in modes')\n",
    "plt.title(f\"L={L_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_dict['Beta_pow_cum_1_Re_6_set1_L6s6_900']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflog10 = df.copy()\n",
    "\n",
    "# Some values are zero need to deal with those\n",
    "# min_clip_val = 1e-25\n",
    "# if min_val < min_clip_val:\n",
    "#   print(f\"Min value in {var} is too small {min_val}, clipping at {min_clip_val}\")\n",
    "#   small_number_mask = visual_data < min_clip_val\n",
    "#   visual_data[small_number_mask] = min_clip_val\n",
    "    # visual_data = np.log10(visual_data)\n",
    "\n",
    "vmin_log,vmax_log = -11,-1\n",
    "vmin_log,vmax_log = None,None\n",
    "if vmin_log is None:\n",
    "  vmin_log = dflog10.min().min()\n",
    "if vmax_log is None:\n",
    "  vmax_log = dflog10.max().max()\n",
    "\n",
    "print(vmin_log,vmax_log)\n",
    "\n",
    "plt.figure(figsize=(45, 10))\n",
    "imshow_plot = plt.imshow(\n",
    "    dflog10[column_names], \n",
    "    aspect='auto', \n",
    "    cmap='RdYlGn_r', \n",
    "    # cmap='viridis', \n",
    "    origin='lower',\n",
    "    vmin=vmin_log, \n",
    "    vmax=vmax_log\n",
    ")\n",
    "\n",
    "plt.xticks(\n",
    "    ticks=np.arange(len(dflog10.columns)), \n",
    "    labels=[i.split(\" \")[-1] for i in column_names], \n",
    "    rotation=90\n",
    ")\n",
    "\n",
    "\n",
    "plt.yticks(\n",
    "    ticks=np.arange(0, len(dflog10.index)), \n",
    "    labels=dflog10.index\n",
    ")\n",
    "\n",
    "colorbar = plt.colorbar(imshow_plot)\n",
    "\n",
    "# plt.ylabel('t(M)')\n",
    "plt.title(f'{run_key} t(M)={minT},{maxT}')\n",
    "plt.tight_layout()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cce_data = Path(\"/groups/sxs/hchaudha/spec_runs/CCE_stuff/CceExecutables/CharacteristicExtractReduction.h5\")\n",
    "cce_data = Path(\"/groups/sxs/hchaudha/spec_runs/CCE_stuff/tests/CharacteristicExtractReduction.h5\")\n",
    "cce_data = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/cce_bondi/Lev0_R0257/red_Lev0_R0257_VolumeData.h5\")\n",
    "# cce_data = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev3_R0258/red_Lev3_R0258_VolumeData.h5\")\n",
    "# cce_data = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev4_R0258/red_Lev4_R0258_VolumeData.h5\")\n",
    "# cce_data = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_R0258/red_Lev5_R0258_VolumeData.h5\")\n",
    "# cce_data = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_master/cce_bondi/Lev5_R0257/red_Lev5_R0257_VolumeData.h5\")\n",
    "# cce_data = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_bg_ah100_cd_01_uamr_full/GW_data/BondiCceR0258/red_cce.h5\")\n",
    "# cce_data = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_bg_ah100_cd_01_uamr_full/GW_data/BondiCceR0686/red_cce.h5\")\n",
    "# cce_data = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_bg_ah100_lapse_uamr_full/GW_data/BondiCceR0258/red_cce.h5\")\n",
    "# cce_data = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_bg_ah100_lapse_uamr_full/GW_data/BondiCceR0100/red_cce.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "abd = scri.create_abd_from_h5(\n",
    "      file_name=str(cce_data),\n",
    "      file_format=\"spectrecce_v1\",\n",
    "      # ch_mass=1.0,  # Optional; helpful if known\n",
    "      t_interpolate=np.linspace(-1000,10000,num=5000),  # Optional; for some specified values of `t_worldtube`\n",
    "      # t_0_superrest=3000,\n",
    "      # padding_time=400\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = abd.h\n",
    "l,m=2,2\n",
    "# l,m=1,1\n",
    "print(lm(l,m,h.ell_min))\n",
    "time_cut = 34500\n",
    "plt.plot(h.t[h.t<time_cut], h.data[:,  lm(l,m,h.ell_min)][h.t<time_cut])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violations2 = abd.bianchi_2()\n",
    "diff_abs = (violations2[1] - violations2[0]).norm()\n",
    "diff_rel = diff_abs/(violations2[0].norm())\n",
    "h.data.shape,violations2[0].shape,diff_abs.shape,diff_rel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(abd.t,diff_abs,label=f\"diff_abs\")\n",
    "plt.semilogy(abd.t,diff_rel,label=f\"diff_rel\")\n",
    "plt.ylabel(\"bianchi2\")\n",
    "plt.xlabel(\"t\")\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = cce_data.parent/\"violations\"\n",
    "save_folder.mkdir(exist_ok=True)\n",
    "for l in range(8):\n",
    "  for m in range(-l,l+1):\n",
    "    print(l,m)\n",
    "    plt.semilogy(abd.t,diff_abs[:, lm(l,m,h.ell_min)],label=f\"l,m={l},{m}\")\n",
    "    plt.ylabel(\"bianchi2\")\n",
    "    plt.xlabel(\"t\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{save_folder}/l,m={l},{m}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = cce_data.parent/\"violations\"\n",
    "save_folder.mkdir(exist_ok=True)\n",
    "for l in range(8):\n",
    "  for m in range(-l,l+1):\n",
    "    print(l,m)\n",
    "    plt.semilogy(abd.t,diff_rel[:, lm(l,m,h.ell_min)],label=f\"l,m={l},{m}\")\n",
    "    plt.ylabel(\"bianchi2\")\n",
    "    plt.xlabel(\"t\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{save_folder}/rel_l,m={l},{m}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norms = np.linalg.norm(diff, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(abd.t,norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violations = abd.bondi_violation_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violation_dict = {\n",
    "  't': abd.t,\n",
    "  '0': violations[0],\n",
    "  '1': violations[1],\n",
    "  '2': violations[2],\n",
    "  '3': violations[3],\n",
    "  '4': violations[4],\n",
    "  '5': violations[5]\n",
    "}\n",
    "\n",
    "# with open(cce_data.parent/\"violation_dict.pkl\",'wb') as f:\n",
    "#   pickle.dump(violation_dict,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n",
    "plt.semilogy(violation_dict['t'],violation_dict['5'],linestyle='--',label='5',color=colors[5])\n",
    "plt.semilogy(violation_dict['t'],violation_dict['4'],linestyle='--',label='4',color=colors[4])\n",
    "plt.semilogy(violation_dict['t'],violation_dict['3'],linestyle='--',label='3',color=colors[3])\n",
    "plt.semilogy(violation_dict['t'],violation_dict['2'],linestyle='--',label='2',color=colors[2])\n",
    "plt.semilogy(violation_dict['t'],violation_dict['1'],linestyle='--',label='1',color=colors[1])\n",
    "plt.semilogy(violation_dict['t'],violation_dict['0'],linestyle='--',label='0',color=colors[0])\n",
    "\n",
    "plt.xlabel('t')\n",
    "plt.ylabel(\"violations\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(cce_data.parent/\"violations.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violations[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violation_dict = {\n",
    "  't': abd.t,\n",
    "  '0': violations[0],\n",
    "  '1': violations[1],\n",
    "  '2': violations[2],\n",
    "  '3': violations[3],\n",
    "  '4': violations[4],\n",
    "  '5': violations[5]\n",
    "}\n",
    "\n",
    "violation_dict2 = data['Lev5']['0258']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "minT = violation_dict['t'].min()\n",
    "maxT = violation_dict['t'].max()\n",
    "print(f\"{minT=}, {maxT=}\")\n",
    "mask = (violation_dict2['t'] < maxT) & (violation_dict2['t']  > minT)\n",
    "# maxT = 200\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n",
    "plt.semilogy(violation_dict2['t'][mask],violation_dict2['5'][mask],label='5', color=colors[5])\n",
    "plt.semilogy(violation_dict2['t'][mask],violation_dict2['4'][mask],label='4', color=colors[4])\n",
    "plt.semilogy(violation_dict2['t'][mask],violation_dict2['3'][mask],label='3', color=colors[3])\n",
    "plt.semilogy(violation_dict2['t'][mask],violation_dict2['2'][mask],label='2', color=colors[2])\n",
    "plt.semilogy(violation_dict2['t'][mask],violation_dict2['1'][mask],label='1', color=colors[1])\n",
    "plt.semilogy(violation_dict2['t'][mask],violation_dict2['0'][mask],label='0', color=colors[0])\n",
    "\n",
    "plt.semilogy(violation_dict['t'],violation_dict['5'],linestyle='--',label='2200_5',color=colors[5])\n",
    "plt.semilogy(violation_dict['t'],violation_dict['4'],linestyle='--',label='2200_4',color=colors[4])\n",
    "plt.semilogy(violation_dict['t'],violation_dict['3'],linestyle='--',label='2200_3',color=colors[3])\n",
    "plt.semilogy(violation_dict['t'],violation_dict['2'],linestyle='--',label='2200_2',color=colors[2])\n",
    "plt.semilogy(violation_dict['t'],violation_dict['1'],linestyle='--',label='2200_1',color=colors[1])\n",
    "plt.semilogy(violation_dict['t'],violation_dict['0'],linestyle='--',label='2200_0',color=colors[0])\n",
    "\n",
    "plt.xlabel('t')\n",
    "plt.ylabel(\"violations\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "minT = violation_dict2['t'].min()\n",
    "maxT = violation_dict2['t'].max()\n",
    "print(f\"{minT=}, {maxT=}\")\n",
    "mask = (violation_dict2['t'] < maxT) & (violation_dict2['t']  > minT)\n",
    "# maxT = 200\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n",
    "plt.semilogy(violation_dict2['t'][mask],violation_dict2['5'][mask],label='5', color=colors[5])\n",
    "plt.semilogy(violation_dict2['t'][mask],violation_dict2['4'][mask],label='4', color=colors[4])\n",
    "plt.semilogy(violation_dict2['t'][mask],violation_dict2['3'][mask],label='3', color=colors[3])\n",
    "plt.semilogy(violation_dict2['t'][mask],violation_dict2['2'][mask],label='2', color=colors[2])\n",
    "plt.semilogy(violation_dict2['t'][mask],violation_dict2['1'][mask],label='1', color=colors[1])\n",
    "plt.semilogy(violation_dict2['t'][mask],violation_dict2['0'][mask],label='0', color=colors[0])\n",
    "\n",
    "plt.xlabel('t')\n",
    "plt.ylabel(\"violations\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bondi_violations_dicts = list(main_folder.glob(\"*Lev*/bondi*\"))\n",
    "bondi_violations_dicts = list(main_folder.glob(\"Lev5_R0258/bondi*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bondi_violations_dicts.sort()\n",
    "bondi_violations_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "data = {\n",
    "  \"Lev3\":{},\n",
    "  \"Lev4\":{},\n",
    "  \"Lev5\":{},\n",
    "  \"Lev5_old\":{}\n",
    "}\n",
    "for file in bondi_violations_dicts:\n",
    "  with file.open('rb') as f:\n",
    "    lev = str(file).split(\"/\")[-2][3]\n",
    "    radius = str(file).split(\"/\")[-2][-4:]\n",
    "    if radius == \"_old\":\n",
    "      lev = lev+\"_old\"\n",
    "      radius = str(file).split(\"/\")[-2][-8:-4]\n",
    "    print(lev,radius)\n",
    "    data[\"Lev\"+lev][radius] = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levs = data.keys()\n",
    "\n",
    "\n",
    "bondi_violation = '2'\n",
    "minT = 220\n",
    "maxT = 7200\n",
    "# maxT = 200\n",
    "RADISU = 200\n",
    "\n",
    "for lev in levs:\n",
    "  # if lev!='Lev5':\n",
    "  #   continue\n",
    "  for radius in data[lev].keys():\n",
    "    # if int(radius) != RADISU:\n",
    "    #   continue\n",
    "    if int(radius) < 150:\n",
    "      continue\n",
    "    # print(radius)\n",
    "\n",
    "    t = data[lev][radius]['t']\n",
    "    y = data[lev][radius][bondi_violation]\n",
    "\n",
    "    mask = (t < maxT) & (t > minT)\n",
    "    if lev == \"Lev3\":\n",
    "      # plt.plot(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='-')\n",
    "      plt.semilogy(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='-')\n",
    "    elif lev == 'Lev4':\n",
    "      # plt.plot(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='--')\n",
    "      plt.semilogy(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='--')\n",
    "    elif lev == 'Lev5':\n",
    "      # plt.plot(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='--')\n",
    "      plt.semilogy(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='--')\n",
    "    else:\n",
    "      # plt.plot(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='-.')\n",
    "      plt.semilogy(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='-.')\n",
    "\n",
    "\n",
    "  plt.xlabel('t')\n",
    "  # plt.ylabel(bondi_violation)\n",
    "  plt.title(f\"Bondi Violation {bondi_violation}\")\n",
    "  plt.legend()\n",
    "  plt.savefig(f\"./{lev}.png\")\n",
    "  plt.close()\n",
    "\n",
    "for radius in data['Lev5'].keys():\n",
    "  for lev in levs:\n",
    "    # if 'Lev5' not in lev:\n",
    "    #   continue\n",
    "\n",
    "    t = data[lev][radius]['t']\n",
    "    y = data[lev][radius][bondi_violation]\n",
    "\n",
    "    mask = (t < maxT) & (t > minT)\n",
    "    if lev == \"Lev3\":\n",
    "      # plt.plot(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='-')\n",
    "      plt.semilogy(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='-')\n",
    "    elif lev == 'Lev4':\n",
    "      # plt.plot(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='--')\n",
    "      plt.semilogy(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='--')\n",
    "    elif lev == 'Lev5':\n",
    "      # plt.plot(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='--')\n",
    "      plt.semilogy(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='--')\n",
    "    else:\n",
    "      # plt.plot(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='-.')\n",
    "      plt.semilogy(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='-.')\n",
    "\n",
    "\n",
    "  plt.xlabel('t')\n",
    "  # plt.ylabel(bondi_violation)\n",
    "  plt.title(f\"Bondi Violation {bondi_violation}\")\n",
    "  plt.legend()\n",
    "  plt.tight_layout()\n",
    "  plt.savefig(f\"./{radius}.png\")\n",
    "  plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levs = data.keys()\n",
    "\n",
    "\n",
    "bondi_violation = '2'\n",
    "minT = 2150\n",
    "maxT = 7500\n",
    "RADISU = 900\n",
    "\n",
    "for lev in levs:\n",
    "  # if lev!='Lev5':\n",
    "  #   continue\n",
    "  for radius in data[lev].keys():\n",
    "    # if int(radius) != RADISU:\n",
    "    #   continue\n",
    "    if int(radius) < 150:\n",
    "      continue\n",
    "    # print(radius)\n",
    "\n",
    "    t = data[lev][radius]['t']\n",
    "    y = data[lev][radius][bondi_violation]\n",
    "\n",
    "    mask = (t < maxT) & (t > minT)\n",
    "    if lev == \"Lev3\":\n",
    "      plt.plot(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='-')\n",
    "      # plt.semilogy(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='-')\n",
    "    elif lev == 'Lev4':\n",
    "      plt.plot(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='--')\n",
    "      # plt.semilogy(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='--')\n",
    "    else:\n",
    "      plt.plot(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='-.')\n",
    "      # plt.semilogy(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='-.')\n",
    "\n",
    "\n",
    "  plt.xlabel('t')\n",
    "  # plt.ylabel(bondi_violation)\n",
    "  plt.title(f\"Bondi Violation {bondi_violation}\")\n",
    "  plt.legend()\n",
    "  plt.savefig(f\"./{lev}.png\")\n",
    "  plt.close()\n",
    "\n",
    "for radius in data['Lev5'].keys():\n",
    "  for lev in levs:\n",
    "  # if lev!='Lev5':\n",
    "  #   continue\n",
    "\n",
    "    t = data[lev][radius]['t']\n",
    "    y = data[lev][radius][bondi_violation]\n",
    "\n",
    "    mask = (t < maxT) & (t > minT)\n",
    "    if lev == \"Lev3\":\n",
    "      plt.plot(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='-')\n",
    "      # plt.semilogy(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='-')\n",
    "    elif lev == 'Lev4':\n",
    "      plt.plot(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='--')\n",
    "      # plt.semilogy(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='--')\n",
    "    else:\n",
    "      plt.plot(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='-.')\n",
    "      # plt.semilogy(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='-.')\n",
    "\n",
    "\n",
    "  plt.xlabel('t')\n",
    "  # plt.ylabel(bondi_violation)\n",
    "  plt.title(f\"Bondi Violation {bondi_violation}\")\n",
    "  plt.legend()\n",
    "  plt.tight_layout()\n",
    "  plt.savefig(f\"./{int(radius)}.png\")\n",
    "  plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bondi_violations_dicts = list(main_folder.glob(\"*/bondi*\"))\n",
    "bondi_violations_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bondi_violations_dicts[0].parent.stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "data = {}\n",
    "for file in bondi_violations_dicts:\n",
    "  with file.open('rb') as f:\n",
    "    data[file.parent.stem] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bondi_violation = '2'\n",
    "minT = 215\n",
    "maxT = 7500\n",
    "RADISU = 900\n",
    "\n",
    "for key in data.keys():\n",
    "  if \"test\" in key:\n",
    "    continue\n",
    "  t = data[key]['t']\n",
    "  y = data[key][bondi_violation]\n",
    "\n",
    "  mask = (t < maxT) & (t > minT)\n",
    "  # plt.plot(t[mask],y[mask],label=f\"{key}\",linestyle='-.')\n",
    "  plt.semilogy(t[mask],y[mask],label=f\"{key}\",linestyle='-.')\n",
    "\n",
    "\n",
    "plt.xlabel('t')\n",
    "# plt.ylabel(bondi_violation)\n",
    "plt.title(f\"Bondi Violation {bondi_violation}\")\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig(f\"./variations.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute and save bondi violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cce_data_folder = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_big_gaussian/GW_data/\")\n",
    "\n",
    "cce_data_paths = list(cce_data_folder.glob(f\"**/red_cce.h5\"))\n",
    "for cce_data in cce_data_paths:\n",
    "  abd = scri.create_abd_from_h5(\n",
    "        file_name=str(cce_data),\n",
    "        file_format=\"spectrecce_v1\",\n",
    "        # ch_mass=1.0,  # Optional; helpful if known\n",
    "        # t_interpolate=t_worldtube,  # Optional; for some specified values of `t_worldtube`\n",
    "        # t_0_superrest=3000,\n",
    "        # padding_time=400\n",
    "      )\n",
    "\n",
    "  violations = abd.bondi_violation_norms\n",
    "  violation_dict = {\n",
    "  't': abd.t,\n",
    "  '0': violations[0],\n",
    "  '1': violations[1],\n",
    "  '2': violations[2],\n",
    "  '3': violations[3],\n",
    "  '4': violations[4],\n",
    "  '5': violations[5]\n",
    "  }\n",
    "\n",
    "  with open(cce_data.parent/\"violation_dict.pkl\",'wb') as f:\n",
    "    pickle.dump(violation_dict,f)\n",
    "\n",
    "\n",
    "  colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n",
    "  plt.semilogy(violation_dict['t'],violation_dict['5'],linestyle='--',label='2200_5',color=colors[5])\n",
    "  plt.semilogy(violation_dict['t'],violation_dict['4'],linestyle='--',label='2200_4',color=colors[4])\n",
    "  plt.semilogy(violation_dict['t'],violation_dict['3'],linestyle='--',label='2200_3',color=colors[3])\n",
    "  plt.semilogy(violation_dict['t'],violation_dict['2'],linestyle='--',label='2200_2',color=colors[2])\n",
    "  plt.semilogy(violation_dict['t'],violation_dict['1'],linestyle='--',label='2200_1',color=colors[1])\n",
    "  plt.semilogy(violation_dict['t'],violation_dict['0'],linestyle='--',label='2200_0',color=colors[0])\n",
    "\n",
    "  plt.xlabel('t')\n",
    "  plt.ylabel(\"violations\")\n",
    "  plt.legend()\n",
    "  plt.tight_layout()\n",
    "  plt.savefig(cce_data.parent/\"violations.png\")\n",
    "  plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sxs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
