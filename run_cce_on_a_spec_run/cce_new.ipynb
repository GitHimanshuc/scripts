{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "from itertools import cycle\n",
    "from pathlib import Path\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import scri\n",
    "from matplotlib import cycler\n",
    "from scipy.interpolate import InterpolatedUnivariateSpline as Spline\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import curve_fit\n",
    "from spherical_functions import LM_index as lm\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 10)\n",
    "colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "line_styles = [\"-\", \"--\", \"-.\", \":\"]\n",
    "combined_cycler = cycler(linestyle=line_styles) * cycler(color=colors)\n",
    "plt.rcParams[\"axes.prop_cycle\"] = combined_cycler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average_valid(array,avg_len):\n",
    "    return np.convolve(array,np.ones(avg_len),'valid')/avg_len\n",
    "\n",
    "def load_and_pickle(data_path:Path, reload_data:bool=False, data_type:str='abd', options:dict={}):\n",
    "  if not data_path.exists():\n",
    "    raise Exception(f\"{data_path} does not exist!\")\n",
    "\n",
    "  saved_data_path = data_path.parent/\"saved.pkl\"\n",
    "  \n",
    "  if saved_data_path.exists() and reload_data == False:\n",
    "    with open(saved_data_path, 'rb') as f:\n",
    "      saved_data = pickle.load(f)\n",
    "      print(f\"Saved data loaded: {saved_data_path}\")\n",
    "  else:\n",
    "    saved_data = {}\n",
    "    if data_type == 'abd':\n",
    "      saved_data['abd']= scri.create_abd_from_h5(\n",
    "          file_name=str(data_path),\n",
    "          file_format=\"spectrecce_v1\",\n",
    "          **options\n",
    "        )\n",
    "      with open(saved_data_path, 'wb') as f:\n",
    "        pickle.dump(saved_data,f)\n",
    "      print(f\"Data loaded and saved at : {saved_data_path}\")\n",
    "\n",
    "  return saved_data\n",
    "\n",
    "def load_bondi_constraints(data_path:Path):\n",
    "  if not data_path.exists():\n",
    "    raise Exception(f\"{data_path} does not exist!\")\n",
    "  saved_data_path = data_path.parent/\"saved.pkl\"\n",
    "  if not saved_data_path.exists():\n",
    "    raise Exception(f\"{saved_data_path} does not exist\")\n",
    "  else:\n",
    "    with open(saved_data_path, 'rb') as f:\n",
    "      saved_data = pickle.load(f)\n",
    "      if 'bondi_violation_norms' in saved_data:\n",
    "        print(f\"bondi_violation_norms loaded for {data_path}\")\n",
    "      else:\n",
    "        print(f\"Computing bondi_violation_norms for: {data_path}\")\n",
    "        saved_data['bondi_violation_norms'] = saved_data['abd'].bondi_violation_norms\n",
    "        with open(saved_data_path, 'wb') as f:\n",
    "          pickle.dump(saved_data,f)\n",
    "\n",
    "        print(f\"Saved bondi_violation_norms for: {data_path}\")\n",
    "    return saved_data\n",
    "\n",
    "def add_bondi_constraints(abd_data:dict):\n",
    "  for key in abd_data:\n",
    "    abd_data[key]['bondi_violation_norms'] = abd_data[key][\"abd\"].bondi_violation_norms\n",
    "    print(f\"bondi_violation_norms computed for {key}\")\n",
    "\n",
    "def create_diff_dict_cce(WT_data_dict:dict, l:int, m:int, base_key:str, t_interpolate:np.ndarray):\n",
    "  h = WT_data_dict[base_key]['abd'].h.interpolate(t_interpolate)\n",
    "  diff_dict = {\"t\": h.t}\n",
    "  y_base = h.data[:,  lm(l,m,h.ell_min)]\n",
    "  y_norm = np.linalg.norm(y_base)\n",
    "  for key in WT_data_dict:\n",
    "    if key == base_key:\n",
    "      continue\n",
    "    h = WT_data_dict[key]['abd'].h.interpolate(t_interpolate)\n",
    "    y_inter = h.data[:,  lm(l,m,h.ell_min)]\n",
    "    diff_dict[key+\"_diff\"] = y_inter-y_base\n",
    "    diff_dict[key+\"_absdiff\"] = np.abs(y_inter-y_base)\n",
    "    diff_dict[key+\"_rel_diff\"] = (y_inter-y_base)/y_norm\n",
    "    diff_dict[key+\"_rel_absdiff\"] = np.abs(y_inter-y_base)/y_norm\n",
    "  return diff_dict\n",
    "\n",
    "def extract_radii(h5_file_path:Path):\n",
    "  radii = set()\n",
    "  with h5py.File(h5_file_path,'r') as f:\n",
    "    names = []\n",
    "    f.visit(names.append)\n",
    "  for name in names:\n",
    "    if \"Version\" in name:\n",
    "      continue\n",
    "    radii.add(name[1:5])\n",
    "  radii = list(radii)\n",
    "  radii.sort()\n",
    "  return radii\n",
    "\n",
    "\n",
    "def generate_columns(num_cols:int,beta_type=False):\n",
    "  if beta_type:\n",
    "    num_cols = num_cols*2\n",
    "  L_max = int(np.sqrt((num_cols-1)/2))-1\n",
    "  # print(L_max,np.sqrt((num_cols-1)/2)-1)\n",
    "  col_names = ['t(M)']\n",
    "  for l in range(0,L_max+1):\n",
    "    for m in range(-l,l+1):\n",
    "      if beta_type:\n",
    "        if m==0:\n",
    "          col_names.append(f\"Re({l},{m})\")\n",
    "        elif m < 0:\n",
    "          continue\n",
    "        else:\n",
    "          col_names.append(f\"Re({l},{m})\")\n",
    "          col_names.append(f\"Im({l},{m})\")\n",
    "      else:\n",
    "        col_names.append(f\"Re({l},{m})\")\n",
    "        col_names.append(f\"Im({l},{m})\")\n",
    "  return col_names\n",
    "\n",
    "\n",
    "def WT_to_pandas(horizon_path:Path, keys_to_load:list=None):\n",
    "    assert(horizon_path.exists())\n",
    "    df_dict = {}\n",
    "    beta_type_list = ['Beta.dat', 'DuR.dat', 'R.dat', 'W.dat']\n",
    "    with h5py.File(horizon_path,'r') as hf:\n",
    "        # Not all horizon files may have AhC\n",
    "        for key in hf.keys():\n",
    "            if keys_to_load is not None:\n",
    "                if key not in keys_to_load:\n",
    "                    continue\n",
    "            if key == \"VersionHist.ver\":\n",
    "              continue \n",
    "            if key in beta_type_list:\n",
    "              df_dict[key] = pd.DataFrame(hf[key], columns=generate_columns(hf[key].shape[1],beta_type=True))\n",
    "            else:\n",
    "              df_dict[key] = pd.DataFrame(hf[key], columns=generate_columns(hf[key].shape[1]))\n",
    "\n",
    "\n",
    "    return df_dict\n",
    "\n",
    "\n",
    "def create_diff_dict(WT_data_dict:dict, mode:str, variable:str, base_key:str):\n",
    "  diff_dict = {\"t(M)\":WT_data_dict[base_key][variable]['t(M)']}\n",
    "  y_base = WT_data_dict[base_key][variable][mode]\n",
    "  y_norm = np.linalg.norm(y_base)\n",
    "  for key in WT_data_dict:\n",
    "    if key == base_key:\n",
    "      continue\n",
    "    y = WT_data_dict[key][variable][mode]\n",
    "    t = WT_data_dict[key][variable]['t(M)']\n",
    "    y_interpolator = interp1d(t, y, kind='cubic',fill_value='extrapolate')\n",
    "    y_inter = y_interpolator(diff_dict['t(M)'])\n",
    "    diff_dict[key+\"_diff\"] = y_inter-y_base\n",
    "    diff_dict[key+\"_absdiff\"] = np.abs(y_inter-y_base)\n",
    "    diff_dict[key+\"_rel_diff\"] = (y_inter-y_base)/y_norm\n",
    "    diff_dict[key+\"_rel_absdiff\"] = np.abs(y_inter-y_base)/y_norm\n",
    "  return diff_dict\n",
    "\n",
    "def filter_by_regex(regex,col_list,exclude=False):\n",
    "  filtered_set = set()\n",
    "  if type(regex) is list:\n",
    "    for reg in regex:\n",
    "      for i in col_list:\n",
    "        if re.search(reg,i):\n",
    "          filtered_set.add(i)\n",
    "  else:\n",
    "    for i in col_list:\n",
    "      if re.search(regex,i):\n",
    "        filtered_set.add(i)\n",
    "\n",
    "  filtered_list = list(filtered_set)\n",
    "  if exclude:\n",
    "    col_list_copy = list(col_list.copy())\n",
    "    for i in filtered_list:\n",
    "      if i in col_list_copy:\n",
    "        col_list_copy.remove(i)\n",
    "    filtered_list = col_list_copy\n",
    "\n",
    "  # Restore the original order\n",
    "  filtered_original_ordered_list = []\n",
    "  for i in list(col_list):\n",
    "    if i in filtered_list:\n",
    "      filtered_original_ordered_list.append(i)\n",
    "  return filtered_original_ordered_list\n",
    "\n",
    "def limit_by_col_val(min_val,max_val,col_name,df):\n",
    "  filter = (df[col_name]>=min_val) &(df[col_name] <=max_val)\n",
    "  return df[filter]\n",
    "\n",
    "def abs_mean_value_upto_l(pd_series,L_max:int):\n",
    "  idx = pd_series.index\n",
    "  abs_cum_sum = 0\n",
    "  num = 0\n",
    "  for i in idx:\n",
    "    L = int(i.split(\",\")[0][3:])\n",
    "    if L > L_max:\n",
    "      continue\n",
    "    else:\n",
    "      abs_cum_sum = abs_cum_sum+abs(pd_series[i])\n",
    "      num = num +1\n",
    "  return abs_cum_sum/num\n",
    "\n",
    "def get_mode(name):\n",
    "  return int(name.split(\"(\")[-1].split(\")\")[0])\n",
    "def get_radii(name):\n",
    "  if name[-5]=='R':\n",
    "    # R0257 -> 0257load_and_pickle\n",
    "    return int(name.split('_')[-1][1:])\n",
    "  else:\n",
    "    return int(name.split('_')[-1])\n",
    "def sort_by_power_modes(col_names):\n",
    "  col_name_copy = list(col_names).copy()\n",
    "  return sorted(col_name_copy, key=lambda x: int(get_mode(x)))\n",
    "\n",
    "def add_L_mode_power(df:pd.DataFrame,L:int, ReOrIm:str):\n",
    "  column_names = df.columns\n",
    "  n = 0\n",
    "  power = 0\n",
    "  for m in range(-L,L+1):\n",
    "    col_name = f'{ReOrIm}({L},{m})'\n",
    "    # print(col_name)\n",
    "    if col_name in column_names:\n",
    "      power = power + df[col_name]*df[col_name]\n",
    "      n = n + 1\n",
    "  if n != 0:\n",
    "    power = power/n\n",
    "    df[f'pow_{ReOrIm}({L})'] = power\n",
    "  return power\n",
    "\n",
    "def add_all_L_mode_power(df:pd.DataFrame,L_max:int):\n",
    "  local_df = df.copy()\n",
    "  total_power_Re = 0\n",
    "  total_power_Im = 0\n",
    "  for l in range(0,L_max+1):\n",
    "    total_power_Re = total_power_Re + add_L_mode_power(local_df,l,\"Re\")\n",
    "    total_power_Im = total_power_Im + add_L_mode_power(local_df,l,\"Im\")\n",
    "    local_df[f\"pow_cum_Re({l})\"] = total_power_Re\n",
    "    local_df[f\"pow_cum_Im({l})\"] = total_power_Im\n",
    "  return local_df\n",
    "\n",
    "\n",
    "def create_power_diff_dict(power_dict:dict, pow_mode:str, variable:str, base_key:str):\n",
    "  diff_dict = {\"t(M)\":power_dict[base_key]['t(M)']}\n",
    "  y_base = power_dict[base_key][variable][pow_mode]\n",
    "  y_norm = np.linalg.norm(y_base)\n",
    "  for key in power_dict:\n",
    "    if key == base_key:\n",
    "      continue\n",
    "    y = power_dict[key][variable][pow_mode]\n",
    "    t = power_dict[key]['t(M)']\n",
    "    y_interpolator = interp1d(t, y, kind='cubic',fill_value='extrapolate')\n",
    "    y_inter = y_interpolator(diff_dict['t(M)'])\n",
    "    diff_dict[key+\"_diff\"] = y_inter-y_base\n",
    "    diff_dict[key+\"_absdiff\"] = np.abs(y_inter-y_base)\n",
    "    diff_dict[key+\"_rel_diff\"] = (y_inter-y_base)/y_norm\n",
    "    diff_dict[key+\"_rel_absdiff\"] = np.abs(y_inter-y_base)/y_norm\n",
    "  return diff_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to compute the mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SplineArray:\n",
    "    def __init__(self, x, y):\n",
    "        self.complex = np.iscomplexobj(y)\n",
    "        if self.complex:\n",
    "            y = y.view(dtype=float)\n",
    "        self.splines = [Spline(x, y[:, i]) for i in range(y.shape[1])]\n",
    "\n",
    "    def __call__(self, xprime):\n",
    "        yprime = np.concatenate(\n",
    "            [spl(xprime)[:, np.newaxis] for spl in self.splines], axis=1\n",
    "        )\n",
    "        if self.complex:\n",
    "            yprime = yprime.view(dtype=complex)\n",
    "        return yprime\n",
    "\n",
    "def SquaredError(W1, W2, t1, t2, modes=None, return_h1h2_h1h1=False):\n",
    "    \"\"\"\n",
    "    Calculate the residue of W1 and W2 between t1 and t2.\n",
    "    \"\"\"\n",
    "    W2_spline = SplineArray(W2.t, W2.data)\n",
    "    t_filter = (W1.t >= t1) & (W1.t <= t2)\n",
    "    filtered_time = W1.t[t_filter]\n",
    "\n",
    "    if modes is None:\n",
    "        h1h2 = np.sum(\n",
    "            sp.integrate.simpson(\n",
    "                abs(W2_spline(filtered_time) - W1.data[t_filter, :]) ** 2.0,\n",
    "                filtered_time,\n",
    "                axis=0,\n",
    "            )\n",
    "        )\n",
    "        h1h1 = np.sum(\n",
    "            sp.integrate.simpson(\n",
    "                abs(W1.data[t_filter, :]) ** 2.0, filtered_time, axis=0\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        h1h2 = np.sum(\n",
    "            sp.integrate.simpson(\n",
    "                abs(W2_spline(filtered_time) - W1.data[t_filter, :])[:, modes] ** 2.0,\n",
    "                filtered_time,\n",
    "                axis=0,\n",
    "            )\n",
    "        )\n",
    "        h1h1 = np.sum(\n",
    "            sp.integrate.simpson(\n",
    "                abs(W1.data[t_filter, :][:, modes]) ** 2.0, filtered_time, axis=0\n",
    "            )\n",
    "        )\n",
    "    if return_h1h2_h1h1:\n",
    "        return h1h2 , h1h1\n",
    "    else:\n",
    "        return 0.5 * h1h2 / h1h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_interpolate = np.linspace(-1000,4000,num=5000)\n",
    "data_path = Path(\"/groups/sxs/hchaudha/spec_runs/6_segs/6_set1_L6/GW_data_lev6/BondiCceR0250/red_cce.h5\")\n",
    "data = load_and_pickle(data_path,options = {'t_interpolate':t_interpolate})\n",
    "data = load_bondi_constraints(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple ABDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cce_data = {}\n",
    "# cce_data[\"high_accuracy_Lev0_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev0/BondiCceR0257/red_cce.h5\")\n",
    "# cce_data[\"high_accuracy_Lev1_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev1/BondiCceR0257/red_cce.h5\")\n",
    "# cce_data[\"high_accuracy_Lev2_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev2/BondiCceR0257/red_cce.h5\")\n",
    "# cce_data[\"high_accuracy_Lev3_R0258\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/GW_data_lev3/BondiCceR0258/red_cce.h5\")\n",
    "# cce_data[\"high_accuracy_Lev4_R0258\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/GW_data_lev4/BondiCceR0258/red_cce.h5\")\n",
    "# cce_data[\"high_accuracy_Lev5_R0258\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/GW_data_lev5/BondiCceR0258/red_cce.h5\")\n",
    "# cce_data[\"high_accuracy_Lev3_R0472\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/GW_data_lev3/BondiCceR0472/red_cce.h5\")\n",
    "# cce_data[\"high_accuracy_Lev4_R0472\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/GW_data_lev4/BondiCceR0472/red_cce.h5\")\n",
    "# cce_data[\"high_accuracy_Lev5_R0472\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/GW_data_lev5/BondiCceR0472/red_cce.h5\")\n",
    "# cce_data[\"master_Lev0_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev/GW_data/BondiCceR0257/red_cce.h5\")\n",
    "# cce_data[\"master_Lev1_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev/GW_data_lev1/BondiCceR0257/red_cce.h5\")\n",
    "# cce_data[\"master_Lev2_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev/GW_data_lev2/BondiCceR0257/red_cce.h5\")\n",
    "# cce_data[\"master_Lev3_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_master/Ev/GW_data_lev3/BondiCceR0257/red_cce.h5\")\n",
    "# cce_data[\"master_Lev4_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_master/Ev/GW_data_lev4/BondiCceR0257/red_cce.h5\")\n",
    "# cce_data[\"master_Lev5_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_master/Ev/GW_data_lev5/BondiCceR0257/red_cce.h5\")\n",
    "# cce_data[\"Lev5_bg_ah100_cd_01_uamr_full_R0258\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_bg_ah100_cd_01_uamr_full/GW_data/BondiCceR0258/red_cce.h5\")\n",
    "# cce_data[\"Lev5_bg_ah100_cd_01_uamr_full_R0686\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_bg_ah100_cd_01_uamr_full/GW_data/BondiCceR0686/red_cce.h5\")\n",
    "# cce_data[\"Lev5_bg_ah100_lapse_uamr_fullR0258\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_bg_ah100_lapse_uamr_full/GW_data/BondiCceR0258/red_cce.h5\")\n",
    "# cce_data[\"Lev5_bg_ah100_lapse_uamr_full_R0100\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_bg_ah100_lapse_uamr_full/GW_data/BondiCceR0100/red_cce.h5\")\n",
    "# cce_data[\"high_accuracy_Lev5_R0258_ZeroNonSmooth\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/ZeroNonSmooth/red_Lev5_R0258_VolumeData.h5\")\n",
    "# cce_data[\"high_accuracy_Lev5_R0258_NoIncomingRadiation\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/NoIncomingRadiation/red_Lev5_R0258_VolumeData.h5\")\n",
    "# cce_data[\"high_accuracy_Lev5_R0258_InverseCubic\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/InverseCubic/red_Lev5_R0258_VolumeData.h5\")\n",
    "# cce_data[\"high_accuracy_Lev5_R0258_ConformalFactor10\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/ConformalFactor10/red_Lev5_R0258_VolumeData.h5\")\n",
    "# cce_data[\"high_accuracy_Lev5_R0258_ConformalFactor7\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/ConformalFactor7/red_Lev5_R0258_VolumeData.h5\")\n",
    "# cce_data[\"high_accuracy_Lev5_R0258_ConformalFactor3\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/ConformalFactor3/red_Lev5_R0258_VolumeData.h5\")\n",
    "\n",
    "# cce_data[\"Lev01_test_ode_Lev2_257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev2/BondiCceR0257/red_cce.h5\")\n",
    "# cce_data[\"Lev01_test_ode_Lev1_257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev1/BondiCceR0257/red_cce.h5\")\n",
    "\n",
    "# cce_data[\"Lev01_test_Lev2_257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev/GW_data_lev2/BondiCceR0257/red_cce.h5\")\n",
    "\n",
    "# cce_data[\"Lev01_test_Lev2_257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev/GW_data_lev2/BondiCceR0257/red_cce.h5\")\n",
    "\n",
    "levs,run_sets,radius= [],[],[]\n",
    "# levs = [0,1,2,3,4,5,6]\n",
    "# levs = [1,2,3,4,5,6]\n",
    "# levs = [1,3,6]\n",
    "# levs = [0,1,2,3]\n",
    "# levs = [5]\n",
    "# levs = [5,6]\n",
    "# levs = [6]\n",
    "# run_sets = [1]\n",
    "# radius = [250]\n",
    "# radius = [100,150,200,250,300,350,500,700,900]\n",
    "# radius = [150,200,250,300,350,500,700]\n",
    "# radius = [200,250,300,350,500]\n",
    "for l,s,r in itertools.product(levs,run_sets,radius):\n",
    "  if s == 2 and (l == 0 or l==1):\n",
    "    continue\n",
    "  if l <= 3:\n",
    "    if s == 1:\n",
    "      cce_data[f\"6_set{s}_L6s{l}_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/6_segs/6_set{s}_L6/GW_data_lev{l}/BondiCceR0{r}/red_cce.h5\")\n",
    "    # cce_data[f\"6_set{s}_L3s{l}_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/6_segs/6_set{s}_L3/GW_data_lev{l}/BondiCceR0{r}/red_cce.h5\")\n",
    "  else:\n",
    "    cce_data[f\"6_set{s}_L6s{l}_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/6_segs/6_set{s}_L6/GW_data_lev{l}/BondiCceR0{r}/red_cce.h5\")\n",
    "    pass\n",
    "\n",
    "\n",
    "# cce_data[f\"6_set1_L6s3_CAMR_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/6_segs/6_set1_L6_vars/L6s3_CAMR/GW_data_lev3/BondiCceR0{r}/red_cce.h5\")\n",
    "# cce_data[f\"6_set1_L6s3_min_L_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/6_segs/6_set1_L6_vars/L6s3_min_L/GW_data_lev3/BondiCceR0{r}/red_cce.h5\")\n",
    "\n",
    "# cce_data[f\"7_constAMR_set1_L6_base_{l}_{r}\"] =  Path(f\"/groups/sxs/hchaudha/spec_runs/7_constAMR_set1_L6_base/GW_data_lev{l}/BondiCceR0{r}/red_cce.h5/\")\n",
    "\n",
    "# cce_data[f\"10_4000M_CAMR_set1_L6_base_{l}_{r}\"] =  Path(f\"/groups/sxs/hchaudha/spec_runs/10_4000M_CAMR_set1_L6_base/GW_data_lev{l}/BondiCceR0{r}/red_cce.h5/\")\n",
    "# cce_data[f\"11_4000M_CAMR_set1_L6_maxExt_{l}_{r}\"] =  Path(f\"/groups/sxs/hchaudha/spec_runs/11_4000M_CAMR_set1_L6_maxExt/GW_data_lev{l}/BondiCceR0{r}/red_cce.h5/\")\n",
    "\n",
    "# cce_data[f\"6_set1_L3s3_3\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/6_segs/6_set1_L3/GW_data_lev2/BondiCceR0250/red_cce.h5\")\n",
    "\n",
    "# radius_list = []\n",
    "# radius_list = ['0100','0150','0200','0250','0300','0350','0500','0700','0900','1100','1300','1400']\n",
    "# radius_list = ['0250','0300','0350','0500','0700']\n",
    "# for r in radius_list:\n",
    "#   cce_data[f\"12_set1_L3_1500_{r}\"] =  Path(f\"/groups/sxs/hchaudha/spec_runs/12_set1_L3_1500/GW_data_lev3/BondiCceR{r}/red_cce.h5/\")\n",
    "\n",
    "# radius_list = []\n",
    "# radius_list = ['0100','0150','0200','0250','0300','0350','0500','0700','0900','1100','1300','1500','1700','1900']\n",
    "# radius_list = ['0200','0250','0300','0350','0500','0700']\n",
    "# for r in radius_list:\n",
    "#   cce_data[f\"12_set1_L3_2000_{r}\"] =  Path(f\"/groups/sxs/hchaudha/spec_runs/12_set1_L3_2000/GW_data_lev3/BondiCceR{r}/red_cce.h5/\")\n",
    "\n",
    "# radius_list = []\n",
    "# radius_list = ['0100','0150','0200','0250','0300','0350','0500','0700','0900','1100','1300','1500','1700','1900','2100','2300']\n",
    "# radius_list = ['0200','0250','0300','0350','0500','0700']\n",
    "# for r in radius_list:\n",
    "#   cce_data[f\"12_set1_L3_2500_{r}\"] =  Path(f\"/groups/sxs/hchaudha/spec_runs/12_set1_L3_2500/GW_data_lev3/BondiCceR{r}/red_cce.h5/\")\n",
    "\n",
    "# radius_list = []\n",
    "# radius_list = ['0100', '0150', '0200', '0250', '0300', '0350', '0400', '0500', '0600', '0700', '0800', '0900', '1000', '1100', '1200', '1300', '1400', '1500', '1600', '1700', '1800', '1900', '2000', '2100', '2200', '2300', '2400', '2500', '2600', '2700', '2800', '2900']\n",
    "# # radius_list = ['0250','0300','0350','0500','0700']\n",
    "# for r in radius_list:\n",
    "#   cce_data[f\"13_set1_L3_3000_{r}\"] =  Path(f\"/groups/sxs/hchaudha/spec_runs/13_set1_L3_3000/GW_data_lev3/BondiCceR{r}/red_cce.h5/\")\n",
    "\n",
    "# radius_list = []\n",
    "# radius_list = ['0100', '0150', '0200', '0250', '0300', '0350', '0400', '0500', '0600', '0700', '0800', '0900', '1000', '1100', '1200', '1300', '1400']\n",
    "# radius_list = ['0200','0250','0300','0350','0500','0700']\n",
    "# for r in radius_list:\n",
    "#   cce_data[f\"13_set1_L4_1500_{r}\"] =  Path(f\"/groups/sxs/hchaudha/spec_runs/13_set1_L4_1500/GW_data_lev4/BondiCceR{r}/red_cce.h5/\")\n",
    "\n",
    "# radius_list = []\n",
    "# radius_list = ['0100', '0150', '0200', '0250', '0300', '0350', '0400', '0500', '0600', '0700', '0800', '0900', '1000', '1100', '1200', '1300', '1400', '1500', '1600', '1700', '1800', '1900', '2000', '2100', '2200', '2300', '2400', '2500', '2600', '2700', '2800', '2900']\n",
    "# radius_list = ['0200','0250','0300','0350','0500','0700']\n",
    "# for r in radius_list:\n",
    "#   cce_data[f\"13_set1_L4_3000_{r}\"] =  Path(f\"/groups/sxs/hchaudha/spec_runs/13_set1_L4_3000/GW_data_lev4/BondiCceR{r}/red_cce.h5/\")\n",
    "\n",
    "# radius_list = []\n",
    "# radius_list = ['0100', '0150', '0200', '0250', '0300', '0350', '0400', '0500', '0600', '0700', '0800', '0900']\n",
    "# for r in radius_list:\n",
    "#   cce_data[f\"16_set1_L3_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/16_set1_L3/GW_data_lev3/BondiCceR{r}/red_cce.h5\")\n",
    "#   cce_data[f\"16_set1_L3_HP32_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/16_set1_L3_HP32/GW_data_lev3/BondiCceR{r}/red_cce.h5\")\n",
    "#   cce_data[f\"16_set1_L3_HP28_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/16_set1_L3_HP28/GW_data_lev3/BondiCceR{r}/red_cce.h5\")\n",
    "#   cce_data[f\"16_set1_L3_HP32_AF_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/16_set1_L3_HP32_AF/GW_data_lev3/BondiCceR{r}/red_cce.h5\")\n",
    "\n",
    "# radius_list = []\n",
    "# radius_list = ['0258', '0472', '0686', '0900']\n",
    "# for r in radius_list:\n",
    "#   cce_data[f\"17_main_9_18_L3_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/17_main_9_18_L3/GW_data_lev3/BondiCceR{r}/red_cce.h5\")\n",
    "\n",
    "# radius_list = []\n",
    "# radius_list = ['0258', '0469', '0679', '0890']\n",
    "# for r in radius_list:\n",
    "#   cce_data[f\"17_set_main_q3_18_L3_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/17_set_main_q3_18_L3/GW_data_lev3/BondiCceR{r}/red_cce.h5\")\n",
    "\n",
    "# radius_list = []\n",
    "# radius_list = ['0199', '0353', '0506', '0660']\n",
    "# for r in radius_list:\n",
    "#   cce_data[f\"17_set_main_q3_15_L3_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/17_set_main_q3_15_L3/GW_data_lev3/BondiCceR{r}/red_cce.h5\")\n",
    "\n",
    "# radius_list = []\n",
    "# radius_list = ['0100', '0150', '0200', '0250', '0300', '0350', '0500', '0700', '0900']\n",
    "# radius_list = [ '0300', '0250', '0350','0200']\n",
    "# radius_list = [ '0350']\n",
    "# for r in radius_list:\n",
    "#   cce_data[f\"17_set1_q3_18_L3_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/17_set1_q3_18_L3/GW_data_lev3/BondiCceR{r}/red_cce.h5\")\n",
    "#   cce_data[f\"17_set3_q3_18_L3_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/17_set3_q3_18_L3/GW_data_lev3/BondiCceR{r}/red_cce.h5\")\n",
    "#   cce_data[f\"17_set1_9_18_L3_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/17_set1_9_18_L3/GW_data_lev3/BondiCceR{r}/red_cce.h5\")\n",
    "#   cce_data[f\"17_set3_9_18_L3_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/17_set3_9_18_L3/GW_data_lev3/BondiCceR{r}/red_cce.h5\")\n",
    "#   cce_data[f\"22_set1_L1_long_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/22_set1_L1_long/GW_data_lev1/BondiCceR{r}/red_cce.h5\")\n",
    "#   cce_data[f\"22_set1_L3_long_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/22_set1_L3_long/GW_data_lev3/BondiCceR{r}/red_cce.h5\")\n",
    "#   cce_data[f\"22_L3_AC_L3_no_res_C_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/22_segs/L3_AC_L3_no_res_C/GW_data_lev3/BondiCceR{r}/red_cce.h5\")\n",
    "#   cce_data[f\"22_L3_AC_L3_res_10_C_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/22_segs/L3_AC_L3_res_10_C/GW_data_lev3/BondiCceR{r}/red_cce.h5\")\n",
    "\n",
    "#   cce_data[f\"L1_AC_L2_long_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/22_segs/L1_AC_L2/GW_data_lev2/BondiCceR{r}/red_cce.h5\")\n",
    "#   cce_data[f\"L1_AC_L3_long_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/22_segs/L1_AC_L3/GW_data_lev3/BondiCceR{r}/red_cce.h5\")\n",
    "#   cce_data[f\"L3_AC_L1_long_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/22_segs/L3_AC_L1/GW_data_lev1/BondiCceR{r}/red_cce.h5\")\n",
    "#   cce_data[f\"L3_AC_L2_long_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/22_segs/L3_AC_L2/GW_data_lev2/BondiCceR{r}/red_cce.h5\")\n",
    "#   cce_data[f\"L3_AC_L4_long_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/22_segs/L3_AC_L4/GW_data_lev4/BondiCceR{r}/red_cce.h5\")\n",
    "\n",
    "# levs,radius,start = [],[],[]\n",
    "# levs = [1,3]\n",
    "# levs = [3]\n",
    "# radius = ['0250', '0350']\n",
    "# radius = ['0350']\n",
    "# start = [3000,5000,7000,8000]\n",
    "# start = [3000,7000]\n",
    "# for l,r,s in itertools.product(levs,radius,start):\n",
    "#   cce_data[f\"L{l}_S{s}_r{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/22_cce_test/L{l}/start_{s}/BondiCceR{r}/red_cce.h5\")\n",
    "\n",
    "# levs,radius,start = [],[],[]\n",
    "# levs = ['_IC','_NIR','_ZNS','']\n",
    "# levs = ['_NIR','']\n",
    "# radius = ['0250', '0350']\n",
    "# radius = ['0350']\n",
    "# start = [0,500,1000,3000,7000]\n",
    "# start = [3000,7000]\n",
    "# for l,r,s in itertools.product(levs,radius,start):\n",
    "#   cce_data[f\"L3{l}_S{s}_r{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/22_cce_test/L3/start_{s}{l}/BondiCceR{r}/red_cce.h5\")\n",
    "\n",
    "# radius = ['0020','0035','0050','0075','0100','0150','0200','0250','0300','0400','0500','0600','0800','1000','1500','2000','2500',]\n",
    "# radius = ['0020','0050','0100','0200','0500','1000','1500','2000','2500',]\n",
    "# for r in radius:\n",
    "#   cce_data[f\"14_NIR_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/single_bh/20_zero_spin_AMR_L5_10000M/GW_data/long_16_2565_10000_14_NIR/BondiCceR{r}/red_cce.h5\")\n",
    "\n",
    "\n",
    "# radius = ['0012', '0050', '0112', '0200', '0312', '0450', '0612', '0800', '1012', '1250', '1512', '1800', '2112', '2450', '2812', '3200', '3612', '4050', '4512', '0003', '0004', '0005', '0006', '0007', '0008', '0009', '0010', '0015', '0020', '0030', '0075']\n",
    "# radius = sorted(['0050', '0112', '0200', '0612', '0800', '1012',  '1800',  '3200', '3612', '4050', '4512', '0006', '0020', '0075'])\n",
    "# radius = sorted(['0050', '0112', '0200', '0612', '0800', '1012',  '0006', '0010', '0015', '0020', '0030', '0075','1800',  '3200','4512'])\n",
    "# radius = ['0006']\n",
    "# for r in radius:\n",
    "#   cce_data[f\"ex_rad_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/single_bh_CCE/runs/radius_dependence/ex_rad_{r}/red_cce.h5\")\n",
    "\n",
    "# radius = [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000 ]\n",
    "# radius = [0, 100, 200, 300, 400, 500, 600]\n",
    "# for r in radius[::]:\n",
    "#   cce_data[f\"CF_350_start_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/22_cce_test/L3_new_executable/runs/ConformalFactor_start_{r}/red_cce.h5\")\n",
    "\n",
    "# for i in Path(\"/groups/sxs/hchaudha/spec_runs/22_cce_test/L3_merged_data/runs\").glob(\"*/red_cce.h5\"):\n",
    "#     cce_data[i.parent.stem] = i\n",
    "# for i in Path(\"/groups/sxs/hchaudha/spec_runs/22_cce_test/L3_merged_data/runs\").glob(\"Delta*/red_cce.h5\"):\n",
    "#     cce_data[i.parent.stem] = i\n",
    "\n",
    "# for i in Path(\"/resnick/groups/sxs/hchaudha/spec_runs/22_cce_test/runs/CF_0\").glob(\n",
    "#     \"Delta*/red_cce.h5\"\n",
    "# ):\n",
    "#     cce_data[i.parent.stem] = i\n",
    "\n",
    "# for i in Path(\"/resnick/groups/sxs/hchaudha/spec_runs/22_set1_L3_long/GW_data_lev3_start_6000\").glob(\n",
    "#     \"BondiCceR*/red_cce.h5\"\n",
    "# ):\n",
    "#     cce_data[\"set1_L3_long_ST_6000M_\"+i.parent.stem[-4:]] = i\n",
    "\n",
    "# for i in Path(\"/resnick/groups/sxs/hchaudha/spec_runs/22_set1_L3_long/GW_data_lev3_start_4000\").glob(\n",
    "#     \"BondiCceR*/red_cce.h5\"\n",
    "# ):\n",
    "#     cce_data[\"set1_L3_long_ST_4000M_\"+i.parent.stem[-4:]] = i\n",
    "\n",
    "# for i in Path(\"/resnick/groups/sxs/hchaudha/spec_runs/22_set1_L3_long/GW_data_lev3_start_2000\").glob(\n",
    "#     \"BondiCceR*/red_cce.h5\"\n",
    "# ):\n",
    "#     cce_data[\"set1_L3_long_ST_2000M_\"+i.parent.stem[-4:]] = i\n",
    "\n",
    "# for i in Path(\"/resnick/groups/sxs/hchaudha/spec_runs/32_RM_set1_L3/GW_data_lev3\").glob(\n",
    "#     \"BondiCceR*/red_cce.h5\"\n",
    "# ):\n",
    "#     cce_data[\"32_RM_set1_L3_\"+i.parent.stem[-4:]] = i\n",
    "\n",
    "def include_radii(name, min,max):\n",
    "    radius = int(name[-4:])\n",
    "    if radius < min or radius > max:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "# for i in Path(\"/resnick/groups/sxs/hchaudha/spec_runs/31_segs/L1s3_cdg1_250/GW_data_lev3\").glob(\n",
    "#     \"BondiCceR*/red_cce.h5\"\n",
    "# ):\n",
    "#     if not include_radii(i.parent.stem, 200, 400):\n",
    "#         continue\n",
    "#     cce_data[\"32_RM_set1_L1s3_cdg1_250_\"+i.parent.stem[-4:]] = i\n",
    "\n",
    "# for i in Path(\"/resnick/groups/sxs/hchaudha/spec_runs/31_segs/L1s3_cdg1_100/GW_data_lev3\").glob(\n",
    "#     \"BondiCceR*/red_cce.h5\"\n",
    "# ):\n",
    "#     if not include_radii(i.parent.stem, 200, 400):\n",
    "#         continue\n",
    "#     cce_data[\"32_RM_set1_L1s3_cdg1_100_\"+i.parent.stem[-4:]] = i\n",
    "\n",
    "# for i in Path(\"/resnick/groups/sxs/hchaudha/spec_runs/31_segs/L1s3_cdg1_10/GW_data_lev3\").glob(\n",
    "#     \"BondiCceR*/red_cce.h5\"\n",
    "# ):\n",
    "#     if not include_radii(i.parent.stem, 200, 400):\n",
    "#         continue\n",
    "#     cce_data[\"32_RM_set1_L1s3_cdg1_10_\"+i.parent.stem[-4:]] = i\n",
    "\n",
    "# for i in Path(\"/resnick/groups/sxs/hchaudha/spec_runs/31_segs/L1s3/GW_data_lev3\").glob(\n",
    "#     \"BondiCceR*/red_cce.h5\"\n",
    "# ):\n",
    "#     if not include_radii(i.parent.stem, 200, 400):\n",
    "#         continue\n",
    "#     cce_data[\"32_RM_set1_L1s3_\"+i.parent.stem[-4:]] = i\n",
    "\n",
    "for i in Path(\"/resnick/groups/sxs/hchaudha/spec_runs/33_const_inn_dom_runs/set1_L3_Lmin18/GW_data_lev3\").glob(\n",
    "    \"BondiCceR*/red_cce.h5\"\n",
    "):\n",
    "    if not include_radii(i.parent.stem, 200, 400):\n",
    "        continue\n",
    "    cce_data[\"set1_L3_Lmin18_\"+i.parent.stem[-4:]] = i\n",
    "\n",
    "for i in Path(\"/resnick/groups/sxs/hchaudha/spec_runs/33_const_inn_dom_runs/set1_L3_Lmin20_Rn2/GW_data_lev3\").glob(\n",
    "    \"BondiCceR*/red_cce.h5\"\n",
    "):\n",
    "    if not include_radii(i.parent.stem, 200, 400):\n",
    "        continue\n",
    "    cce_data[\"set1_L3_Lmin20_Rn2_\"+i.parent.stem[-4:]] = i\n",
    "\n",
    "for i in Path(\"/resnick/groups/sxs/hchaudha/spec_runs/33_const_inn_dom_runs/set1_L3_Rn1/GW_data_lev3\").glob(\n",
    "    \"BondiCceR*/red_cce.h5\"\n",
    "):\n",
    "    if not include_radii(i.parent.stem, 200, 400):\n",
    "        continue\n",
    "    cce_data[\"set1_L3_Rn1_\"+i.parent.stem[-4:]] = i\n",
    "\n",
    "for i in Path(\"/resnick/groups/sxs/hchaudha/spec_runs/33_const_inn_dom_runs/set1_L3_Rn2/GW_data_lev3\").glob(\n",
    "    \"BondiCceR*/red_cce.h5\"\n",
    "):\n",
    "    if not include_radii(i.parent.stem, 200, 400):\n",
    "        continue\n",
    "    cce_data[\"set1_L3_Rn2_\"+i.parent.stem[-4:]] = i\n",
    "\n",
    "# cce_data['6_12_250'] = Path(\"/resnick/groups/sxs/hchaudha/spec_runs/6_segs/6_set1_L6/GW_data_lev6_12/BondiCceR0250/red_cce.h5\")\n",
    "# cce_data['6_10_250'] = Path(\"/resnick/groups/sxs/hchaudha/spec_runs/6_segs/6_set1_L6/GW_data_lev6_10/BondiCceR0250/red_cce.h5\")\n",
    "# cce_data['BondiCceR0334'] = Path(\"/resnick/groups/sxs/hchaudha/spec_runs/CCE_stuff/Lev4_061CCE/BondiCceR0334/red_cce.h5\")\n",
    "# cce_data['BondiCceR0586'] = Path(\"/resnick/groups/sxs/hchaudha/spec_runs/CCE_stuff/Lev4_061CCE/BondiCceR0586/red_cce.h5\")\n",
    "\n",
    "cce_data = dict(sorted(cce_data.items()))\n",
    "\n",
    "\n",
    "fail_flag = False\n",
    "for key in cce_data:\n",
    "    if not cce_data[key].exists():\n",
    "        fail_flag = True\n",
    "        print(f\"{cce_data[key]} does not exist!\")\n",
    "    if fail_flag:\n",
    "        raise Exception(\"Some paths do not exist!\")\n",
    "\n",
    "print(cce_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_interpolate = np.linspace(-1000,20000,num=2000)\n",
    "# t_interpolate = np.linspace(-1000,4000,num=10000)\n",
    "\n",
    "abd_data = {}\n",
    "failed_keys=  {}\n",
    "for key in cce_data:\n",
    "  try:\n",
    "    # abd_data[key] = load_and_pickle(cce_data[key])\n",
    "    # abd_data[key] = load_and_pickle(cce_data[key], reload_data=True)\n",
    "    # abd_data[key] = load_and_pickle(cce_data[key],options = {'t_interpolate':t_interpolate}, reload_data=True)\n",
    "    abd_data[key] = load_and_pickle(cce_data[key],options = {'t_interpolate':t_interpolate})\n",
    "    abd_data[key] = load_bondi_constraints(cce_data[key])\n",
    "  except Exception as e:\n",
    "    failed_keys[key] = str(e)\n",
    "    print(f\"Failed to load and pickle data for key {key}: {e}\")\n",
    "    continue\n",
    "\n",
    "print(abd_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bondi_norms_to_plot = [0, 1, 2, 3, 4, 5]\n",
    "# bondi_norms_to_plot = [0,1,3,4,2]\n",
    "# bondi_norms_to_plot = [2]\n",
    "\n",
    "t_min = -10000\n",
    "# t_min = 700\n",
    "# t_min = 2500\n",
    "# t_min = 7500\n",
    "# t_min = 4000 - 250\n",
    "t_max = 100000\n",
    "# t_max = 7751.5\n",
    "# t_max = 1200\n",
    "# t_max = 3600\n",
    "t_max = 4000\n",
    "# t_max = 7000\n",
    "\n",
    "labels = None\n",
    "# labels={\n",
    "# #  \"high_accuracy_Lev5_R0258\" : \"Lev5_ode_tol_R0258\",\n",
    "#  \"6_set1_L3s3_200\" : \"Lev3_variant_R0200\",\n",
    "#  \"6_set1_L3s3_250\" : \"Lev3_variant_R0250\",\n",
    "#  \"6_set1_L3s3_300\" : \"Lev3_variant_R0300\",\n",
    "#  \"6_set1_L3s2_200\" : \"Lev2_variant_R0200\",\n",
    "#  \"6_set1_L3s2_250\" : \"Lev2_variant_R0250\",\n",
    "#  \"6_set1_L3s2_300\" : \"Lev2_variant_R0300\",\n",
    "# }\n",
    "\n",
    "\n",
    "def get_radius(run_name):\n",
    "    radius_part = run_name.split(\"_\")[-1]\n",
    "    a = \"\".join([i for i in radius_part if i.isdigit()])\n",
    "    return int(a)\n",
    "\n",
    "\n",
    "min_radius = 0\n",
    "min_radius = 200\n",
    "# min_radius = 310\n",
    "max_radius = 1000\n",
    "max_radius = 360\n",
    "# max_radius = 460\n",
    "\n",
    "line_styles = cycle([\"-\", \"--\", \"-.\", \":\"])\n",
    "y_list = []\n",
    "for num_key, key in enumerate(abd_data):\n",
    "    # if \"6\" not in key:\n",
    "    #     continue\n",
    "\n",
    "    line_style = next(line_styles)\n",
    "    plt.gca().set_prop_cycle(None)\n",
    "    #   if num_key%6 == 0:\n",
    "    #     plt.gca().set_prop_cycle(None)\n",
    "    violation_dict = abd_data[key][\"bondi_violation_norms\"]\n",
    "    #   radius = get_radius(key)\n",
    "    #   if radius > max_radius or radius < min_radius:\n",
    "    #     continue\n",
    "    #   if \"_12_\" not  in key:\n",
    "    #     continue\n",
    "    #   if \"cdg1\" not in key:\n",
    "    #     continue\n",
    "    # if \"_main_q3_18\" not in key:\n",
    "    #   continue\n",
    "    #   if \"L6s6\" not in key:\n",
    "    #     continue\n",
    "    #   if \"3000\" not in key:\n",
    "    #     continue\n",
    "    #   if not re.search(r'L6s[1,2,3,4,5,6]_200',key):\n",
    "    #     continue\n",
    "    #   if not re.search(r'[\\_,0]250$',key):\n",
    "    #     continue\n",
    "    # if not re.search(r'[\\_,0][2-9]??$',key):\n",
    "    #   continue\n",
    "\n",
    "    t_arr = abd_data[key][\"abd\"].t\n",
    "    trimmed_indices = (t_arr > t_min) & (t_arr < t_max)\n",
    "    t_arr = t_arr[trimmed_indices]\n",
    "\n",
    "    for i in bondi_norms_to_plot:\n",
    "        if labels is None:\n",
    "            plt.semilogy(t_arr, violation_dict[i][trimmed_indices], line_style, label=f\"{key}_{i}\")\n",
    "        #   plt.plot(t_arr,violation_dict[i][trimmed_indices],line_style, label=f\"{key}\")\n",
    "        # plt.semilogy(t_arr,violation_dict[i][trimmed_indices])\n",
    "        else:\n",
    "            plt.semilogy(\n",
    "                t_arr, violation_dict[i][trimmed_indices], line_style, label=f\"{labels[key]}_{i}\"\n",
    "            )\n",
    "\n",
    "    plt.xlabel(\"t(M)\")\n",
    "    plt.ylabel(f\"bondi violations {bondi_norms_to_plot}\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "#   plt.show()\n",
    "# plt.savefig(Path(\"/home/hchaudha/notes/spec_accuracy/CCE/new_set_L3\")/f\"violations_alllll_{bondi_norms_to_plot}_t={t_min}-{t_max}.png\")\n",
    "# plt.savefig(Path(\"/home/hchaudha/notes/spec_accuracy/CCE/\")/f\"{bondi_norms_to_plot}_t={t_min}-{t_max}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_val = {}\n",
    "r = []\n",
    "val = []\n",
    "for key in abd_data.keys():\n",
    "    r.append(int(key.split(\"_\")[-1]))\n",
    "    val.append(abd_data[key]['bondi_violation_norms'][2][-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = abd_data['14_NIR_0006']['abd'].t\n",
    "y = abd_data['14_NIR_0006']['bondi_violation_norms'][2]\n",
    "x = np.log10(x)\n",
    "y = np.log10(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Fit a line y = m*x + b\n",
    "coeffs = np.polyfit(x, y, deg=1)\n",
    "m, b = coeffs\n",
    "\n",
    "# Predict y values\n",
    "y_fit = m * x + b\n",
    "\n",
    "# Print results\n",
    "print(f\"Slope: {m}, Intercept: {b}\")\n",
    "\n",
    "# Plotting\n",
    "plt.scatter(x, y, label='Data')\n",
    "plt.plot(x, y_fit, color='red', label=f'Fit: y = {m:.2f}x + {b:.2f}')\n",
    "plt.xlabel('log10(Extraction Radius)')\n",
    "plt.ylabel('log10(Bondi violation 2)') \n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other bondi stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bondi_norms_to_plot = [0,1,2,3,4,5]\n",
    "bondi_norms_to_plot = [2]\n",
    "\n",
    "t_min = -10000\n",
    "# t_min = 1200\n",
    "# t_min = 2500\n",
    "# t_min = 7500\n",
    "# t_min = 4000 - 250\n",
    "t_max = 100000\n",
    "# t_max = 7751.5\n",
    "# t_max = 1200\n",
    "# t_max = 3600\n",
    "# t_max = 4000\n",
    "# t_max = 7000\n",
    "\n",
    "labels = None\n",
    "# labels={\n",
    "# #  \"high_accuracy_Lev5_R0258\" : \"Lev5_ode_tol_R0258\",\n",
    "#  \"6_set1_L3s3_200\" : \"Lev3_variant_R0200\",\n",
    "#  \"6_set1_L3s3_250\" : \"Lev3_variant_R0250\",\n",
    "#  \"6_set1_L3s3_300\" : \"Lev3_variant_R0300\",\n",
    "#  \"6_set1_L3s2_200\" : \"Lev2_variant_R0200\",\n",
    "#  \"6_set1_L3s2_250\" : \"Lev2_variant_R0250\",\n",
    "#  \"6_set1_L3s2_300\" : \"Lev2_variant_R0300\",\n",
    "# }\n",
    "\n",
    "def get_radius(run_name):\n",
    "  radius_part = run_name.split(\"_\")[-1]\n",
    "  a = \"\".join([i for i in radius_part if i.isdigit()])\n",
    "  return int(a)\n",
    "\n",
    "min_radius = 0\n",
    "# min_radius = 260\n",
    "max_radius = 1000\n",
    "# max_radius = 360\n",
    "\n",
    "y_list = []\n",
    "for key in list(abd_data.keys())[::-1]:\n",
    "#   violation_dict = abd_data[key]['bondi_violation_norms']\n",
    "#   radius = get_radius(key)\n",
    "#   if radius > max_radius or radius < min_radius:\n",
    "#     continue\n",
    "  # if \"Factor\" in key:\n",
    "  #   continue\n",
    "#   if \"high\" in key:\n",
    "#     continue\n",
    "  # if \"_main_q3_18\" not in key:\n",
    "  #   continue\n",
    "#   if \"L6\" not in key:\n",
    "#     continue\n",
    "#   if \"s6\" not in key:\n",
    "#     continue\n",
    "#   if \"3000\" not in key:\n",
    "#     continue\n",
    "#   if not re.search(r'L6s[1,2,3,4,5,6]_200',key):\n",
    "#     continue\n",
    "#   if not re.search(r'[\\_,0]250$',key):\n",
    "#     continue\n",
    "  # if not re.search(r'[\\_,0][2-9]??$',key):\n",
    "  #   continue\n",
    "  print(key)\n",
    "  violation_dict = abd_data[key]['abd'].bondi_rest_mass()\n",
    "#   violation_dict = abd_data[key]['abd'].bondi_angular_momentum()\n",
    "\n",
    "  t_arr = abd_data[key][\"abd\"].t\n",
    "  trimmed_indices = (t_arr>t_min) & (t_arr<t_max)\n",
    "  t_arr = t_arr[trimmed_indices]\n",
    "\n",
    "  print(key)\n",
    "  violation_dict = abd_data[key]['abd'].bondi_rest_mass() - 1.0\n",
    "  plt.plot(t_arr,violation_dict[trimmed_indices],label=f\"{key}\")\n",
    "\n",
    "\n",
    "#   violation_dict = abd_data[key]['abd'].bondi_angular_momentum()\n",
    "#   plt.plot(t_arr,violation_dict[:,0][trimmed_indices],label=f\"{key}_0\")\n",
    "#   plt.plot(t_arr,violation_dict[:,1][trimmed_indices],label=f\"{key}_1\")\n",
    "#   plt.plot(t_arr,violation_dict[:,2][trimmed_indices],label=f\"{key}_2\")\n",
    "\n",
    "\n",
    "  plt.xlabel('t(M)')\n",
    "  plt.ylabel(\"bond_rest_mass - 1.0\")\n",
    "#   plt.ylabel(f\"bondi violations \")\n",
    "  plt.legend()\n",
    "  plt.tight_layout()\n",
    "  # plt.show()\n",
    "  # plt.savefig(Path(\"/home/hchaudha/notes/spec_accuracy/CCE/new_set_L3\")/f\"violations_alllll_{bondi_norms_to_plot}_t={t_min}-{t_max}.png\")\n",
    "  # plt.savefig(Path(\"/home/hchaudha/notes/spec_accuracy/CCE/\")/f\"{bondi_norms_to_plot}_t={t_min}-{t_max}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ylabel(\"bond_rest_mass - 1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bondi_norms_to_plot = [0,1,2,3,4,5]\n",
    "bondi_norms_to_plot = [2]\n",
    "\n",
    "t_min = -10000\n",
    "t_min = 2000\n",
    "t_min = 2500\n",
    "# t_min = 7500\n",
    "# t_min = 4000 - 250\n",
    "t_max = 10000\n",
    "# t_max = 7751.5\n",
    "# t_max = 1200\n",
    "t_max = 3600\n",
    "# t_max = 4000\n",
    "# t_max = 7000\n",
    "\n",
    "labels = None\n",
    "labels={\n",
    "#  \"high_accuracy_Lev5_R0258\" : \"Lev5_ode_tol_R0258\",\n",
    " \"6_set1_L6s1_250\" : \"New Level 1\",\n",
    " \"6_set1_L6s2_250\" : \"New Level 2\",\n",
    " \"6_set1_L6s3_250\" : \"New Level 3\",\n",
    " \"6_set1_L6s4_250\" : \"New Level 4\",\n",
    " \"6_set1_L6s5_250\" : \"New Level 5\",\n",
    "\"high_accuracy_Lev1_R0257\": \"Old Level 1\",\n",
    "\"high_accuracy_Lev2_R0257\": \"Old Level 2\",\n",
    "\"high_accuracy_Lev3_R0258\": \"Old Level 3\",\n",
    "\"high_accuracy_Lev4_R0258\": \"Old Level 4\",\n",
    "\"high_accuracy_Lev5_R0258\": \"Old Level 5\",\n",
    "}\n",
    "\n",
    "def get_radius(run_name):\n",
    "  radius_part = run_name.split(\"_\")[-1]\n",
    "  a = \"\".join([i for i in radius_part if i.isdigit()])\n",
    "  return int(a)\n",
    "\n",
    "min_radius = 0\n",
    "# min_radius = 260\n",
    "max_radius = 1000\n",
    "max_radius = 360\n",
    "\n",
    "y_list = []\n",
    "\n",
    "with plt.style.context('ggplot'):\n",
    "    plt.rcParams[\"figure.figsize\"] = (8,4)\n",
    "    # plt.rcParams[\"figure.figsize\"] = (10,8)\n",
    "    fig,ax = plt.subplots(1, 2)\n",
    "\n",
    "\n",
    "    for key in ['high_accuracy_Lev1_R0257', 'high_accuracy_Lev2_R0257', 'high_accuracy_Lev3_R0258', 'high_accuracy_Lev4_R0258', 'high_accuracy_Lev5_R0258']:\n",
    "        violation_dict = abd_data[key]['bondi_violation_norms']\n",
    "        t_arr = abd_data[key][\"abd\"].t\n",
    "        trimmed_indices = (t_arr>t_min) & (t_arr<t_max)\n",
    "        t_arr = t_arr[trimmed_indices]\n",
    "\n",
    "        ax[0].semilogy(t_arr,violation_dict[i][trimmed_indices],label=f\"{labels[key]}\")\n",
    "        ax[0].set_xlabel('t(M)')\n",
    "        ax[0].legend(loc='upper right')\n",
    "        ax[0].set_ylim(5e-8,3e-6)\n",
    "\n",
    "    for key in ['6_set1_L6s1_250', '6_set1_L6s2_250', '6_set1_L6s3_250', '6_set1_L6s4_250', '6_set1_L6s5_250']:\n",
    "        violation_dict = abd_data[key]['bondi_violation_norms']\n",
    "        t_arr = abd_data[key][\"abd\"].t\n",
    "        trimmed_indices = (t_arr>t_min) & (t_arr<t_max)\n",
    "        t_arr = t_arr[trimmed_indices]\n",
    "\n",
    "        ax[1].semilogy(t_arr,violation_dict[i][trimmed_indices],label=f\"{labels[key]}\")\n",
    "        ax[1].legend(loc='upper right')\n",
    "        ax[1].set_xlabel('t(M)')\n",
    "        ax[1].set_ylim(5e-8,3e-6)\n",
    "\n",
    "    fig.suptitle(\"Bondi constraint violations in CCE waveforms\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(Path(\"/groups/sxs/hchaudha/scripts/report/figures\")/f\"Bondi constraints.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "one_over_x = y_list[0]*1e2/np.array(radius)\n",
    "one_over_x2 = y_list[0]*1e4/np.array(radius)**2\n",
    "\n",
    "# Define the fitting function\n",
    "def fitting_func(r, a, b):\n",
    "    return a / r**b\n",
    "popt, pcov = curve_fit(fitting_func, radius, y_list,p0=[y_list[0],2])\n",
    "a_fit, b_fit = popt\n",
    "\n",
    "# Create a smooth curve for the fitted function\n",
    "fit_vals = fitting_func(radius, a_fit, b_fit)\n",
    "\n",
    "plt.plot(radius,y_list, label=f\"power in mode \",marker='x')\n",
    "# plt.plot(radius,one_over_x, label=\"1/x\",marker='x')\n",
    "# plt.plot(radius,one_over_x2, label=\"1/(x*x)\",marker='x')\n",
    "plt.plot(radius,fit_vals,label=f'Fit: a/r^b, a={a_fit:.2e}, b={b_fit:.2f}', linestyle='--')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.xlabel('r(M)')\n",
    "# plt.ylabel('power in modes')\n",
    "# plt.title(f\"L={L_list}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot cce waveform diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_radius(run_name):\n",
    "  radius_part = run_name.split(\"_\")[-1]\n",
    "  a = \"\".join([i for i in radius_part if i.isdigit()])\n",
    "  return int(a)\n",
    "\n",
    "for i in abd_data.keys():\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes_to_plot = [(3,2)]\n",
    "modes_to_plot = [(2,2)]\n",
    "\n",
    "# base_key = 'high_accuracy_Lev5_R0258'\n",
    "# base_key = 'high_accuracy_Lev2_R0257'\n",
    "# base_key = '6_set1_L6s4_250'\n",
    "base_key = '22_set1_L3_long_0300'\n",
    "# base_key = '22_set1_L3_long_0250'\n",
    "# base_key = '12_set1_L3_2500_0350'\n",
    "# base_key = '6_set1_L3s3_250'\n",
    "# base_key = '6_set1_L6s6_250'\n",
    "radius = get_radius(base_key)\n",
    "\n",
    "plot_vals = [\"_diff\",\"_absdiff\",\"_rel_diff\",\"_rel_absdiff\"]\n",
    "plot_vals = [\"_absdiff\",\"_rel_absdiff\"]\n",
    "# plot_vals = [\"_rel_absdiff\"]\n",
    "\n",
    "t_min = 0\n",
    "# t_min = 2000\n",
    "# t_min = 2500\n",
    "# t_min = 1190\n",
    "# t_min = 4000\n",
    "t_max = 10000\n",
    "# t_max = 7751.5\n",
    "# t_max = 7000\n",
    "# t_max = 6000\n",
    "# t_max = 3500\n",
    "t_interpolate = np.linspace(t_min,t_max,num=5000)\n",
    "\n",
    "def filter(key):\n",
    "  min_radius = 0\n",
    "  min_radius = 200\n",
    "  max_radius = 1000\n",
    "#   max_radius = 550\n",
    "\n",
    "  radius = get_radius(key)\n",
    "  if radius > max_radius or radius < min_radius:\n",
    "    return True\n",
    "  if key == base_key:\n",
    "    return True\n",
    "  if 'L3_long_0250' not in key:\n",
    "    return True\n",
    "  # if not re.search(r\"Lev[3,4,5]\",key):\n",
    "  #   return True\n",
    "#   if not re.search(r\"s[0,1,2]\",key):\n",
    "#     return True\n",
    "  # if 's3' in key:\n",
    "  #   return True\n",
    "\n",
    "num_colors_required = len(modes_to_plot)*(len(abd_data)-1)\n",
    "\n",
    "num_colors_required = 0\n",
    "for mode,key in itertools.product(modes_to_plot,abd_data):\n",
    "  if filter(key):\n",
    "    continue\n",
    "  num_colors_required = num_colors_required + 1\n",
    "\n",
    "if num_colors_required <=10:\n",
    "  cmap = plt.get_cmap('tab10')\n",
    "  color = [cmap(i) for i in range(num_colors_required )]\n",
    "elif num_colors_required <=20:\n",
    "  cmap = plt.get_cmap('tab20')\n",
    "  color = [cmap(i) for i in range(num_colors_required )]\n",
    "else:\n",
    "  color=plt.cm.hsv(np.linspace(0, 1, num_colors_required))\n",
    "  # color=plt.cm.gist_rainbow(np.linspace(0, 1, num_colors_required))\n",
    "\n",
    "i=-1\n",
    "plt.close()\n",
    "for mode,key in itertools.product(modes_to_plot,abd_data):\n",
    "  l,m = mode\n",
    "  if filter(key):\n",
    "    continue\n",
    "\n",
    "  diff_dict = create_diff_dict_cce(abd_data,l=l,m=m,base_key=base_key,t_interpolate=t_interpolate)\n",
    "  t_arr = diff_dict[\"t\"]\n",
    "\n",
    "  i = i+1\n",
    "  for plot_val in plot_vals:\n",
    "    match plot_val:\n",
    "      case \"_rel_absdiff\":\n",
    "        plt.semilogy(t_arr,diff_dict[key+plot_val],label=f\"{key}_{mode}\"+plot_val,linestyle=\"-\",color=color[i])\n",
    "      case \"_absdiff\":\n",
    "        # plt.semilogy(t_arr,diff_dict[key+plot_val],label=f\"{key}_{mode}\"+plot_val,linestyle=\":\",color=color[i])\n",
    "        plt.semilogy(t_arr,diff_dict[key+plot_val],linestyle=\":\",color=color[i])\n",
    "      case \"_diff\":\n",
    "        plt.semilogy(t_arr,diff_dict[key+plot_val],label=f\"{key}_{mode}\"+plot_val,linestyle=\"--\",color=color[i])\n",
    "      case \"_rel_diff\":\n",
    "        plt.semilogy(t_arr,diff_dict[key+plot_val],label=f\"{key}_{mode}\"+plot_val,linestyle=\"-.\",color=color[i])\n",
    "\n",
    "    plt.xlabel('t')\n",
    "    plt.ylabel(\"diff\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.title(f\"CCE waveform diff {modes_to_plot} {base_key=}\")\n",
    "    # plt.savefig(Path(\"/home/hchaudha/notes/spec_accuracy/CCE/new_set_L3\")/f\"violations_alllll_{bondi_norms_to_plot}_t={t_min}-{t_max}.png\")\n",
    "    # plt.savefig(Path(\"/home/hchaudha/notes/spec_accuracy/CCE/\")/f\"{bondi_norms_to_plot}_t={t_min}-{t_max}.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CCE frame fixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "wave1 = deepcopy(abd_data['22_set1_L3_long_0300']['abd'])\n",
    "wave2 = deepcopy(abd_data['22_set1_L3_long_0350']['abd'])\n",
    "wave2 = deepcopy(abd_data['22_L3_AC_L3_res_10_C_0300']['abd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abd_prime1,transformations1,err1 = wave1.map_to_superrest_frame(t_0=9000)\n",
    "abd_prime2,transformations2,err2 = wave2.map_to_superrest_frame(t_0=9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l,m = 2,2\n",
    "\n",
    "h1 = abd_prime1.h\n",
    "y1 = h1.data[:, lm(2,2, h1.ell_min)]\n",
    "\n",
    "h2 = abd_prime2.h\n",
    "y2 = h2.data[:, lm(2,2, h2.ell_min)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l,m = 2,2\n",
    "\n",
    "h1 = wave1.h\n",
    "y1 = h1.data[:, lm(2,2, h1.ell_min)]\n",
    "\n",
    "h2 = wave2.h\n",
    "y2 = h2.data[:, lm(2,2, h2.ell_min)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h1.t,np.abs(y1), label='y1')\n",
    "plt.plot(h2.t,np.abs(y2), label='y2')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(h1.t,y1-y2, label='y1-y2')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finite radius waveform comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_radii(h5_file_path:Path):\n",
    "  radii = set()\n",
    "  with h5py.File(h5_file_path,'r') as f:\n",
    "    names = []\n",
    "    f.visit(names.append)\n",
    "  for name in names:\n",
    "    if \"Version\" in name:\n",
    "      continue\n",
    "    radii.add(name[1:5])\n",
    "  radii = list(radii)\n",
    "  radii.sort()\n",
    "  return radii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GW_data_path= {}\n",
    "# GW_data_path[\"master_Lev0\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev/GW_data\")\n",
    "# GW_data_path[\"master_Lev1\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev/GW_data_lev1\")\n",
    "# GW_data_path[\"master_Lev2\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev/GW_data_lev2\")\n",
    "# GW_data_path[\"master_Lev3\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_master/Ev/GW_data_lev3\")\n",
    "# GW_data_path[\"master_Lev4\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_master/Ev/GW_data_lev4\")\n",
    "# GW_data_path[\"master_Lev5\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_master/Ev/GW_data_lev5\")\n",
    "\n",
    "# GW_data_path[\"high_accuracy_Lev0\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev0/rh_FiniteRadii_CodeUnits\")\n",
    "# GW_data_path[\"high_accuracy_Lev1\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev1/rh_FiniteRadii_CodeUnits\")\n",
    "# GW_data_path[\"high_accuracy_Lev2\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev2/rh_FiniteRadii_CodeUnits\")\n",
    "# GW_data_path[\"high_accuracy_Lev0\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/Lev0_AC/Run/GW2/\")\n",
    "# GW_data_path[\"high_accuracy_Lev1\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/Lev1_AC/Run/GW2/\")\n",
    "# GW_data_path[\"high_accuracy_Lev2\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/Lev2_AC/Run/GW2/\")\n",
    "# GW_data_path[\"high_accuracy_Lev3\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/GW_data_lev3/rh_FiniteRadii_CodeUnits\")\n",
    "# GW_data_path[\"high_accuracy_Lev4\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/GW_data_lev4/rh_FiniteRadii_CodeUnits\")\n",
    "# GW_data_path[\"high_accuracy_Lev45\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/Lev45_AC/Run/GW2/\")\n",
    "# GW_data_path[\"high_accuracy_Lev5\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/GW_data_lev5/rh_FiniteRadii_CodeUnits\")\n",
    "# GW_data_path[\"high_accuracy_Lev55\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/Lev55_AC/Run/GW2/\")\n",
    "\n",
    "# GW_data_path[\"20_zero_spin_AMR_L5_10000M\"] = Path(\"/groups/sxs/hchaudha/spec_runs/single_bh/20_zero_spin_AMR_L5_10000M/GW_data/long_16_2565_10000_14/rh_FiniteRadii_CodeUnits\")\n",
    "\n",
    "levs,run_sets,radius= [],[],[]\n",
    "levs = [1,2,3,4,5,6]\n",
    "# levs = [0,1,2,3]\n",
    "# levs = [4,5]\n",
    "# levs = [0,2,3,4,5]\n",
    "# levs = [0]\n",
    "run_sets = [1]\n",
    "# run_sets = [1]\n",
    "\n",
    "for l,s in itertools.product(levs,run_sets):\n",
    "  if s == 2 and (l == 0 or l==1):\n",
    "    continue\n",
    "#   if l <= 3:\n",
    "#     GW_data_path[f\"6_set{s}_L3s{l}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/6_segs/6_set{s}_L3/GW_data_lev{l}/rh_FiniteRadii_CodeUnits\")\n",
    "#   else:\n",
    "  GW_data_path[f\"6_set{s}_L6s{l}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/6_segs/6_set{s}_L6/GW_data_lev{l}/rh_FiniteRadii_CodeUnits\")\n",
    "\n",
    "\n",
    "# levs = [1,2,3,4,5,6]\n",
    "# for l in levs:\n",
    "#   GW_data_path[f\"main_s{l}\"] = Path(f\"/resnick/groups/sxs/hchaudha/spec_runs/34_master_L16/GW_data_lev{l}/rh_FiniteRadii_CodeUnits/\")\n",
    "\n",
    "file = \"rh_FiniteRadii_CodeUnits.h5\"\n",
    "for key in GW_data_path:\n",
    "  GW_data_path[key] = GW_data_path[key]/file\n",
    "  if not GW_data_path[key].exists():\n",
    "    raise Exception(f\"{key}, {GW_data_path[key]} does not exists!\")\n",
    "radii_list = extract_radii(list(GW_data_path.values())[0])\n",
    "print(radii_list)\n",
    "print(GW_data_path.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GW_data = {}\n",
    "# for radius in radii_list:\n",
    "for radius in [radii_list[9]]:\n",
    "# for radius in list(np.array(radii_list)[[0,4,8,12,15,17,19,21,23]]):\n",
    "# for radius in list(np.array(radii_list)[[0,4,12,19,23]]):\n",
    "    for key in GW_data_path:\n",
    "        key_name = key + \"_\" + radius\n",
    "        GW_data[key_name] = scri.SpEC.read_from_h5(\n",
    "            f\"{GW_data_path[key]}/R{radius}.dir\",\n",
    "            dataType=scri.h,\n",
    "            frameType=scri.Inertial,\n",
    "            r_is_scaled_out=False,\n",
    "            m_is_scaled_out=False,\n",
    "        )\n",
    "        print(f\"{key_name} loaded!\")\n",
    "\n",
    "print(GW_data.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "def indices_of_a_mode(L, ell_min):\n",
    "    if L is None:\n",
    "        return None\n",
    "    indices = []\n",
    "    if L < ell_min:\n",
    "        return indices\n",
    "    for m in range(-L, L + 1):\n",
    "        indices.append(lm(L, m, ell_min))\n",
    "    return indices\n",
    "\n",
    "def have_same_extraction_radius(key1, key2):\n",
    "    rad1 = key1.split(\"_\")[-1]\n",
    "    rad2 = key2.split(\"_\")[-1]\n",
    "    if rad1 == rad2:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def pair_mismatch(GW_data, t1, t2, modes=None, pair_alg=\"all\",split_by_radius=False):\n",
    "    mismatch = {}\n",
    "\n",
    "    # This is to deal with the situation where we have multiple levels with multiple extraction radii.\n",
    "    dict_by_radius = defaultdict(dict)\n",
    "    for key, val in GW_data.items():\n",
    "        suffix = key.split(\"_\")[-1]\n",
    "        dict_by_radius[suffix][key] = val\n",
    "\n",
    "    for suffix, data in dict_by_radius.items():\n",
    "        keys = sorted(list(data.keys()))\n",
    "        print(data.keys())\n",
    "        if pair_alg == \"alternate\":\n",
    "            for i, j in zip(keys[:-1], keys[1:]):\n",
    "                mismatch[i + \"@\" + j] = SquaredError(\n",
    "                    data[i], data[j], modes=modes, t1=t1, t2=t2\n",
    "                )\n",
    "        elif pair_alg == \"wrt_highest\":\n",
    "            j = keys[-1]\n",
    "            for i in keys[:-1]:\n",
    "                mismatch[i + \"@\" + j] = SquaredError(\n",
    "                    data[i], data[j], modes=modes, t1=t1, t2=t2\n",
    "                )\n",
    "        elif pair_alg == \"all\":\n",
    "            for i, j in itertools.combinations(keys, 2):\n",
    "                mismatch[i + \"@\" + j] = SquaredError(\n",
    "                    data[i], data[j], modes=modes, t1=t1, t2=t2\n",
    "                )\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Unknown pair algorithm: {pair_alg}, must be one of 'alternate', 'wrt_highest', 'all'\"\n",
    "            )\n",
    "\n",
    "    if split_by_radius:\n",
    "        mismatch_by_radius = defaultdict(dict)\n",
    "        for key, val in mismatch.items():\n",
    "            radius = key.split(\"@\")[0].split(\"_\")[-1]\n",
    "            mismatch_by_radius[radius][key] = val\n",
    "        return mismatch_by_radius\n",
    "    else:\n",
    "        return mismatch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Lmode = None\n",
    "# Lmode = 8\n",
    "mode_indices = indices_of_a_mode(Lmode, GW_data[list(GW_data.keys())[0]].ell_min)\n",
    "\n",
    "# mismatch_dict = pair_mismatch(GW_data, t1=1200, t2=4000, pair_alg=\"alternate\",modes=mode_indices)\n",
    "mismatch_dict = pair_mismatch(GW_data, t1=1200, t2=4000, pair_alg=\"alternate\", modes=mode_indices)\n",
    "# mismatch_dict = pair_mismatch(GW_data, t1=1200, t2=4000, pair_alg=\"all\",modes=mode_indices)\n",
    "mismatch_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig,ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "filter_dict = {\n",
    "    's1,s2': {},\n",
    "    's2,s3': {},\n",
    "    's3,s4': {},\n",
    "    's4,s5': {},\n",
    "    's5,s6': {},\n",
    "}\n",
    "for key, val in mismatch_dict.items():\n",
    "    for s in filter_dict.keys():\n",
    "        matching_keys = True\n",
    "        for i in s.split(\",\"):\n",
    "            if i not in key:\n",
    "                matching_keys = False\n",
    "        if matching_keys:\n",
    "            filter_dict[s][key] = val\n",
    "\n",
    "for s, mismatch_dict_local in filter_dict.items():\n",
    "    radius_arr = [int(key.split(\"_\")[-1]) for key in mismatch_dict_local.keys()]\n",
    "    val_arr = [i for i in mismatch_dict_local.values()]\n",
    "    ax.scatter(radius_arr, val_arr, label=s)\n",
    "\n",
    "# ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel(\"Extraction Radius (M)\")\n",
    "if Lmode is not None:\n",
    "    ax.set_ylabel(f\"Mismatch for L={Lmode}\")\n",
    "    ax.set_title(f\"Mismatch for L={Lmode} vs Extraction Radius\")\n",
    "else:\n",
    "    ax.set_ylabel(\"Mismatch\")\n",
    "    ax.set_title(\"Mismatch vs Extraction Radius\")\n",
    "plt.legend(loc='upper right')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius_arr = [int(key.split(\"_\")[-1]) for key in mismatch_dict.keys()]\n",
    "val_arr = [i for i in mismatch_dict.values()]\n",
    "\n",
    "fig,ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "ax.scatter(radius_arr, val_arr)\n",
    "# ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel(\"Extraction Radius (M)\")\n",
    "if Lmode is not None:\n",
    "    ax.set_ylabel(f\"Mismatch for L={Lmode}\")\n",
    "    ax.set_title(f\"Mismatch for L={Lmode} vs Extraction Radius\")\n",
    "else:\n",
    "    ax.set_ylabel(\"Mismatch\")\n",
    "    ax.set_title(\"Mismatch vs Extraction Radius\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variation by modes\n",
    "\n",
    "Load a single extraction radii with multiple levs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch_dict = {}\n",
    "for Lmode in [\"all\", 2, 3, 4, 5, 6, 7, 8]:\n",
    "    if Lmode == \"all\":\n",
    "        mode_indices = None\n",
    "    else:\n",
    "        mode_indices = indices_of_a_mode(\n",
    "            Lmode, GW_data[list(GW_data.keys())[0]].ell_min\n",
    "        )\n",
    "    # mismatch_dict[str(Lmode)] = pair_mismatch(GW_data, t1=1200, t2=4000, pair_alg=\"alternate\",modes=mode_indices)\n",
    "    mismatch_dict[str(Lmode)] = pair_mismatch(\n",
    "        GW_data, t1=1200, t2=4000, pair_alg=\"alternate\", modes=mode_indices\n",
    "    )\n",
    "    # mismatch_dict[str(Lmode)] = pair_mismatch(GW_data, t1=1200, t2=4000, pair_alg=\"all\",modes=mode_indices)\n",
    "mismatch_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig,ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "filter_dict = {\n",
    "    's1,s2': {},\n",
    "    's2,s3': {},\n",
    "    's3,s4': {},\n",
    "    's4,s5': {},\n",
    "    's5,s6': {},\n",
    "}\n",
    "\n",
    "for key, val in mismatch_dict.items():\n",
    "    for key1, val1 in val.items():\n",
    "        for s in filter_dict.keys():\n",
    "            matching_keys = True\n",
    "            for i in s.split(\",\"):\n",
    "                if i not in key1:\n",
    "                    matching_keys = False\n",
    "            if matching_keys:\n",
    "                filter_dict[s][key] = val1\n",
    "\n",
    "for s, mismatch_dict_local in filter_dict.items():\n",
    "\n",
    "    x_labels = mismatch_dict_local.keys()\n",
    "    val_arr = [i for i in mismatch_dict_local.values()]\n",
    "    ax.scatter(range(len(x_labels)), val_arr, label=s)\n",
    "\n",
    "# ax.set_xscale('log')\n",
    "\n",
    "ax.set_xticks(range(len(x_labels)))\n",
    "ax.set_xticklabels(x_labels, ha='right')\n",
    "\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel(\"Modes\")\n",
    "ax.set_ylabel(\"Mismatch\")\n",
    "ax.set_title(list(GW_data.keys())[-1])\n",
    "ax.set_ylim(1e-11, 1e-1)\n",
    "plt.legend(loc='upper left')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Older stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l, m = 2,2\n",
    "t_max = 3500\n",
    "t_interpolate = np.linspace(1200+int(radius),t_max+int(radius),num=5000)\n",
    "\n",
    "def np_abs_func(x):\n",
    "  return np.abs(np.real(x))\n",
    "  # return np.abs(x)\n",
    "\n",
    "for key in GW_data:\n",
    "#   if 'L6' not in key:\n",
    "#     continue\n",
    "#   if not re.search(r'Lev[3,4,5]',key):\n",
    "#     continue\n",
    "\n",
    "  h = GW_data[key].interpolate(t_interpolate)\n",
    "  shited_time = h.t - int(radius)\n",
    "  diff = h.data[:, lm(l,m,h.ell_min)] \n",
    "  diff = np_abs_func(diff)\n",
    "  plt.plot(shited_time,diff,label=f'{key}_{l=}_{m=}')\n",
    "  # plt.plot(shited_time,diff_normalize,label=f'{key}_rel_{l=}_{m=}')\n",
    "  # plt.plot(shited_time,base_h.data[:, lm(l,m,h.ell_min)],label=f'{key}_rel2_{l=}_{m=}')\n",
    "  # plt.plot(shited_time,np_abs_func(base_h.data[:, lm(l,m,h.ell_min)]),label=f'{key}_rel2_{l=}_{m=}')\n",
    "  # plt.semilogy(h.t,h.energy_flux(),label=f'{key}')\n",
    "\n",
    "plt.title(f\"diff:{base_key}  {l=},{m=}, {radius=}\")\n",
    "plt.xlabel('t')\n",
    "plt.ylabel(\"diff\")\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(Path(\"/home/hchaudha/notes/spec_accuracy/del/LevVariations\")/f\"L05_finite_radius_{base_key}_{l=}_{m=}_{radius}_{t_max=}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "l, m = 2,2\n",
    "t_max = 3500\n",
    "t_interpolate = np.linspace(1200+int(radius),t_max+int(radius),num=5000)\n",
    "\n",
    "base_key = 'master_Lev5'\n",
    "# base_key = 'master_Lev2'\n",
    "base_key = 'high_accuracy_Lev5'\n",
    "# base_key = 'high_accuracy_Lev2'\n",
    "# base_key = '6_set1_L6s6'\n",
    "# base_key = '6_set3_L6s5'\n",
    "# base_key = '6_set1_L3s3'\n",
    "# base_key = '6_set2_L3s2'\n",
    "base_h = GW_data[base_key].interpolate(t_interpolate)\n",
    "\n",
    "def np_abs_func(x):\n",
    "  return np.abs(np.real(x))\n",
    "  # return np.abs(x)\n",
    "\n",
    "for key in GW_data:\n",
    "  if 'L6' not in key:\n",
    "    continue\n",
    "#   if not re.search(r'Lev[3,4,5]',key):\n",
    "#     continue\n",
    "  if key == base_key:\n",
    "    continue\n",
    "  h = GW_data[key].interpolate(t_interpolate)\n",
    "  shited_time = h.t - int(radius)\n",
    "  diff = h.data[:, lm(l,m,h.ell_min)] - base_h.data[:, lm(l,m,h.ell_min)]\n",
    "  diff = np_abs_func(diff)\n",
    "  diff_normalize = diff/np_abs_func(base_h.data[:, lm(l,m,h.ell_min)])\n",
    "  plt.plot(shited_time,diff,label=f'{key}_{l=}_{m=}')\n",
    "  # plt.plot(shited_time,diff_normalize,label=f'{key}_rel_{l=}_{m=}')\n",
    "  # plt.plot(shited_time,base_h.data[:, lm(l,m,h.ell_min)],label=f'{key}_rel2_{l=}_{m=}')\n",
    "  # plt.plot(shited_time,np_abs_func(base_h.data[:, lm(l,m,h.ell_min)]),label=f'{key}_rel2_{l=}_{m=}')\n",
    "  # plt.semilogy(h.t,h.energy_flux(),label=f'{key}')\n",
    "\n",
    "plt.title(f\"diff:{base_key}  {l=},{m=}, {radius=}\")\n",
    "plt.xlabel('t')\n",
    "plt.ylabel(\"diff\")\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(Path(\"/home/hchaudha/notes/spec_accuracy/del/LevVariations\")/f\"L05_finite_radius_{base_key}_{l=}_{m=}_{radius}_{t_max=}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# World tube data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_data= {}\n",
    "# WT_data[\"high_accuracy_Lev0_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev0/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"high_accuracy_Lev1_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev1/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"high_accuracy_Lev2_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev2/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"high_accuracy_Lev3_R0258\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/GW_data_lev3/BondiCceR0258/BondiCceR0258.h5\")\n",
    "# WT_data[\"high_accuracy_Lev4_R0258\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/GW_data_lev4/BondiCceR0258/BondiCceR0258.h5\")\n",
    "# WT_data[\"high_accuracy_Lev5_R0258\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/GW_data_lev5/BondiCceR0258/BondiCceR0258.h5\")\n",
    "# WT_data[\"master_Lev0_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev/GW_data/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"master_Lev1_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev/GW_data_lev1/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"master_Lev2_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev/GW_data_lev2/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"master_Lev3_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_master/Ev/GW_data_lev3/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"master_Lev1_R0257\"] = Path(\"/resnick/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_master/GW_data_lev1/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"master_Lev2_R0257\"] = Path(\"/resnick/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_master/GW_data_lev2/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"master_Lev3_R0257\"] = Path(\"/resnick/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_master/GW_data_lev3/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"master_Lev4_R0257\"] = Path(\"/resnick/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_master/GW_data_lev4/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"master_Lev5_R0257\"] = Path(\"/resnick/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_master/GW_data_lev5/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"Lev5_bg_ah100_cd_01_uamr_full_R0258\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_bg_ah100_cd_01_uamr_full/GW_data/BondiCceR0258/BondiCceR0258.h5\")\n",
    "# WT_data[\"Lev5_bg_ah100_cd_01_uamr_full_R0686\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_bg_ah100_cd_01_uamr_full/GW_data/BondiCceR0686/BondiCceR0686.h5\")\n",
    "# WT_data[\"Lev5_bg_ah100_lapse_uamr_fullR0258\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_bg_ah100_lapse_uamr_full/GW_data/BondiCceR0258/BondiCceR0258.h5\")\n",
    "# WT_data[\"Lev5_bg_ah100_lapse_uamr_full_R0100\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_bg_ah100_lapse_uamr_full/GW_data/BondiCceR0100/BondiCceR0100.h5\")\n",
    "# WT_data[\"high_accuracy_Lev5_R0258_ZeroNonSmooth\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/ZeroNonSmooth/red_Lev5_R0258_VolumeData.h5\")\n",
    "# WT_data[\"high_accuracy_Lev5_R0258_NoIncomingRadiation\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/NoIncomingRadiation/red_Lev5_R0258_VolumeData.h5\")\n",
    "# WT_data[\"high_accuracy_Lev5_R0258_InverseCubic\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/InverseCubic/red_Lev5_R0258_VolumeData.h5\")\n",
    "# WT_data[\"high_accuracy_Lev5_R0258_ConformalFactor10\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/ConformalFactor10/red_Lev5_R0258_VolumeData.h5\")\n",
    "# WT_data[\"high_accuracy_Lev5_R0258_ConformalFactor7\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/ConformalFactor7/red_Lev5_R0258_VolumeData.h5\")\n",
    "# WT_data[\"high_accuracy_Lev5_R0258_ConformalFactor3\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/ConformalFactor3/red_Lev5_R0258_VolumeData.h5\")\n",
    "\n",
    "# WT_data[\"Lev01_test_ode_Lev2_257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev2/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"Lev01_test_ode_Lev1_257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev1/BondiCceR0257/BondiCceR0257.h5\")\n",
    "\n",
    "# WT_data[\"Lev01_test_Lev2_257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev/GW_data_lev2/BondiCceR0257/BondiCceR0257.h5\")\n",
    "\n",
    "levs,run_sets,radius= [],[],[]\n",
    "# levs = [1,2,3,4,5,6]\n",
    "levs = [2,3,4,5,6]\n",
    "# levs = [5,4]\n",
    "# levs = [0,1,2,3]\n",
    "# levs = [6]\n",
    "# run_sets = [1,2,3]\n",
    "# run_sets = [1,3]\n",
    "run_sets = [1]\n",
    "radius = [250]\n",
    "# radius = [100,150,200,250,300,350,500,700,900]\n",
    "# radius = [100,250,900]\n",
    "\n",
    "for l,s,r in itertools.product(levs,run_sets,radius):\n",
    "  # if s == 2 and (l == 0 or l==1):\n",
    "  #   continue\n",
    "  # if l <= 3:\n",
    "  #   WT_data[f\"6_set{s}_L3s{l}_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/6_segs/6_set{s}_L3/GW_data_lev{l}/BondiCceR0{r}/BondiCceR0{r}.h5\")\n",
    "  # else:\n",
    "  #   WT_data[f\"6_set{s}_L6s{l}_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/6_segs/6_set{s}_L6/GW_data_lev{l}/BondiCceR0{r}/BondiCceR0{r}.h5\")\n",
    "\n",
    "  WT_data[f\"6_set{s}_L6s{l}_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/6_segs/6_set{s}_L6/GW_data_lev{l}/BondiCceR0{r}/BondiCceR0{r}.h5\")\n",
    "\n",
    "# for i in Path(\"/resnick/groups/sxs/hchaudha/spec_runs/CCE_stuff/Lev4_061CCE/\").glob(\"*.h5\"):\n",
    "#     WT_data[i.name.split(\".\")[0]] = i\n",
    "\n",
    "fail_flag=False\n",
    "for key in WT_data:\n",
    "  if not WT_data[key].exists():\n",
    "    fail_flag = True\n",
    "    print(f\"{WT_data[key]} does not exist!\")\n",
    "  if fail_flag:\n",
    "    raise Exception(\"Some paths do not exist!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ['Beta.dat', 'DrJ.dat', 'DuR.dat', 'H.dat', 'J.dat', 'Q.dat', 'R.dat', 'U.dat', 'W.dat']\n",
    "WT_data_dict = {}\n",
    "for key in WT_data:\n",
    "  WT_data_dict[key] = WT_to_pandas(WT_data[key],keys_to_load=['J.dat'])\n",
    "  print(f\"{key} loaded!\")\n",
    "\n",
    "print(WT_data_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LMPair(L, pre=\"Re\"):\n",
    "    if pre in [\"Re\", \"Im\"]:\n",
    "        return [f\"{pre}({L},{m})\" for m in range(-L, L + 1)]\n",
    "    elif pre == \"ReIm\":\n",
    "        return [f\"Re({L},{m})\" for m in range(-L, L + 1)] + [\n",
    "            f\"Im({L},{m})\" for m in range(-L, L + 1)\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 2\n",
    "\n",
    "\n",
    "def power_in_mode(L, data, pre=\"Re\"):\n",
    "    # data = WT_data_dict[\"6_set1_L6s0_250\"]['J.dat']\n",
    "    all_cols = LMPair(L, pre=pre)\n",
    "    cols_present = []\n",
    "    for col in all_cols:\n",
    "        if col in data.columns:\n",
    "            cols_present.append(col)\n",
    "    if len(cols_present) == 0:\n",
    "        raise Exception(f\"None of the columns {all_cols} are present in the data\")\n",
    "\n",
    "    num_m = len(cols_present)\n",
    "    return np.linalg.norm(data[cols_present], axis=1) / (num_m)\n",
    "\n",
    "\n",
    "def power_in_mode(L, data, pre=\"Re\"):\n",
    "    # Get list of possible column names\n",
    "    all_cols = LMPair(L, pre=pre)\n",
    "    \n",
    "    # Find which columns are present in data\n",
    "    cols_present = [col for col in all_cols if col in data.columns] if isinstance(data, pd.DataFrame) else [col for col in all_cols if col in data.index]\n",
    "    \n",
    "    if len(cols_present) == 0:\n",
    "        raise Exception(f\"None of the columns {all_cols} are present in the data\")\n",
    "\n",
    "    num_m = len(cols_present)\n",
    "    \n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        # DataFrame case: multiple rows\n",
    "        result = np.linalg.norm(data[cols_present], axis=1) / num_m\n",
    "    elif isinstance(data, pd.Series):\n",
    "        # Series case: single row\n",
    "        result = np.linalg.norm(data[cols_present].values) / num_m\n",
    "    else:\n",
    "        raise TypeError(\"data must be a pandas DataFrame or Series\")\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(WT_data_dict.keys())\n",
    "print(WT_data_dict[list(WT_data_dict.keys())[0]].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_val = 3500\n",
    "key = \"master_Lev5_R0257\"\n",
    "key = \"6_set1_L6s6_250\"\n",
    "# key = \"BondiCceR0334\"\n",
    "data = WT_data_dict[key]\n",
    "\n",
    "for var in ['Beta.dat', 'DrJ.dat', 'DuR.dat', 'H.dat', 'J.dat', 'Q.dat', 'R.dat', 'U.dat', 'W.dat']:\n",
    "    data = WT_data_dict[key][var]\n",
    "    t = data[\"t(M)\"]\n",
    "    closest_index = (t - t_val).abs().idxmin()\n",
    "    L_val = []\n",
    "    pow_in_L = []\n",
    "    for L in range(16):\n",
    "        L_val.append(L)\n",
    "        pow_in_L.append(power_in_mode(L, data.iloc[closest_index, :], pre=\"ReIm\"))\n",
    "\n",
    "    # plt.scatter(L_val, pow_in_L, label=var)\n",
    "    plt.plot(L_val, pow_in_L, label=var)\n",
    "plt.legend()\n",
    "plt.xlabel('L')\n",
    "plt.ylabel('Power in mode')\n",
    "plt.title(f\"{key} at {t_val=}M\")\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_val = 3500\n",
    "var = 'J.dat'\n",
    "for key in WT_data_dict:\n",
    "    data = WT_data_dict[key][var]\n",
    "    t = data[\"t(M)\"]\n",
    "    closest_index = (t - t_val).abs().idxmin()\n",
    "    L_val = []\n",
    "    pow_in_L = []\n",
    "    for L in range(16):\n",
    "        L_val.append(L)\n",
    "        pow_in_L.append(power_in_mode(L, data.iloc[closest_index, :], pre=\"ReIm\"))\n",
    "\n",
    "    # plt.scatter(L_val, pow_in_L, label=var)\n",
    "    plt.plot(L_val, pow_in_L, label=key)\n",
    "plt.legend()\n",
    "plt.xlabel('L')\n",
    "plt.ylabel(f'Power in mode {var}')\n",
    "plt.title(f\"{key} at {t_val=}M\")\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Diff in power modes of various levs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_at_time(df: pd.DataFrame,\n",
    "                        times,\n",
    "                        time_col: str = \"t(M)\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Interpolate all measurement columns in df to the given time(s).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Input DataFrame. Must contain `time_col` and one or more numeric columns.\n",
    "    times : scalar or array-like\n",
    "        The time value(s) at which to interpolate.\n",
    "    time_col : str, optional\n",
    "        Name of the time column (default \"time\").\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        A new DataFrame indexed by the queried time(s), with each\n",
    "        column interpolated linearly.\n",
    "    \"\"\"\n",
    "    # 1. Set the time column as the index\n",
    "    df_time = df.set_index(time_col)\n",
    "    # 2. Build a new index that includes both existing and desired times\n",
    "    new_idx = df_time.index.union(pd.Index(np.atleast_1d(times)))\n",
    "    # 3. Reindex to introduce NaNs at query points :contentReference[oaicite:0]{index=0}\n",
    "    df_reindexed = df_time.reindex(new_idx)\n",
    "    # 4. Fill those NaNs by linear interpolation along the index :contentReference[oaicite:1]{index=1}\n",
    "    df_interp = df_reindexed.interpolate(method='polynomial', order=3)\n",
    "    # 5. Select only the rows at the desired times\n",
    "    out = df_interp.loc[np.atleast_1d(times)]\n",
    "    # 6. If the input was a scalar, return a single-row DataFrame\n",
    "    if np.isscalar(times):\n",
    "        return out.to_frame().T if isinstance(out, pd.Series) else out\n",
    "    return out\n",
    "\n",
    "\n",
    "WT_data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'W.dat'\n",
    "var = 'J.dat'\n",
    "var = 'DrJ.dat'\n",
    "\n",
    "base_key = '6_set1_L6s6_250'\n",
    "base_key = 'BondiCceR0334'\n",
    "\n",
    "base_pd = WT_data_dict[base_key][var]\n",
    "t_interp = WT_data_dict[base_key][var][\"t(M)\"].values\n",
    "correlation_56 = interpolate_at_time(WT_data_dict[base_key][var], t_interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_val = 3500\n",
    "# base_key = 'master_Lev5_R0257'\n",
    "# base_key = 'master_Lev5_R0257'\n",
    "# base_key = 'master_Lev5_R0257'\n",
    "\n",
    "data = WT_data_dict[key][var]\n",
    "t = data[\"t(M)\"]\n",
    "closest_index = (t - t_val).abs().idxmin()\n",
    "base_L_val = []\n",
    "base_pow_in_L = []\n",
    "for L in range(16):\n",
    "    base_L_val.append(L)\n",
    "    base_pow_in_L.append(power_in_mode(L, data.iloc[closest_index, :], pre=\"ReIm\"))\n",
    "\n",
    "for key in WT_data_dict:\n",
    "    if key == base_key:\n",
    "        continue\n",
    "    data = WT_data_dict[key][var]\n",
    "    t = data[\"t(M)\"]\n",
    "    closest_index = (t - t_val).abs().idxmin()\n",
    "    L_val = []\n",
    "    pow_in_L = []\n",
    "    for L in range(16):\n",
    "        L_val.append(L)\n",
    "        pow_in_L.append(power_in_mode(L, data.iloc[closest_index, :], pre=\"ReIm\"))\n",
    "\n",
    "    abs_diff = np.abs(np.array(pow_in_L) - np.array(base_pow_in_L))\n",
    "    rel_diff = np.abs(np.array(pow_in_L) - np.array(base_pow_in_L)) / np.abs(np.array(base_pow_in_L))\n",
    "    # plt.scatter(L_val, pow_in_L, label=var)\n",
    "    # plt.plot(L_val, abs_diff, label=f\"abs_diff_{key}\")\n",
    "    plt.plot(L_val, rel_diff, label=f\"rel_diff_{key}\")\n",
    "plt.legend()\n",
    "plt.xlabel('L')\n",
    "plt.ylabel(f'{var} diff power')\n",
    "plt.title(f\"diff {base_key} at {t_val=}M\")\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_val = 3500\n",
    "# base_key1 = 'master_Lev5_R0257'\n",
    "# base_key = 'master_Lev5_R0257'\n",
    "# base_key = 'master_Lev5_R0257'\n",
    "\n",
    "data = WT_data_dict[key][var]\n",
    "t = data[\"t(M)\"]\n",
    "closest_index = (t - t_val).abs().idxmin()\n",
    "base_L_val = []\n",
    "base_pow_in_L = []\n",
    "for L in range(16):\n",
    "    base_L_val.append(L)\n",
    "    base_pow_in_L.append(power_in_mode(L, data.iloc[closest_index, :], pre=\"ReIm\"))\n",
    "\n",
    "for key in WT_data_dict:\n",
    "    if key == base_key:\n",
    "        continue\n",
    "    data = WT_data_dict[key][var]\n",
    "    t = data[\"t(M)\"]\n",
    "    closest_index = (t - t_val).abs().idxmin()\n",
    "    L_val = []\n",
    "    pow_in_L = []\n",
    "    for L in range(16):\n",
    "        L_val.append(L)\n",
    "        pow_in_L.append(power_in_mode(L, data.iloc[closest_index, :], pre=\"ReIm\"))\n",
    "\n",
    "    abs_diff = np.abs(np.array(pow_in_L) - np.array(base_pow_in_L))\n",
    "    rel_diff = np.abs(np.array(pow_in_L) - np.array(base_pow_in_L)) / np.abs(np.array(base_pow_in_L))\n",
    "    # plt.scatter(L_val, pow_in_L, label=var)\n",
    "    # plt.plot(L_val, abs_diff, label=f\"abs_diff_{key}\")\n",
    "    plt.plot(L_val, rel_diff, label=f\"rel_diff_{key}\")\n",
    "plt.legend()\n",
    "plt.xlabel('L')\n",
    "plt.ylabel(f'{var} diff power')\n",
    "plt.title(f\"diff {base_key} at {t_val=}M\")\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power modes wrt time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = power_in_mode(2,WT_data_dict[\"6_set1_L6s0_250\"]['J.dat'])\n",
    "pre = \"ReIm\"\n",
    "key = \"master_Lev5_R0257\"\n",
    "key = \"BondiCceR0586\"\n",
    "key = \"6_set1_L6s6_100\"\n",
    "var = \"J.dat\"\n",
    "for L in range(16):\n",
    "  t = WT_data_dict[key][var]['t(M)']\n",
    "  a = power_in_mode(L,WT_data_dict[key][var], pre=pre)\n",
    "  plt.semilogy(t,np.abs(a),label=f\"{L=}\")\n",
    "plt.legend()\n",
    "plt.title(f\"{key}\")\n",
    "plt.xlabel('t(M)')\n",
    "plt.ylabel(f\"{var}: {pre}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_plot = ['Beta.dat', 'DrJ.dat', 'DuR.dat', 'H.dat', 'J.dat', 'Q.dat', 'R.dat', 'U.dat', 'W.dat']\n",
    "# variables_to_plot = ['DrJ.dat', 'J.dat', 'Q.dat', 'R.dat']\n",
    "variables_to_plot = ['J.dat']\n",
    "\n",
    "modes_to_plot = ['Re(2,2)','Im(2,2)','Re(2,0)']\n",
    "modes_to_plot = ['Re(2,2)']\n",
    "modes_to_plot = ['Re(2,0)']\n",
    "\n",
    "base_key = 'high_accuracy_Lev5_R0258'\n",
    "base_key = 'master_Lev5_R0257'\n",
    "# base_key = '6_set1_L6s6_250'\n",
    "# base_key = '6_set1_L6s5_250'\n",
    "# base_key = '6_set1_L3s3_250'\n",
    "# base_key = '6_set1_L3s2_250'\n",
    "radius = int(base_key[-3:])\n",
    "\n",
    "plot_vals = [\"_diff\",\"_absdiff\",\"_rel_diff\",\"_rel_absdiff\"]\n",
    "plot_vals = [\"_absdiff\",\"_rel_absdiff\"]\n",
    "plot_vals = [\"_rel_absdiff\"]\n",
    "# plot_vals = [\"_absdiff\"]\n",
    "\n",
    "t_min = -10000\n",
    "# t_min = 2000\n",
    "t_min = 2500\n",
    "t_min = 1190\n",
    "t_min = 1210\n",
    "t_max = 10000\n",
    "# t_max = 7751.5\n",
    "# t_max = 7000\n",
    "t_max = 4000\n",
    "# t_max = 3500\n",
    "\n",
    "avg_len = None\n",
    "avg_len = 50\n",
    "\n",
    "num_colors_required = len(list(itertools.product(variables_to_plot,modes_to_plot)))*(len(WT_data_dict)-1)\n",
    "\n",
    "num_colors_required = 0\n",
    "for variable,mode,key in itertools.product(variables_to_plot,modes_to_plot,WT_data_dict):\n",
    "  if key == base_key:\n",
    "    continue\n",
    "#   if '250' not in key:\n",
    "#     continue\n",
    "  num_colors_required = num_colors_required + 1\n",
    "\n",
    "if num_colors_required <=10:\n",
    "  cmap = plt.get_cmap('tab10')\n",
    "  color = [cmap(i) for i in range(num_colors_required )]\n",
    "elif num_colors_required <=20:\n",
    "  cmap = plt.get_cmap('tab20')\n",
    "  color = [cmap(i) for i in range(num_colors_required )]\n",
    "else:\n",
    "  color=plt.cm.hsv(np.linspace(0, 1, num_colors_required))\n",
    "  color=plt.cm.viridis(np.linspace(0, 1, num_colors_required))\n",
    "\n",
    "i=-1\n",
    "plt.close()\n",
    "for key,variable,mode in itertools.product(WT_data_dict,variables_to_plot,modes_to_plot):\n",
    "  if key == base_key:\n",
    "    continue\n",
    "#   if '250' not in key:\n",
    "#     continue\n",
    "  # if not re.search(r\"Lev[3,4,5]\",key):\n",
    "  #   continue\n",
    "\n",
    "  diff_dict = create_diff_dict(WT_data_dict,variable=variable,mode=mode,base_key=base_key)\n",
    "  t_arr = diff_dict[\"t(M)\"]\n",
    "  trimmed_indices = (t_arr>t_min) & (t_arr<t_max)\n",
    "  t_arr = t_arr[trimmed_indices]\n",
    "\n",
    "  i = i+1\n",
    "  for plot_val in plot_vals:\n",
    "    y_vals = diff_dict[key+plot_val][trimmed_indices]\n",
    "    if avg_len:\n",
    "        y_vals = np.convolve(y_vals,np.ones(avg_len),'valid')/avg_len\n",
    "    x_vals = t_arr[:len(y_vals)]\n",
    "    match plot_val:\n",
    "      case \"_rel_absdiff\":\n",
    "        plt.semilogy(x_vals,y_vals,label=f\"{key}_{variable}_{mode}\"+plot_val,linestyle=\"-\",color=color[i])\n",
    "      case \"_absdiff\":\n",
    "        plt.semilogy(x_vals,y_vals,label=f\"{key}_{variable}_{mode}\"+plot_val,linestyle=\":\",color=color[i])\n",
    "        # plt.semilogy(x_vals,y_vals,linestyle=\":\",color=color[i])\n",
    "      case \"_diff\":\n",
    "        plt.semilogy(x_vals,y_vals,label=f\"{key}_{variable}_{mode}\"+plot_val,linestyle=\"--\",color=color[i])\n",
    "      case \"_rel_diff\":\n",
    "        plt.semilogy(x_vals,y_vals,label=f\"{key}_{variable}_{mode}\"+plot_val,linestyle=\"-.\",color=color[i])\n",
    "    \n",
    "\n",
    "    plt.xlabel('t')\n",
    "    plt.ylabel(\"diff\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    title = f\"Diff {base_key}\"\n",
    "    if avg_len:\n",
    "      title = title + f\" : moving_avg_len={avg_len}\"\n",
    "    plt.title(title)\n",
    "    # plt.show()\n",
    "    # plt.savefig(Path(\"/home/hchaudha/notes/spec_accuracy/CCE/new_set_L3\")/f\"violations_alllll_{bondi_norms_to_plot}_t={t_min}-{t_max}.png\")\n",
    "    # plt.savefig(Path(\"/home/hchaudha/notes/spec_accuracy/CCE/\")/f\"{bondi_norms_to_plot}_t={t_min}-{t_max}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No base diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_plot = ['Beta.dat', 'DrJ.dat', 'DuR.dat', 'H.dat', 'J.dat', 'Q.dat', 'R.dat', 'U.dat', 'W.dat']\n",
    "# variables_to_plot = ['Beta.dat']\n",
    "variables_to_plot = ['J.dat']\n",
    "\n",
    "l,m = 2,2\n",
    "modes_to_plot = ['Re(2,2)','Im(2,2)','Re(2,0)']\n",
    "modes_to_plot = ['Re(2,2)']\n",
    "\n",
    "t_min = -10000\n",
    "# t_min = 2000\n",
    "t_min = 2500\n",
    "t_min = 1200\n",
    "t_max = 10000\n",
    "# t_max = 7751.5\n",
    "# t_max = 7000\n",
    "t_max = 4000\n",
    "t_max = 3500\n",
    "\n",
    "labels = None\n",
    "# labels={\n",
    "# #  \"high_accuracy_Lev5_R0258\" : \"Lev5_ode_tol_R0258\",\n",
    "#  \"6_set1_L3s3_200\" : \"Lev3_variant_R0200\",\n",
    "#  \"6_set1_L3s3_250\" : \"Lev3_variant_R0250\",\n",
    "#  \"6_set1_L3s3_300\" : \"Lev3_variant_R0300\",\n",
    "#  \"6_set1_L3s2_200\" : \"Lev2_variant_R0200\",\n",
    "#  \"6_set1_L3s2_250\" : \"Lev2_variant_R0250\",\n",
    "#  \"6_set1_L3s2_300\" : \"Lev2_variant_R0300\",\n",
    "# }\n",
    "\n",
    "for key in WT_data_dict:\n",
    "  data_dict = WT_data_dict[key]\n",
    "  if \"s3\" not in key:\n",
    "    continue\n",
    "\n",
    "  t_arr = data_dict[variables_to_plot[0]][\"t(M)\"]\n",
    "  trimmed_indices = (t_arr>t_min) & (t_arr<t_max)\n",
    "  t_arr = t_arr[trimmed_indices]\n",
    "\n",
    "  for i,mode in itertools.product(variables_to_plot, modes_to_plot):\n",
    "    if labels is None:\n",
    "      plt.plot(t_arr,data_dict[i][mode][trimmed_indices],label=f\"{key}_{i}_{mode}\")\n",
    "    else:\n",
    "      plt.plot(t_arr,data_dict[i][mode][trimmed_indices],label=f\"{labels[key]}_{i}_{mode}\")\n",
    "\n",
    "  plt.xlabel('t')\n",
    "  plt.legend()\n",
    "  plt.tight_layout()\n",
    "  # plt.show()\n",
    "  # plt.savefig(Path(\"/home/hchaudha/notes/spec_accuracy/CCE/new_set_L3\")/f\"violations_alllll_{bondi_norms_to_plot}_t={t_min}-{t_max}.png\")\n",
    "  # plt.savefig(Path(\"/home/hchaudha/notes/spec_accuracy/CCE/\")/f\"{bondi_norms_to_plot}_t={t_min}-{t_max}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WT data modes plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_data= {}\n",
    "# WT_data[\"high_accuracy_Lev0_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev0/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"high_accuracy_Lev1_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev1/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"high_accuracy_Lev2_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev2/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"high_accuracy_Lev3_R0258\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/GW_data_lev3/BondiCceR0258/BondiCceR0258.h5\")\n",
    "# WT_data[\"high_accuracy_Lev4_R0258\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/GW_data_lev4/BondiCceR0258/BondiCceR0258.h5\")\n",
    "# WT_data[\"high_accuracy_Lev5_R0258\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/GW_data_lev5/BondiCceR0258/BondiCceR0258.h5\")\n",
    "# WT_data[\"master_Lev0_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev/GW_data/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"master_Lev1_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev/GW_data_lev1/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"master_Lev2_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev/GW_data_lev2/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"master_Lev3_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_master/Ev/GW_data_lev3/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"master_Lev4_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_master/Ev/GW_data_lev4/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"master_Lev5_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_master/Ev/GW_data_lev5/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"Lev5_bg_ah100_cd_01_uamr_full_R0258\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_bg_ah100_cd_01_uamr_full/GW_data/BondiCceR0258/BondiCceR0258.h5\")\n",
    "# WT_data[\"Lev5_bg_ah100_cd_01_uamr_full_R0686\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_bg_ah100_cd_01_uamr_full/GW_data/BondiCceR0686/BondiCceR0686.h5\")\n",
    "# WT_data[\"Lev5_bg_ah100_lapse_uamr_fullR0258\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_bg_ah100_lapse_uamr_full/GW_data/BondiCceR0258/BondiCceR0258.h5\")\n",
    "# WT_data[\"Lev5_bg_ah100_lapse_uamr_full_R0100\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_bg_ah100_lapse_uamr_full/GW_data/BondiCceR0100/BondiCceR0100.h5\")\n",
    "# WT_data[\"high_accuracy_Lev5_R0258_ZeroNonSmooth\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/ZeroNonSmooth/red_Lev5_R0258_VolumeData.h5\")\n",
    "# WT_data[\"high_accuracy_Lev5_R0258_NoIncomingRadiation\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/NoIncomingRadiation/red_Lev5_R0258_VolumeData.h5\")\n",
    "# WT_data[\"high_accuracy_Lev5_R0258_InverseCubic\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/InverseCubic/red_Lev5_R0258_VolumeData.h5\")\n",
    "# WT_data[\"high_accuracy_Lev5_R0258_ConformalFactor10\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/ConformalFactor10/red_Lev5_R0258_VolumeData.h5\")\n",
    "# WT_data[\"high_accuracy_Lev5_R0258_ConformalFactor7\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/ConformalFactor7/red_Lev5_R0258_VolumeData.h5\")\n",
    "# WT_data[\"high_accuracy_Lev5_R0258_ConformalFactor3\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/ConformalFactor3/red_Lev5_R0258_VolumeData.h5\")\n",
    "\n",
    "# WT_data[\"Lev01_test_ode_Lev2_257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev2/BondiCceR0257/BondiCceR0257.h5\")\n",
    "# WT_data[\"Lev01_test_ode_Lev1_257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev1/BondiCceR0257/BondiCceR0257.h5\")\n",
    "\n",
    "# WT_data[\"Lev01_test_Lev2_257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev/GW_data_lev2/BondiCceR0257/BondiCceR0257.h5\")\n",
    "\n",
    "radius = ['0020','0035','0050','0075','0100','0150','0200','0250','0300','0400','0500','0600','0800','1000','1500','2000','2500',]\n",
    "radius = ['0050','0200','1000','2500']\n",
    "for r in radius:\n",
    "    WT_data[f\"long_16_2565_10000_14_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/single_bh/20_zero_spin_AMR_L5_10000M/GW_data/long_16_2565_10000_14/BondiCceR{r}/BondiCceR{r}.h5\")\n",
    "\n",
    "# levs,run_sets,radius= [],[],[]\n",
    "# # levs = [0,1,2,3]\n",
    "# levs = [4,5,6]\n",
    "# # levs = [0,1,2,3,4,5,6]\n",
    "# # levs = [3]\n",
    "# # run_sets = [1,2,3]\n",
    "# # run_sets = [1,3]\n",
    "# run_sets = [1]\n",
    "# radius = [250]\n",
    "# # radius = [100,150,200,250,300,350,500,700,900]\n",
    "# # radius = [250,500,900]\n",
    "\n",
    "# for l,s,r in itertools.product(levs,run_sets,radius):\n",
    "#   if s == 2 and (l == 0 or l==1):\n",
    "#     continue\n",
    "#   if l <= 3:\n",
    "#     if s == 1:\n",
    "#       WT_data[f\"6_set{s}_L6s{l}_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/6_segs/6_set{s}_L6/GW_data_lev{l}/BondiCceR0{r}/BondiCceR0{r}.h5\")\n",
    "#     WT_data[f\"6_set{s}_L3s{l}_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/6_segs/6_set{s}_L3/GW_data_lev{l}/BondiCceR0{r}/BondiCceR0{r}.h5\")\n",
    "#   else:\n",
    "#     WT_data[f\"6_set{s}_L6s{l}_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/6_segs/6_set{s}_L6/GW_data_lev{l}/BondiCceR0{r}/BondiCceR0{r}.h5\")\n",
    "\n",
    "\n",
    "# #   WT_data[f\"6_set1_L6s3_CAMR_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/6_segs/6_set1_L6_vars/L6s3_CAMR/GW_data_lev3/BondiCceR0{r}/BondiCceR0{r}.h5\")\n",
    "# #   WT_data[f\"6_set1_L6s3_min_L_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/6_segs/6_set1_L6_vars/L6s3_min_L/GW_data_lev3/BondiCceR0{r}/BondiCceR0{r}.h5\")\n",
    "\n",
    "\n",
    "fail_flag=False\n",
    "for key in WT_data:\n",
    "  if not WT_data[key].exists():\n",
    "    fail_flag = True\n",
    "    print(f\"{WT_data[key]} does not exist!\")\n",
    "  if fail_flag:\n",
    "    raise Exception(\"Some paths do not exist!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_data_dict = {}\n",
    "for key in WT_data:\n",
    "  WT_data_dict[key] = WT_to_pandas(WT_data[key])\n",
    "  print(f\"{key} loaded!\")\n",
    "\n",
    "print(WT_data_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = WT_data_dict['6_set1_L3s0_250']['Beta.dat']\n",
    "data2 = WT_data_dict['6_set1_L3s3_250']['Beta.dat']\n",
    "diff = data2 - data1\n",
    "diff['t(M)'] = data2['t(M)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = WT_data_dict['6_set1_L3s0_250']['W.dat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minT = 0\n",
    "minT = 1200\n",
    "\n",
    "maxT = 40000\n",
    "maxT = 4000\n",
    "data1 = limit_by_col_val(minT,maxT,'t(M)',data1)\n",
    "data = limit_by_col_val(minT,maxT,'t(M)',diff)\n",
    "\n",
    "min_clip_val = 1e-25\n",
    "\n",
    "domain_col_list = filter_by_regex(regex=[\"Re\"],col_list=data.columns)\n",
    "domain_col_list = filter_by_regex(regex=[r\"Re\\(\\d6\"],col_list=domain_col_list)\n",
    "\n",
    "visual_data = data[domain_col_list]\n",
    "visual_data = np.abs(visual_data)\n",
    "min_val = visual_data.min().min()\n",
    "print(f\"Minimum value in the filtered data: {min_val}\")\n",
    "if min_val < min_clip_val:\n",
    "  print(f\"Min value is too small {min_val}, clipping at {min_clip_val}\")\n",
    "  small_number_mask = visual_data < min_clip_val\n",
    "  visual_data[small_number_mask] = min_clip_val\n",
    "visual_data = np.log10(visual_data)\n",
    "\n",
    "column_names = list(visual_data.columns)\n",
    "\n",
    "vmin_log,vmax_log = -11,-1\n",
    "vmin_log,vmax_log = None,None\n",
    "if vmin_log is None:\n",
    "  vmin_log = visual_data.min().min()\n",
    "if vmax_log is None:\n",
    "  vmax_log = visual_data.max().max()\n",
    "\n",
    "print(vmin_log,vmax_log)\n",
    "\n",
    "plt.figure(figsize=(45, 10))\n",
    "imshow_plot = plt.imshow(\n",
    "    visual_data[column_names], \n",
    "    aspect='auto', \n",
    "    # cmap='RdYlGn_r', \n",
    "    cmap='viridis', \n",
    "    origin='lower',\n",
    "    vmin=vmin_log, \n",
    "    vmax=vmax_log\n",
    ")\n",
    "\n",
    "plt.xticks(\n",
    "    ticks=np.arange(len(visual_data.columns)), \n",
    "    labels=[i.split(\" \")[-1] for i in column_names], \n",
    "    rotation=90\n",
    ")\n",
    "\n",
    "ytick_step = len(data) // 10  # Show about 10 ticks\n",
    "plt.yticks(\n",
    "    ticks=np.arange(0, len(data), ytick_step), \n",
    "    labels=data['t(M)'][::ytick_step].astype(int)\n",
    ")\n",
    "\n",
    "colorbar = plt.colorbar(imshow_plot)\n",
    "\n",
    "plt.ylabel('t(M)')\n",
    "plt.title(f'{key}')\n",
    "plt.tight_layout()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean/Max of modes over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_dict = {}\n",
    "L_max_for_mean = 50\n",
    "variables = ['Beta.dat', 'DrJ.dat', 'DuR.dat', 'H.dat', 'J.dat', 'Q.dat', 'R.dat', 'U.dat', 'W.dat']\n",
    "variables = ['H.dat', 'R.dat']\n",
    "variables = ['J.dat']\n",
    "r1 = '100'\n",
    "# run_keys = [f'6_set1_L6s6_{r1}']\n",
    "# run_keys = [f'6_set1_L6s5_{r1}']\n",
    "# run_keys = [f'6_set1_L6s4_{r1}',f'6_set1_L6s5_{r1}',f'6_set1_L6s6_{r1}']\n",
    "run_keys = [f'6_set1_L3s0_{r1}',f'6_set1_L3s1_{r1}',f'6_set1_L3s2_{r1}',f'6_set1_L3s3_{r1}']\n",
    "r1='250'\n",
    "run_keys = run_keys+[f'6_set1_L3s0_{r1}',f'6_set1_L3s1_{r1}',f'6_set1_L3s2_{r1}',f'6_set1_L3s3_{r1}']\n",
    "r1='900'\n",
    "run_keys = run_keys+[f'6_set1_L3s0_{r1}',f'6_set1_L3s1_{r1}',f'6_set1_L3s2_{r1}',f'6_set1_L3s3_{r1}']\n",
    "run_keys = WT_data_dict.keys()\n",
    "# run_keys = ['high_accuracy_Lev0_R0257', 'high_accuracy_Lev1_R0257', 'high_accuracy_Lev2_R0257',]\n",
    "# run_keys = ['high_accuracy_Lev3_R0258', 'high_accuracy_Lev4_R0258', 'high_accuracy_Lev5_R0258',]\n",
    "\n",
    "minT = 0\n",
    "minT = 3200\n",
    "\n",
    "maxT = 40000\n",
    "maxT = 4000\n",
    "\n",
    "reduced_dict = {}\n",
    "flattened_dict = {}\n",
    "for run_key in run_keys:\n",
    "\n",
    "  column_names = None\n",
    "  reduced_dict[run_key] = {}\n",
    "\n",
    "  for var in variables:\n",
    "\n",
    "    data = limit_by_col_val(minT,maxT,'t(M)',WT_data_dict[run_key][var])\n",
    "\n",
    "    domain_col_list = filter_by_regex(regex=[\"Re\"],col_list=data.columns)\n",
    "    domain_col_list = filter_by_regex(regex=[r\"Re\\(\\d\\d?,\\d\\d?\\)\"],col_list=domain_col_list)\n",
    "    # domain_col_list = filter_by_regex(regex=[r\"Re\\(\\d\\d,\\d\\d?\\)\"],col_list=domain_col_list)\n",
    "\n",
    "    if column_names is None and var == \"R.dat\":\n",
    "      column_names = domain_col_list\n",
    "\n",
    "    visual_data = data[domain_col_list]\n",
    "    visual_data = np.abs(visual_data)\n",
    "    min_val = visual_data.min().min()\n",
    "    # print(f\"Minimum value in the filtered data: {min_val}\")\n",
    "\n",
    "    reduced_dict[run_key][var] = {\n",
    "      \"mean\" : visual_data.mean(),\n",
    "      \"rel_mean\" : visual_data.mean()/abs_mean_value_upto_l( visual_data.mean(),L_max_for_mean),\n",
    "      # \"run_mean\" : visual_data.mean().cumsum()/range(1,1+len( visual_data.mean())),\n",
    "      \"max\" : visual_data.max(),\n",
    "      \"rel_max\" : visual_data.max()/abs_mean_value_upto_l( visual_data.max(),L_max_for_mean),\n",
    "      # \"run_max\" : visual_data.max().cumsum()/range(1,1+len( visual_data.max())),\n",
    "    }\n",
    "\n",
    "\n",
    "  for key,val in reduced_dict[run_key].items():\n",
    "    for key1,val1 in val.items():\n",
    "      flattened_dict[f\"{key[:-4]}_{key1}_{run_key}\"] = val1\n",
    "\n",
    "sorted_keys = sorted(flattened_dict.keys())\n",
    "flattened_dict = {key: flattened_dict[key] for key in sorted_keys}\n",
    "\n",
    "df = None\n",
    "for key,val in flattened_dict.items():\n",
    "  if df is None:\n",
    "    df = pd.DataFrame([val],index=[key])\n",
    "  else:\n",
    "    df = pd.concat([df,pd.DataFrame([val],index=[key])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfT = df.T\n",
    "for col in dfT.columns:\n",
    "  if \"max\" not in col:\n",
    "    continue\n",
    "  if \"rel_\" in col:\n",
    "    continue\n",
    "  plt.plot(dfT[col],label = col)\n",
    "\n",
    "plt.title(f'{run_key} t(M)={minT},{maxT}')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.grid(False)\n",
    "plt.yscale('log')\n",
    "plt.xticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = dfT.columns\n",
    "cols_new = [i for i in cols if \"run_max\" in i]\n",
    "a = np.arange(1,len(cols_new)+1)\n",
    "one_over_x = 2.8e-7/a\n",
    "\n",
    "plt.plot(dfT[cols_new].loc['Re(16,16)'])\n",
    "plt.plot(one_over_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power in modes plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_dict = {}\n",
    "L_max_for_mean = 50\n",
    "variables = ['Beta.dat', 'DrJ.dat', 'DuR.dat', 'H.dat', 'J.dat', 'Q.dat', 'R.dat', 'U.dat', 'W.dat']\n",
    "# variables = ['H.dat', 'R.dat']\n",
    "variables = ['J.dat']\n",
    "# r1 = '100'\n",
    "# run_keys = [f'6_set1_L6s6_{r1}']\n",
    "# run_keys = [f'6_set1_L6s5_{r1}']\n",
    "# run_keys = [f'6_set1_L6s4_{r1}',f'6_set1_L6s5_{r1}',f'6_set1_L6s6_{r1}']\n",
    "# run_keys = [f'6_set1_L3s0_{r1}',f'6_set1_L3s1_{r1}',f'6_set1_L3s2_{r1}',f'6_set1_L3s3_{r1}']\n",
    "# r1='250'\n",
    "# run_keys = run_keys+[f'6_set1_L3s0_{r1}',f'6_set1_L3s1_{r1}',f'6_set1_L3s2_{r1}',f'6_set1_L3s3_{r1}']\n",
    "# r1='900'\n",
    "# run_keys = run_keys+[f'6_set1_L3s0_{r1}',f'6_set1_L3s1_{r1}',f'6_set1_L3s2_{r1}',f'6_set1_L3s3_{r1}']\n",
    "run_keys = WT_data_dict.keys()\n",
    "# run_keys = ['high_accuracy_Lev0_R0257', 'high_accuracy_Lev1_R0257', 'high_accuracy_Lev2_R0257',]\n",
    "# run_keys = ['high_accuracy_Lev3_R0258', 'high_accuracy_Lev4_R0258', 'high_accuracy_Lev5_R0258',]\n",
    "\n",
    "minT = 0\n",
    "minT = 3200\n",
    "\n",
    "maxT = 40000\n",
    "maxT = 4000\n",
    "\n",
    "power_dict = {}\n",
    "flattened_dict = {}\n",
    "for run_key in run_keys:\n",
    "\n",
    "  column_names = None\n",
    "  power_dict[run_key] = {}\n",
    "\n",
    "  for var in variables:\n",
    "\n",
    "    data = limit_by_col_val(minT,maxT,'t(M)',WT_data_dict[run_key][var])\n",
    "\n",
    "    power_dict[run_key][var] = add_all_L_mode_power(data,16)\n",
    "    power_dict[run_key]['t(M)'] = data['t(M)'] # same for all vars\n",
    "    print(run_key,var,len(power_dict[run_key]['t(M)']),f't(M)__{run_key}')\n",
    "  \n",
    "  for key,val in power_dict[run_key].items():\n",
    "    if 't(M)' in key:\n",
    "      continue\n",
    "    for key1,val1 in val.items():\n",
    "      # print(key1)\n",
    "      if \"pow\" in key1:\n",
    "        flattened_dict[f\"{key[:-4]}_{key1}__{run_key}\"] = val1\n",
    "\n",
    "sorted_keys = sort_by_power_modes(flattened_dict.keys())\n",
    "flattened_dict = {key: flattened_dict[key] for key in sorted_keys}\n",
    "# add_times_for_runs\n",
    "for run_key in run_keys:\n",
    "  flattened_dict[f't(M)__{run_key}'] = power_dict[run_key]['t(M)']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "minY,maxY = 1e-40,1e-10\n",
    "avg_len = 1\n",
    "# avg_len = 1500\n",
    "\n",
    "last_val_list = []\n",
    "r_list = [100,150,200,250,300,350,500,700,900]\n",
    "# r_list = [250,500,900]\n",
    "# r_list = [900]\n",
    "L_list =  [0,1,2,3,4,5,6]\n",
    "L_list =  [2]\n",
    "# L_list =  list(range(0,17))\n",
    "# L_list =  list(range(14,17))\n",
    "\n",
    "for col in flattened_dict:\n",
    "  if 'cum_' in col:\n",
    "    continue\n",
    "  if 'Re' not in col:\n",
    "    continue\n",
    "  # if 't(M)' == col:\n",
    "  #   continue\n",
    "  L = get_mode(col)\n",
    "  r = get_radii(col)\n",
    "  if \"L3\" not in col:\n",
    "    continue\n",
    "  if (r not in r_list) or (L not in L_list):\n",
    "    continue\n",
    "  \n",
    "  run_name = col.split(\"__\")[1]\n",
    "  x = flattened_dict[f't(M)__{run_name}'][avg_len-1:]\n",
    "  y = moving_average_valid(flattened_dict[col],avg_len=avg_len)\n",
    "  last_val_list.append(y[-1])\n",
    "  plt.plot(x,y,label = col)\n",
    "\n",
    "plt.title(f'Power in modes, var={variables}, avg_len={avg_len}')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.grid(False)\n",
    "plt.yscale('log')\n",
    "plt.ylabel(f\"Power in modes\")\n",
    "# plt.ylim((minY,maxY))\n",
    "plt.xlabel(\"t(M)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_dict = {}\n",
    "L_max_for_mean = 50\n",
    "variables = ['Beta.dat', 'DrJ.dat', 'DuR.dat', 'H.dat', 'J.dat', 'Q.dat', 'R.dat', 'U.dat', 'W.dat']\n",
    "# variables = ['H.dat', 'R.dat']\n",
    "# variables = ['J.dat']\n",
    "# r1 = '100'\n",
    "# run_keys = [f'6_set1_L6s6_{r1}']\n",
    "# run_keys = [f'6_set1_L6s5_{r1}']\n",
    "# run_keys = [f'6_set1_L6s4_{r1}',f'6_set1_L6s5_{r1}',f'6_set1_L6s6_{r1}']\n",
    "# run_keys = [f'6_set1_L3s0_{r1}',f'6_set1_L3s1_{r1}',f'6_set1_L3s2_{r1}',f'6_set1_L3s3_{r1}']\n",
    "# r1='250'\n",
    "# run_keys = run_keys+[f'6_set1_L3s0_{r1}',f'6_set1_L3s1_{r1}',f'6_set1_L3s2_{r1}',f'6_set1_L3s3_{r1}']\n",
    "# r1='900'\n",
    "# run_keys = run_keys+[f'6_set1_L3s0_{r1}',f'6_set1_L3s1_{r1}',f'6_set1_L3s2_{r1}',f'6_set1_L3s3_{r1}']\n",
    "run_keys = WT_data_dict.keys()\n",
    "# run_keys = [i for i in run_keys if \"L6\" in i] + [i for i in run_keys if \"L3\" in i]\n",
    "# run_keys = [i for i in run_keys if \"900\" in i]\n",
    "run_keys = [i for i in run_keys if \"L6\" in i]\n",
    "# run_keys = ['high_accuracy_Lev0_R0257', 'high_accuracy_Lev1_R0257', 'high_accuracy_Lev2_R0257',]\n",
    "# run_keys = ['high_accuracy_Lev3_R0258', 'high_accuracy_Lev4_R0258', 'high_accuracy_Lev5_R0258',]\n",
    "\n",
    "# base_key = '6_set1_L6s6_250'\n",
    "# base_key = 'high_accuracy_Lev5_R0258'\n",
    "# base_key = 'high_accuracy_Lev2_R0257'\n",
    "base_key = '6_set1_L6s6_250'\n",
    "# base_key = '6_set1_L6s3_250'\n",
    "\n",
    "\n",
    "minT = 0\n",
    "minT = 3200\n",
    "minT = 1200\n",
    "\n",
    "maxT = 40000\n",
    "maxT = 4000\n",
    "\n",
    "power_dict = {}\n",
    "flattened_dict = {}\n",
    "for run_key in run_keys:\n",
    "  column_names = None\n",
    "  power_dict[run_key] = {}\n",
    "\n",
    "  for var in variables:\n",
    "\n",
    "    data = limit_by_col_val(minT,maxT,'t(M)',WT_data_dict[run_key][var])\n",
    "\n",
    "    power_dict[run_key][var] = add_all_L_mode_power(data,16)\n",
    "    power_dict[run_key]['t(M)'] = data['t(M)'] # same for all vars\n",
    "  \n",
    "  for key,val in power_dict[run_key].items():\n",
    "    if 't(M)' in key:\n",
    "      continue\n",
    "    for key1,val1 in val.items():\n",
    "      # print(key1)\n",
    "      if \"pow\" in key1:\n",
    "        flattened_dict[f\"{key[:-4]}_{key1}__{run_key}\"] = val1\n",
    "\n",
    "sorted_keys = sort_by_power_modes(flattened_dict.keys())\n",
    "flattened_dict = {key: flattened_dict[key] for key in sorted_keys}\n",
    "# add_times_for_runs\n",
    "for run_key in run_keys:\n",
    "  flattened_dict[f't(M)__{run_key}'] = power_dict[run_key]['t(M)']\n",
    "\n",
    "diff_dict = {}\n",
    "for var in variables:\n",
    "  diff_dict[var] = {}\n",
    "  for pow_mode in power_dict[base_key][var]:\n",
    "    if 'pow' not in pow_mode:\n",
    "      continue\n",
    "    diff_dict[var][pow_mode] = create_power_diff_dict(power_dict,pow_mode,var,base_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# minY,maxY = 1e-40,1e-10\n",
    "avg_len = 1\n",
    "avg_len = 800\n",
    "\n",
    "# minY,maxY = 1e-18,1e-4\n",
    "r_list = [100,150,200,250,300,350,500,700,900]\n",
    "# r_list = [250,500,900]\n",
    "# r_list = [900]\n",
    "L_list =  [2]\n",
    "# L_list =  list(range(0,17))\n",
    "# L_list =  list(range(2,10,2))\n",
    "# L_list =  list(range(14,17))\n",
    "\n",
    "plot_vals = [\"_diff\",\"_absdiff\",\"_rel_diff\",\"_rel_absdiff\"]\n",
    "plot_vals = [\"_absdiff\",\"_rel_absdiff\"]\n",
    "plot_vals = [\"_rel_absdiff\"]\n",
    "# plot_vals = [\"_absdiff\"]\n",
    "\n",
    "def filter(var,pow_mode,run_name,L_list):\n",
    "  if run_name == base_key:\n",
    "    return True\n",
    "  if 'Re' not in pow_mode:\n",
    "    return True\n",
    "  if 'cum' in pow_mode:\n",
    "    return True\n",
    "  L = get_mode(pow_mode)\n",
    "  if (L not in L_list):\n",
    "    return True\n",
    "  if run_name == 't(M)':\n",
    "    return True\n",
    "  # if not re.search(r\"L6s[4,5]\",run_name):\n",
    "  #   return True\n",
    "#   if not re.search(r\"L\\ds[1,2,3]_250\",run_name):\n",
    "#     return True\n",
    "  # if not re.search(r\"L\\ds[1,2,3,4,5]_250\",run_name):\n",
    "  #   return True\n",
    "  # if not re.search(r\"L6\",run_name):\n",
    "  #   return True\n",
    "  # if not re.search(r\"Lev[4,3]\",run_name):\n",
    "  #   return True\n",
    "  # if not re.search(r\"Lev[0,1,2]\",run_name):\n",
    "  #   return True\n",
    "\n",
    "num_colors_required = 0\n",
    "for var in diff_dict.keys():\n",
    "  for pow_mode in diff_dict[var]:\n",
    "    for run_name in run_keys:\n",
    "      if filter(var,pow_mode,run_name,L_list):\n",
    "        continue\n",
    "      num_colors_required = num_colors_required + 1\n",
    "\n",
    "if num_colors_required <=10:\n",
    "  cmap = plt.get_cmap('tab10')\n",
    "  color = [cmap(i) for i in range(num_colors_required )]\n",
    "elif num_colors_required <=20:\n",
    "  cmap = plt.get_cmap('tab20')\n",
    "  color = [cmap(i) for i in range(num_colors_required )]\n",
    "else:\n",
    "  color=plt.cm.viridis(np.linspace(0, 1, num_colors_required))\n",
    "  # color=plt.cm.hsv(np.linspace(0, 1, num_colors_required))\n",
    "  # color=plt.cm.gist_rainbow(np.linspace(0, 1, num_colors_required))\n",
    "\n",
    "i=0\n",
    "for var in diff_dict.keys():\n",
    "  for pow_mode in diff_dict[var]:\n",
    "    x = diff_dict[var][pow_mode][f't(M)'][avg_len-1:]\n",
    "    for run_name in run_keys:\n",
    "      if filter(var,pow_mode,run_name,L_list):\n",
    "        continue\n",
    "\n",
    "      # y = moving_average_valid(diff_dict[var][pow_mode][run_name],avg_len=avg_len)\n",
    "      for plot_val in plot_vals:\n",
    "        match plot_val:\n",
    "          case \"_rel_absdiff\":\n",
    "            plt.semilogy(x,moving_average_valid(diff_dict[var][pow_mode][run_name+plot_val],avg_len=avg_len),label = f\"{pow_mode}_{var} : {run_name}\",linestyle=\"-\",color=color[i])\n",
    "          case \"_absdiff\":\n",
    "            if \"_rel_absdiff\" in plot_vals:\n",
    "              plt.semilogy(x,moving_average_valid(diff_dict[var][pow_mode][run_name+plot_val],avg_len=avg_len),linestyle=\":\",color=color[i])\n",
    "            else:\n",
    "              plt.semilogy(x,moving_average_valid(diff_dict[var][pow_mode][run_name+plot_val],avg_len=avg_len),label = f\"{pow_mode}_{var} : {run_name}\",linestyle=\"-\",color=color[i])\n",
    "          case \"_diff\":\n",
    "            plt.semilogy(x,moving_average_valid(diff_dict[var][pow_mode][run_name+plot_val],avg_len=avg_len),label = f\"{pow_mode}_{var} : {run_name}\",linestyle=\"--\",color=color[i])\n",
    "          case \"_rel_diff\":\n",
    "            plt.semilogy(x,moving_average_valid(diff_dict[var][pow_mode][run_name+plot_val],avg_len=avg_len),label = f\"{pow_mode}_{var} : {run_name}\",linestyle=\"-.\",color=color[i])\n",
    "      i = i+1\n",
    "\n",
    "title = f'Difference in power of L modes from {base_key}, var={variables}, modes={L_list}, avg_len={avg_len}'\n",
    "if len(title) > 80:\n",
    "    title = f'Difference in power of L modes from {base_key}, modes={L_list}, avg_len={avg_len}\\nvar={variables},'\n",
    "plt.title(f'Difference in power of L modes from {base_key}, var={variables}, modes={L_list}, avg_len={avg_len}')\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.grid(False)\n",
    "plt.yscale('log')\n",
    "plt.ylabel(f\"Difference in power of modes\")\n",
    "# plt.ylim((minY,maxY))\n",
    "plt.xlabel(\"t(M)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "one_over_x = last_val_list[0]*1e2/np.array(r_list)\n",
    "one_over_x2 = last_val_list[0]*1e4/np.array(r_list)**2\n",
    "\n",
    "# Define the fitting function\n",
    "def fitting_func(r, a, b):\n",
    "    return a / r**b\n",
    "popt, pcov = curve_fit(fitting_func, r_list, last_val_list,p0=[last_val_list[0],2])\n",
    "a_fit, b_fit = popt\n",
    "\n",
    "# Create a smooth curve for the fitted function\n",
    "fit_vals = fitting_func(r_list, a_fit, b_fit)\n",
    "\n",
    "plt.plot(r_list,last_val_list, label=f\"power in mode L={L_list}\",marker='x')\n",
    "# plt.plot(r_list,one_over_x, label=\"1/x\",marker='x')\n",
    "# plt.plot(r_list,one_over_x2, label=\"1/(x*x)\",marker='x')\n",
    "plt.plot(r_list,fit_vals,label=f'Fit: a/r^b, a={a_fit:.2e}, b={b_fit:.2f}', linestyle='--')\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.xlabel('r(M)')\n",
    "plt.ylabel('power in modes')\n",
    "plt.title(f\"L={L_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_dict['Beta_pow_cum_1_Re_6_set1_L6s6_900']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflog10 = df.copy()\n",
    "\n",
    "# Some values are zero need to deal with those\n",
    "# min_clip_val = 1e-25\n",
    "# if min_val < min_clip_val:\n",
    "#   print(f\"Min value in {var} is too small {min_val}, clipping at {min_clip_val}\")\n",
    "#   small_number_mask = visual_data < min_clip_val\n",
    "#   visual_data[small_number_mask] = min_clip_val\n",
    "    # visual_data = np.log10(visual_data)\n",
    "\n",
    "vmin_log,vmax_log = -11,-1\n",
    "vmin_log,vmax_log = None,None\n",
    "if vmin_log is None:\n",
    "  vmin_log = dflog10.min().min()\n",
    "if vmax_log is None:\n",
    "  vmax_log = dflog10.max().max()\n",
    "\n",
    "print(vmin_log,vmax_log)\n",
    "\n",
    "plt.figure(figsize=(45, 10))\n",
    "imshow_plot = plt.imshow(\n",
    "    dflog10[column_names], \n",
    "    aspect='auto', \n",
    "    cmap='RdYlGn_r', \n",
    "    # cmap='viridis', \n",
    "    origin='lower',\n",
    "    vmin=vmin_log, \n",
    "    vmax=vmax_log\n",
    ")\n",
    "\n",
    "plt.xticks(\n",
    "    ticks=np.arange(len(dflog10.columns)), \n",
    "    labels=[i.split(\" \")[-1] for i in column_names], \n",
    "    rotation=90\n",
    ")\n",
    "\n",
    "\n",
    "plt.yticks(\n",
    "    ticks=np.arange(0, len(dflog10.index)), \n",
    "    labels=dflog10.index\n",
    ")\n",
    "\n",
    "colorbar = plt.colorbar(imshow_plot)\n",
    "\n",
    "# plt.ylabel('t(M)')\n",
    "plt.title(f'{run_key} t(M)={minT},{maxT}')\n",
    "plt.tight_layout()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single bh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cce_data= {}\n",
    "# cce_data[\"high_accuracy_Lev0_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev0/BondiCceR0257/red_cce.h5\")\n",
    "\n",
    "# levs,run_sets,radius= [],[],[]\n",
    "# levs = [1,2,3,4,5,6,7,8]\n",
    "# levs = [1,2,3,4,5,6]\n",
    "# levs = [5]\n",
    "# radius = [6,12,25,50,75,100,125,150,175]\n",
    "# radius = [25,50,75,100]\n",
    "# radius = [50]\n",
    "# for l,r in itertools.product(levs,radius):\n",
    "#   cce_data[f\"ode_change_L{l}_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/single_bh/0/GW_data/GW_data_lev{l}/BondiCceR{r:04}/red_cce.h5\")\n",
    "\n",
    "# levs = [1,2,3,4,5,6,7]\n",
    "# radius = [3,5,10,25,45,65,95,125,155,190, 290, 390, 490, 590, 690, 790, 890, 990]\n",
    "# radius = [65]\n",
    "# for l,r in itertools.product(levs,radius):\n",
    "#   cce_data[f\"1000M_L{l}_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/single_bh/2_1000M/GW_data/GW_data_lev{l}/BondiCceR{r:04}/red_cce.h5\")\n",
    "\n",
    "# levs = [1,2,3,4,5,6,7]\n",
    "# radius = [ 4, 6, 10, 16, 24, 32, 40, 60, 80, 120, 160, 200, 240, 280, 320]\n",
    "# # radius = [50]\n",
    "# for l,r in itertools.product(levs,radius):\n",
    "#   cce_data[f\"Lin_L{l}_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/single_bh/3_Lin/GW_data/GW_data_lev{l}/BondiCceR{r:04}/red_cce.h5\")\n",
    "\n",
    "# levs = [1,2,3,4,5]\n",
    "# radius = [3,6,12,25,50,75,100,125,150,175,195,245,295,345]\n",
    "# radius = [50]\n",
    "# for l,r in itertools.product(levs,radius):\n",
    "#   cce_data[f\"400M_L{l}_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/single_bh/4_400M_base/GW_data/GW_data_lev{l}/BondiCceR{r:04}/red_cce.h5\")\n",
    "\n",
    "# levs = [1,2,3,4,5]\n",
    "# radius = [3,6,12,25,50,75,100,125,150,175,195,245,295,345]\n",
    "# radius = [50]\n",
    "# for l,r in itertools.product(levs,radius):\n",
    "#   cce_data[f\"400M_pbc_L{l}_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/single_bh/12_400M_phys_bc/GW_data/GW_data_lev{l}/BondiCceR{r:04}/red_cce.h5\")\n",
    "\n",
    "# outer_bdr = [250,300,350,400,450,500,550,600,650,700,750]\n",
    "# radius = [3,6,12,25,50,75,100,125,150,175]\n",
    "# # radius = [50]\n",
    "# for l,r in itertools.product(outer_bdr,radius):\n",
    "#   cce_data[f\"13_err_fo_{l}_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/single_bh/13_error_falloff/GW_data/GW_data_lev{l}/BondiCceR{r:04}/red_cce.h5\")\n",
    "\n",
    "# outer_bdr = [250,300,350,400,450,500,550,600,650,700,750]\n",
    "# radius = [3,6,12,25,50,75,100,125,150,175]\n",
    "# radius = [25,50,75,100,125,150,175]\n",
    "# # radius = [50]\n",
    "# for l,r in itertools.product(outer_bdr,radius):\n",
    "#   cce_data[f\"14_err_fo_{l}_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/single_bh/14_error_fo_2000M/GW_data/GW_data_lev{l}/BondiCceR{r:04}/red_cce.h5\")\n",
    "\n",
    "# folders = [\"Lev5_265\",\"Lev5_265_003\",\"Lev5_265_03\",\"Lev5_265_10\",\"Lev5_265_100\",\"Lev5_265_1000\",\"Lev5_265_10000\",\"Lev5_265_30\",\"Lev5_265_9\",]\n",
    "# folders = [\"Lev5_265\"]\n",
    "# radius = [10, 15, 25, 35, 50, 75, 100, 125, 150, 175, 200, 225, 250]\n",
    "# radius = [50,100]\n",
    "# for f,r in itertools.product(folders,radius):\n",
    "#   cce_data[f\"18_{f}_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/single_bh/18_zero_spin_const_damp/GW_data/{f}/BondiCceR{r:04}/red_cce.h5\")\n",
    "\n",
    "\n",
    "radius = [20,35,50,75,100,150,200,250,300,400,500,600,800,1000,1500,2000,2500,]\n",
    "radius = [20,75,250,500,1000,1500,2000,2500,]\n",
    "radius = [2000]\n",
    "for r in radius:\n",
    "  cce_data[f\"20_zero_err_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/single_bh/20_zero_spin_AMR_L5_10000M/GW_data/long_16_2565_10000_14/BondiCceR{r:04}/red_cce.h5\")\n",
    "#   cce_data[f\"20_zero_err_{r}_IC\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/single_bh/20_zero_spin_AMR_L5_10000M/GW_data/long_16_2565_10000_14_IC/BondiCceR{r:04}/red_cce.h5\")\n",
    "#   cce_data[f\"20_zero_err_{r}_NIR\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/single_bh/20_zero_spin_AMR_L5_10000M/GW_data/long_16_2565_10000_14_NIR/BondiCceR{r:04}/red_cce.h5\")\n",
    "#   cce_data[f\"20_zero_err_{r}_ZNS\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/single_bh/20_zero_spin_AMR_L5_10000M/GW_data/long_16_2565_10000_14_ZNS/BondiCceR{r:04}/red_cce.h5\")\n",
    "\n",
    "# cce_data[f\"temp_50_250\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/single_bh/17_zero_spin_AMR/GW_data/GW_data_lev0/BondiCceR0100/red_cce.h5\")\n",
    "# fail_flag = False\n",
    "drop_unavailable_keys = True\n",
    "unavailable_keys = []\n",
    "for key in cce_data:\n",
    "  if not cce_data[key].exists():\n",
    "    fail_flag = True\n",
    "    unavailable_keys.append(key)\n",
    "    print(f\"{cce_data[key]} does not exist!\")\n",
    "# if fail_flag:\n",
    "#   raise Exception(\"Some paths do not exist!\")\n",
    "\n",
    "for key in unavailable_keys:\n",
    "  cce_data.pop(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fail_flag = False\n",
    "drop_unavailable_keys = True\n",
    "unavailable_keys = []\n",
    "for key in cce_data:\n",
    "  if not cce_data[key].exists():\n",
    "    fail_flag = True\n",
    "    unavailable_keys.append(key)\n",
    "    print(f\"{cce_data[key]} does not exist!\")\n",
    "# if fail_flag:\n",
    "#   raise Exception(\"Some paths do not exist!\")\n",
    "\n",
    "for key in unavailable_keys:\n",
    "  cce_data.pop(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_interpolate = None\n",
    "t_interpolate = np.linspace(-2000,8000,num=5000)\n",
    "# t_interpolate = np.linspace(6000,8000,num=1000)\n",
    "# t_interpolate = np.linspace(-1000,4000,num=5000)\n",
    "\n",
    "abd_data = {}\n",
    "failed_keys = {}\n",
    "for key in cce_data:\n",
    "  try:\n",
    "    if \"temp\" in key:\n",
    "      abd_data[key] = load_and_pickle(cce_data[key],options = {'t_interpolate':t_interpolate}, reload_data=True)\n",
    "      abd_data[key] = load_bondi_constraints(cce_data[key])\n",
    "    elif t_interpolate is None:\n",
    "      abd_data[key] = load_and_pickle(cce_data[key], reload_data=False)\n",
    "    #   abd_data[key] = load_and_pickle(cce_data[key],reload_data=True)\n",
    "      abd_data[key] = load_bondi_constraints(cce_data[key])\n",
    "    else:\n",
    "      abd_data[key] = load_and_pickle(cce_data[key],options = {'t_interpolate':t_interpolate}, reload_data=False)\n",
    "    #   abd_data[key] = load_and_pickle(cce_data[key],reload_data=True)\n",
    "      abd_data[key] = load_bondi_constraints(cce_data[key])\n",
    "  except Exception as e:\n",
    "    failed_keys[key] = str(e)\n",
    "    print(f\"Failed to load and pickle data for key {key}: {e}\")\n",
    "    continue\n",
    "\n",
    "for key,val in failed_keys.items():\n",
    "  abd_data.pop(key)\n",
    "  print(f\"{key}: {val}\")\n",
    "\n",
    "print(abd_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bondi_norms_to_plot = [0,1,2,3,4,5]\n",
    "bondi_norms_to_plot = [2]\n",
    "\n",
    "t_min = -10000\n",
    "# t_min = 2000\n",
    "# t_min = 2500\n",
    "# t_min = 4000 - 250\n",
    "t_max = 10000\n",
    "# t_max = 7751.5\n",
    "# t_max = 7000\n",
    "# t_max = 4000\n",
    "# t_max = 3500\n",
    "\n",
    "labels = None\n",
    "# labels={\n",
    "# #  \"high_accuracy_Lev5_R0258\" : \"Lev5_ode_tol_R0258\",\n",
    "#  \"6_set1_L3s3_200\" : \"Lev3_variant_R0200\",\n",
    "#  \"6_set1_L3s3_250\" : \"Lev3_variant_R0250\",\n",
    "#  \"6_set1_L3s3_300\" : \"Lev3_variant_R0300\",\n",
    "#  \"6_set1_L3s2_200\" : \"Lev2_variant_R0200\",\n",
    "#  \"6_set1_L3s2_250\" : \"Lev2_variant_R0250\",\n",
    "#  \"6_set1_L3s2_300\" : \"Lev2_variant_R0300\",\n",
    "# }\n",
    "\n",
    "x_data0 = []\n",
    "y_data0 = []\n",
    "\n",
    "for key in abd_data:\n",
    "  violation_dict = abd_data[key]['bondi_violation_norms']\n",
    "#   radius = int(key.split(\"_\")[-1])\n",
    "  # if radius > 200:\n",
    "  #   continue\n",
    "  # if radius <= 25:\n",
    "  #   continue\n",
    "#   if radius != 35:\n",
    "#     continue\n",
    "  # if not re.search(r'18_Lev5_265',key):\n",
    "  #   continue\n",
    "  # if not re.search(r'10_4000M_CAMR_set1_L6_base_[3,4,5,6]_',key):\n",
    "  #   continue\n",
    "  # if not re.search(r'400M_L[1-5]',key):\n",
    "  #   continue\n",
    "\n",
    "  t_arr = abd_data[key][\"abd\"].t\n",
    "  trimmed_indices = (t_arr>t_min) & (t_arr<t_max)\n",
    "  t_arr = t_arr[trimmed_indices]\n",
    "\n",
    "  for i in bondi_norms_to_plot:\n",
    "    # x_data0.append(int(key.split(\"_\")[-2]))\n",
    "    # y_data0.append(violation_dict[i][trimmed_indices][-1])\n",
    "    if labels is None:\n",
    "      plt.semilogy(t_arr,violation_dict[i][trimmed_indices],label=f\"{key}_{i}\")\n",
    "      # plt.semilogy(t_arr,violation_dict[i][trimmed_indices])\n",
    "    else:\n",
    "      plt.semilogy(t_arr,violation_dict[i][trimmed_indices],label=f\"{labels[key]}_{i}\")\n",
    "\n",
    "  plt.xlabel('t(M)')\n",
    "  plt.ylabel(f\"bondi violations {bondi_norms_to_plot}\")\n",
    "  plt.legend()\n",
    "  plt.tight_layout()\n",
    "  # plt.show()\n",
    "  # plt.savefig(Path(\"/home/hchaudha/notes/spec_accuracy/CCE/new_set_L3\")/f\"violations_alllll_{bondi_norms_to_plot}_t={t_min}-{t_max}.png\")\n",
    "  # plt.savefig(Path(\"/home/hchaudha/notes/spec_accuracy/CCE/\")/f\"{bondi_norms_to_plot}_t={t_min}-{t_max}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# x_data0 = x_data0[:-3]\n",
    "# y_data0 = y_data0[:-3]\n",
    "\n",
    "plt.semilogy(x_data0,y_data0,marker='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# y_data = np.log10(y_data0)\n",
    "y_data = np.array(y_data0)\n",
    "x_data = np.array(x_data0)\n",
    "\n",
    "# Define the linear function\n",
    "# def linear_func(x, a, b, c, d):\n",
    "#     return a + b * x + c/x + d/(x*x)\n",
    "# Define the linear function\n",
    "def linear_func(x, a, b, c, d):\n",
    "    return a + b / (x + c)**d\n",
    "\n",
    "# Perform the fit\n",
    "popt, pcov = curve_fit(linear_func, x_data, y_data,p0=[1,100,10,5], maxfev=50000)\n",
    "# popt, pcov = curve_fit(linear_func, x_data, y_data,p0=[1,1,1,6],method='trf', maxfev=5000)\n",
    "a, b, c, d = popt  # Extract fitted parameters\n",
    "\n",
    "# Generate fitted y values using the linear function\n",
    "fitted_y = linear_func(x_data, a, b, c, d)\n",
    "\n",
    "# Plot the original data\n",
    "plt.scatter(x_data, y_data, label=\"Original Data\", color=\"red\")\n",
    "\n",
    "# Plot the fitted line\n",
    "x_fit = np.linspace(min(x_data), max(x_data), 100)  # Create smooth x values for the fitted line\n",
    "y_fit = linear_func(x_fit, a, b, c, d)\n",
    "# plt.plot(x_fit, y_fit, label=f\"Fitted Line: y = {a:.3f} + {b:.3f}x + {c:.3f}/x + {d:.3f}/(x*x)\", color=\"blue\")\n",
    "plt.plot(x_fit, y_fit, label=f\"Fitted Line: y = {a:.3f} + {b:.3f} / ({c:.3f} + x )**{d:.3f}\", color=\"blue\")\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.yscale('log')\n",
    "plt.title(\"Data and Fitted Line\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "a,b,c,d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = {\n",
    " \"50\":(1.1581528540505392e-10,\n",
    " 4415930.873064357,\n",
    " 43.15124058912971,\n",
    " 5.846213947609586),\n",
    " \"75\":(4.359321925135716e-11, 86699.62733692401, 6.550548570857155, 5.12793960776798),\n",
    "  \"100\" : (9.333520525768315e-11,\n",
    " 253460.87961644097,\n",
    " 10.59258112884228,\n",
    " 5.201469675191469),\n",
    " \"125\":(5.25373272312163e-11, 168652.6696880026, 3.723416133107745, 5.071300081310898),\n",
    " \"150\":(2.3990765414383054e-11,\n",
    " 181987.48368018138,\n",
    " 1.4191463150509127,\n",
    " 5.026842345756565),\n",
    " \"175\":(1.7528319171317524e-11,\n",
    " 230552.90706779822,\n",
    " 0.8124681122352008,\n",
    " 5.015726886364778)\n",
    "}\n",
    "radius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### waveforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l,m = 2,0\n",
    "for key in abd_data:\n",
    "  radius = int(key.split(\"_\")[-1])\n",
    "  # if radius > 200:\n",
    "  #   continue\n",
    "  if radius != 50:\n",
    "    continue\n",
    "  # if re.search(r'[6]',key):\n",
    "  #   continue\n",
    "  # if \"_50_\" not in key:\n",
    "  #   continue\n",
    "  # if not re.search(r'10_4000M_CAMR_set1_L6_base_[3,4,5,6]_',key):\n",
    "  #   continue\n",
    "  if not re.search(r'400M_L[1-5]',key):\n",
    "    continue\n",
    "  # if not re.search(r'400M_pbc_L[2-5]',key):\n",
    "  #   continue\n",
    "  h = abd_data[key]['abd'].h\n",
    "  y = h.data[:,  lm(l,m,h.ell_min)]\n",
    "  t = h.t\n",
    "  plt.plot(t,y,label=f\"{key}_{l}_{m}\")\n",
    "\n",
    "plt.xlabel('t(M)')\n",
    "plt.ylabel(f\"{l}_{m}\")\n",
    "# plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finite radius waveform comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_radii(h5_file_path:Path):\n",
    "  radii = set()\n",
    "  with h5py.File(h5_file_path,'r') as f:\n",
    "    names = []\n",
    "    f.visit(names.append)\n",
    "  for name in names:\n",
    "    if \"Version\" in name:\n",
    "      continue\n",
    "    radii.add(name[1:5])\n",
    "  radii = list(radii)\n",
    "  radii.sort()\n",
    "  return radii"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GW_data_path= {}\n",
    "\n",
    "levs,run_sets,radius= [],[],[]\n",
    "levs = [1,2,3,4,5,6,7,8]\n",
    "levs = [1,2,3,4,5]\n",
    "\n",
    "\n",
    "for l in levs:\n",
    "    GW_data_path[f\"400M_pbc_L{l}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/single_bh/12_400M_phys_bc/GW_data/GW_data_lev{l}/rh_FiniteRadii_CodeUnits\")\n",
    "\n",
    "file = \"rh_FiniteRadii_CodeUnits.h5\"\n",
    "for key in GW_data_path:\n",
    "  GW_data_path[key] = GW_data_path[key]/file\n",
    "  if not GW_data_path[key].exists():\n",
    "    raise Exception(f\"{key}, {GW_data_path[key]} does not exists!\")\n",
    "radii_list = extract_radii(list(GW_data_path.values())[0])\n",
    "print(radii_list)\n",
    "\n",
    "\n",
    "# fail_flag = False\n",
    "drop_unavailable_keys = True\n",
    "unavailable_keys = []\n",
    "for key in cce_data:\n",
    "  if not cce_data[key].exists():\n",
    "    fail_flag = True\n",
    "    unavailable_keys.append(key)\n",
    "    print(f\"{cce_data[key]} does not exist!\")\n",
    "# if fail_flag:\n",
    "#   raise Exception(\"Some paths do not exist!\")\n",
    "\n",
    "for key in unavailable_keys:\n",
    "  cce_data.pop(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = radii_list[-1]\n",
    "# radius = radii_list[4]\n",
    "GW_data = {}\n",
    "for key in GW_data_path:\n",
    "  GW_data[key] = scri.SpEC.read_from_h5(\n",
    "      f\"{GW_data_path[key]}/R{radius}.dir\",\n",
    "      dataType = scri.h,\n",
    "      frameType = scri.Inertial,\n",
    "      r_is_scaled_out = True,\n",
    "      m_is_scaled_out = True,\n",
    "      )\n",
    "  print(f\"{key} loaded!\")\n",
    "\n",
    "print(GW_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "l, m = 2,2\n",
    "t_max = 2700\n",
    "t_interpolate = np.linspace(1200+int(radius),t_max+int(radius),num=5000)\n",
    "\n",
    "base_key = 'master_Lev5'\n",
    "# base_key = 'master_Lev2'\n",
    "base_key = 'high_accuracy_Lev5'\n",
    "# base_key = 'high_accuracy_Lev2'\n",
    "# base_key = '6_set3_L6s6'\n",
    "# base_key = '6_set3_L6s5'\n",
    "# base_key = '6_set1_L3s3'\n",
    "# base_key = '6_set2_L3s2'\n",
    "base_h = GW_data[base_key].interpolate(t_interpolate)\n",
    "\n",
    "def np_abs_func(x):\n",
    "  return np.abs(np.real(x))\n",
    "  # return np.abs(x)\n",
    "\n",
    "for key in GW_data:\n",
    "  # if 'L6' not in key:\n",
    "  #   continue\n",
    "  if not re.search(r'Lev[3,4,5]',key):\n",
    "    continue\n",
    "  if key == base_key:\n",
    "    continue\n",
    "  h = GW_data[key].interpolate(t_interpolate)\n",
    "  shited_time = h.t - int(radius)\n",
    "  diff = h.data[:, lm(l,m,h.ell_min)] - base_h.data[:, lm(l,m,h.ell_min)]\n",
    "  diff = np_abs_func(diff)\n",
    "  diff_normalize = diff/np_abs_func(base_h.data[:, lm(l,m,h.ell_min)])\n",
    "  plt.plot(shited_time,diff,label=f'{key}_{l=}_{m=}')\n",
    "  # plt.plot(shited_time,diff_normalize,label=f'{key}_rel_{l=}_{m=}')\n",
    "  # plt.plot(shited_time,base_h.data[:, lm(l,m,h.ell_min)],label=f'{key}_rel2_{l=}_{m=}')\n",
    "  # plt.plot(shited_time,np_abs_func(base_h.data[:, lm(l,m,h.ell_min)]),label=f'{key}_rel2_{l=}_{m=}')\n",
    "  # plt.semilogy(h.t,h.energy_flux(),label=f'{key}')\n",
    "\n",
    "plt.title(f\"diff:{base_key}  {l=},{m=}, {radius=}\")\n",
    "plt.xlabel('t')\n",
    "plt.ylabel(\"diff\")\n",
    "plt.yscale('log')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(Path(\"/home/hchaudha/notes/spec_accuracy/del/LevVariations\")/f\"L05_finite_radius_{base_key}_{l=}_{m=}_{radius}_{t_max=}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cce_data = Path(\"/groups/sxs/hchaudha/spec_runs/CCE_stuff/CceExecutables/CharacteristicExtractReduction.h5\")\n",
    "cce_data = Path(\"/groups/sxs/hchaudha/spec_runs/CCE_stuff/tests/CharacteristicExtractReduction.h5\")\n",
    "cce_data = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/cce_bondi/Lev0_R0257/red_Lev0_R0257_VolumeData.h5\")\n",
    "# cce_data = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev3_R0258/red_Lev3_R0258_VolumeData.h5\")\n",
    "# cce_data = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev4_R0258/red_Lev4_R0258_VolumeData.h5\")\n",
    "# cce_data = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_R0258/red_Lev5_R0258_VolumeData.h5\")\n",
    "# cce_data = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_master/cce_bondi/Lev5_R0257/red_Lev5_R0257_VolumeData.h5\")\n",
    "# cce_data = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_bg_ah100_cd_01_uamr_full/GW_data/BondiCceR0258/red_cce.h5\")\n",
    "# cce_data = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_bg_ah100_cd_01_uamr_full/GW_data/BondiCceR0686/red_cce.h5\")\n",
    "# cce_data = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_bg_ah100_lapse_uamr_full/GW_data/BondiCceR0258/red_cce.h5\")\n",
    "# cce_data = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_bg_ah100_lapse_uamr_full/GW_data/BondiCceR0100/red_cce.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "abd = scri.create_abd_from_h5(\n",
    "      file_name=str(cce_data),\n",
    "      file_format=\"spectrecce_v1\",\n",
    "      # ch_mass=1.0,  # Optional; helpful if known\n",
    "      t_interpolate=np.linspace(-1000,10000,num=5000),  # Optional; for some specified values of `t_worldtube`\n",
    "      # t_0_superrest=3000,\n",
    "      # padding_time=400\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = abd.h\n",
    "l,m=2,2\n",
    "# l,m=1,1\n",
    "print(lm(l,m,h.ell_min))\n",
    "time_cut = 34500\n",
    "plt.plot(h.t[h.t<time_cut], h.data[:,  lm(l,m,h.ell_min)][h.t<time_cut])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violations2 = abd.bianchi_2()\n",
    "diff_abs = (violations2[1] - violations2[0]).norm()\n",
    "diff_rel = diff_abs/(violations2[0].norm())\n",
    "h.data.shape,violations2[0].shape,diff_abs.shape,diff_rel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(abd.t,diff_abs,label=f\"diff_abs\")\n",
    "plt.semilogy(abd.t,diff_rel,label=f\"diff_rel\")\n",
    "plt.ylabel(\"bianchi2\")\n",
    "plt.xlabel(\"t\")\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = cce_data.parent/\"violations\"\n",
    "save_folder.mkdir(exist_ok=True)\n",
    "for l in range(8):\n",
    "  for m in range(-l,l+1):\n",
    "    print(l,m)\n",
    "    plt.semilogy(abd.t,diff_abs[:, lm(l,m,h.ell_min)],label=f\"l,m={l},{m}\")\n",
    "    plt.ylabel(\"bianchi2\")\n",
    "    plt.xlabel(\"t\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{save_folder}/l,m={l},{m}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = cce_data.parent/\"violations\"\n",
    "save_folder.mkdir(exist_ok=True)\n",
    "for l in range(8):\n",
    "  for m in range(-l,l+1):\n",
    "    print(l,m)\n",
    "    plt.semilogy(abd.t,diff_rel[:, lm(l,m,h.ell_min)],label=f\"l,m={l},{m}\")\n",
    "    plt.ylabel(\"bianchi2\")\n",
    "    plt.xlabel(\"t\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{save_folder}/rel_l,m={l},{m}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norms = np.linalg.norm(diff, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogy(abd.t,norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violations = abd.bondi_violation_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violation_dict = {\n",
    "  't': abd.t,\n",
    "  '0': violations[0],\n",
    "  '1': violations[1],\n",
    "  '2': violations[2],\n",
    "  '3': violations[3],\n",
    "  '4': violations[4],\n",
    "  '5': violations[5]\n",
    "}\n",
    "\n",
    "# with open(cce_data.parent/\"violation_dict.pkl\",'wb') as f:\n",
    "#   pickle.dump(violation_dict,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n",
    "plt.semilogy(violation_dict['t'],violation_dict['5'],linestyle='--',label='5',color=colors[5])\n",
    "plt.semilogy(violation_dict['t'],violation_dict['4'],linestyle='--',label='4',color=colors[4])\n",
    "plt.semilogy(violation_dict['t'],violation_dict['3'],linestyle='--',label='3',color=colors[3])\n",
    "plt.semilogy(violation_dict['t'],violation_dict['2'],linestyle='--',label='2',color=colors[2])\n",
    "plt.semilogy(violation_dict['t'],violation_dict['1'],linestyle='--',label='1',color=colors[1])\n",
    "plt.semilogy(violation_dict['t'],violation_dict['0'],linestyle='--',label='0',color=colors[0])\n",
    "\n",
    "plt.xlabel('t')\n",
    "plt.ylabel(\"violations\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(cce_data.parent/\"violations.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violations[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "violation_dict = {\n",
    "  't': abd.t,\n",
    "  '0': violations[0],\n",
    "  '1': violations[1],\n",
    "  '2': violations[2],\n",
    "  '3': violations[3],\n",
    "  '4': violations[4],\n",
    "  '5': violations[5]\n",
    "}\n",
    "\n",
    "violation_dict2 = data['Lev5']['0258']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "minT = violation_dict['t'].min()\n",
    "maxT = violation_dict['t'].max()\n",
    "print(f\"{minT=}, {maxT=}\")\n",
    "mask = (violation_dict2['t'] < maxT) & (violation_dict2['t']  > minT)\n",
    "# maxT = 200\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n",
    "plt.semilogy(violation_dict2['t'][mask],violation_dict2['5'][mask],label='5', color=colors[5])\n",
    "plt.semilogy(violation_dict2['t'][mask],violation_dict2['4'][mask],label='4', color=colors[4])\n",
    "plt.semilogy(violation_dict2['t'][mask],violation_dict2['3'][mask],label='3', color=colors[3])\n",
    "plt.semilogy(violation_dict2['t'][mask],violation_dict2['2'][mask],label='2', color=colors[2])\n",
    "plt.semilogy(violation_dict2['t'][mask],violation_dict2['1'][mask],label='1', color=colors[1])\n",
    "plt.semilogy(violation_dict2['t'][mask],violation_dict2['0'][mask],label='0', color=colors[0])\n",
    "\n",
    "plt.semilogy(violation_dict['t'],violation_dict['5'],linestyle='--',label='2200_5',color=colors[5])\n",
    "plt.semilogy(violation_dict['t'],violation_dict['4'],linestyle='--',label='2200_4',color=colors[4])\n",
    "plt.semilogy(violation_dict['t'],violation_dict['3'],linestyle='--',label='2200_3',color=colors[3])\n",
    "plt.semilogy(violation_dict['t'],violation_dict['2'],linestyle='--',label='2200_2',color=colors[2])\n",
    "plt.semilogy(violation_dict['t'],violation_dict['1'],linestyle='--',label='2200_1',color=colors[1])\n",
    "plt.semilogy(violation_dict['t'],violation_dict['0'],linestyle='--',label='2200_0',color=colors[0])\n",
    "\n",
    "plt.xlabel('t')\n",
    "plt.ylabel(\"violations\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "minT = violation_dict2['t'].min()\n",
    "maxT = violation_dict2['t'].max()\n",
    "print(f\"{minT=}, {maxT=}\")\n",
    "mask = (violation_dict2['t'] < maxT) & (violation_dict2['t']  > minT)\n",
    "# maxT = 200\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n",
    "plt.semilogy(violation_dict2['t'][mask],violation_dict2['5'][mask],label='5', color=colors[5])\n",
    "plt.semilogy(violation_dict2['t'][mask],violation_dict2['4'][mask],label='4', color=colors[4])\n",
    "plt.semilogy(violation_dict2['t'][mask],violation_dict2['3'][mask],label='3', color=colors[3])\n",
    "plt.semilogy(violation_dict2['t'][mask],violation_dict2['2'][mask],label='2', color=colors[2])\n",
    "plt.semilogy(violation_dict2['t'][mask],violation_dict2['1'][mask],label='1', color=colors[1])\n",
    "plt.semilogy(violation_dict2['t'][mask],violation_dict2['0'][mask],label='0', color=colors[0])\n",
    "\n",
    "plt.xlabel('t')\n",
    "plt.ylabel(\"violations\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bondi_violations_dicts = list(main_folder.glob(\"*Lev*/bondi*\"))\n",
    "bondi_violations_dicts = list(main_folder.glob(\"Lev5_R0258/bondi*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bondi_violations_dicts.sort()\n",
    "bondi_violations_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "data = {\n",
    "  \"Lev3\":{},\n",
    "  \"Lev4\":{},\n",
    "  \"Lev5\":{},\n",
    "  \"Lev5_old\":{}\n",
    "}\n",
    "for file in bondi_violations_dicts:\n",
    "  with file.open('rb') as f:\n",
    "    lev = str(file).split(\"/\")[-2][3]\n",
    "    radius = str(file).split(\"/\")[-2][-4:]\n",
    "    if radius == \"_old\":\n",
    "      lev = lev+\"_old\"\n",
    "      radius = str(file).split(\"/\")[-2][-8:-4]\n",
    "    print(lev,radius)\n",
    "    data[\"Lev\"+lev][radius] = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levs = data.keys()\n",
    "\n",
    "\n",
    "bondi_violation = '2'\n",
    "minT = 220\n",
    "maxT = 7200\n",
    "# maxT = 200\n",
    "RADISU = 200\n",
    "\n",
    "for lev in levs:\n",
    "  # if lev!='Lev5':\n",
    "  #   continue\n",
    "  for radius in data[lev].keys():\n",
    "    # if int(radius) != RADISU:\n",
    "    #   continue\n",
    "    if int(radius) < 150:\n",
    "      continue\n",
    "    # print(radius)\n",
    "\n",
    "    t = data[lev][radius]['t']\n",
    "    y = data[lev][radius][bondi_violation]\n",
    "\n",
    "    mask = (t < maxT) & (t > minT)\n",
    "    if lev == \"Lev3\":\n",
    "      # plt.plot(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='-')\n",
    "      plt.semilogy(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='-')\n",
    "    elif lev == 'Lev4':\n",
    "      # plt.plot(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='--')\n",
    "      plt.semilogy(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='--')\n",
    "    elif lev == 'Lev5':\n",
    "      # plt.plot(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='--')\n",
    "      plt.semilogy(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='--')\n",
    "    else:\n",
    "      # plt.plot(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='-.')\n",
    "      plt.semilogy(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='-.')\n",
    "\n",
    "\n",
    "  plt.xlabel('t')\n",
    "  # plt.ylabel(bondi_violation)\n",
    "  plt.title(f\"Bondi Violation {bondi_violation}\")\n",
    "  plt.legend()\n",
    "  plt.savefig(f\"./{lev}.png\")\n",
    "  plt.close()\n",
    "\n",
    "for radius in data['Lev5'].keys():\n",
    "  for lev in levs:\n",
    "    # if 'Lev5' not in lev:\n",
    "    #   continue\n",
    "\n",
    "    t = data[lev][radius]['t']\n",
    "    y = data[lev][radius][bondi_violation]\n",
    "\n",
    "    mask = (t < maxT) & (t > minT)\n",
    "    if lev == \"Lev3\":\n",
    "      # plt.plot(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='-')\n",
    "      plt.semilogy(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='-')\n",
    "    elif lev == 'Lev4':\n",
    "      # plt.plot(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='--')\n",
    "      plt.semilogy(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='--')\n",
    "    elif lev == 'Lev5':\n",
    "      # plt.plot(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='--')\n",
    "      plt.semilogy(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='--')\n",
    "    else:\n",
    "      # plt.plot(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='-.')\n",
    "      plt.semilogy(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='-.')\n",
    "\n",
    "\n",
    "  plt.xlabel('t')\n",
    "  # plt.ylabel(bondi_violation)\n",
    "  plt.title(f\"Bondi Violation {bondi_violation}\")\n",
    "  plt.legend()\n",
    "  plt.tight_layout()\n",
    "  plt.savefig(f\"./{radius}.png\")\n",
    "  plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "levs = data.keys()\n",
    "\n",
    "\n",
    "bondi_violation = '2'\n",
    "minT = 2150\n",
    "maxT = 7500\n",
    "RADISU = 900\n",
    "\n",
    "for lev in levs:\n",
    "  # if lev!='Lev5':\n",
    "  #   continue\n",
    "  for radius in data[lev].keys():\n",
    "    # if int(radius) != RADISU:\n",
    "    #   continue\n",
    "    if int(radius) < 150:\n",
    "      continue\n",
    "    # print(radius)\n",
    "\n",
    "    t = data[lev][radius]['t']\n",
    "    y = data[lev][radius][bondi_violation]\n",
    "\n",
    "    mask = (t < maxT) & (t > minT)\n",
    "    if lev == \"Lev3\":\n",
    "      plt.plot(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='-')\n",
    "      # plt.semilogy(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='-')\n",
    "    elif lev == 'Lev4':\n",
    "      plt.plot(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='--')\n",
    "      # plt.semilogy(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='--')\n",
    "    else:\n",
    "      plt.plot(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='-.')\n",
    "      # plt.semilogy(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='-.')\n",
    "\n",
    "\n",
    "  plt.xlabel('t')\n",
    "  # plt.ylabel(bondi_violation)\n",
    "  plt.title(f\"Bondi Violation {bondi_violation}\")\n",
    "  plt.legend()\n",
    "  plt.savefig(f\"./{lev}.png\")\n",
    "  plt.close()\n",
    "\n",
    "for radius in data['Lev5'].keys():\n",
    "  for lev in levs:\n",
    "  # if lev!='Lev5':\n",
    "  #   continue\n",
    "\n",
    "    t = data[lev][radius]['t']\n",
    "    y = data[lev][radius][bondi_violation]\n",
    "\n",
    "    mask = (t < maxT) & (t > minT)\n",
    "    if lev == \"Lev3\":\n",
    "      plt.plot(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='-')\n",
    "      # plt.semilogy(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='-')\n",
    "    elif lev == 'Lev4':\n",
    "      plt.plot(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='--')\n",
    "      # plt.semilogy(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='--')\n",
    "    else:\n",
    "      plt.plot(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='-.')\n",
    "      # plt.semilogy(t[mask],y[mask],label=f\"{lev}_{radius}\",linestyle='-.')\n",
    "\n",
    "\n",
    "  plt.xlabel('t')\n",
    "  # plt.ylabel(bondi_violation)\n",
    "  plt.title(f\"Bondi Violation {bondi_violation}\")\n",
    "  plt.legend()\n",
    "  plt.tight_layout()\n",
    "  plt.savefig(f\"./{int(radius)}.png\")\n",
    "  plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bondi_violations_dicts = list(main_folder.glob(\"*/bondi*\"))\n",
    "bondi_violations_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bondi_violations_dicts[0].parent.stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "data = {}\n",
    "for file in bondi_violations_dicts:\n",
    "  with file.open('rb') as f:\n",
    "    data[file.parent.stem] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bondi_violation = '2'\n",
    "minT = 215\n",
    "maxT = 7500\n",
    "RADISU = 900\n",
    "\n",
    "for key in data.keys():\n",
    "  if \"test\" in key:\n",
    "    continue\n",
    "  t = data[key]['t']\n",
    "  y = data[key][bondi_violation]\n",
    "\n",
    "  mask = (t < maxT) & (t > minT)\n",
    "  # plt.plot(t[mask],y[mask],label=f\"{key}\",linestyle='-.')\n",
    "  plt.semilogy(t[mask],y[mask],label=f\"{key}\",linestyle='-.')\n",
    "\n",
    "\n",
    "plt.xlabel('t')\n",
    "# plt.ylabel(bondi_violation)\n",
    "plt.title(f\"Bondi Violation {bondi_violation}\")\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.savefig(f\"./variations.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute and save bondi violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cce_data_folder = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_big_gaussian/GW_data/\")\n",
    "\n",
    "cce_data_paths = list(cce_data_folder.glob(f\"**/red_cce.h5\"))\n",
    "for cce_data in cce_data_paths:\n",
    "  abd = scri.create_abd_from_h5(\n",
    "        file_name=str(cce_data),\n",
    "        file_format=\"spectrecce_v1\",\n",
    "        # ch_mass=1.0,  # Optional; helpful if known\n",
    "        # t_interpolate=t_worldtube,  # Optional; for some specified values of `t_worldtube`\n",
    "        # t_0_superrest=3000,\n",
    "        # padding_time=400\n",
    "      )\n",
    "\n",
    "  violations = abd.bondi_violation_norms\n",
    "  violation_dict = {\n",
    "  't': abd.t,\n",
    "  '0': violations[0],\n",
    "  '1': violations[1],\n",
    "  '2': violations[2],\n",
    "  '3': violations[3],\n",
    "  '4': violations[4],\n",
    "  '5': violations[5]\n",
    "  }\n",
    "\n",
    "  with open(cce_data.parent/\"violation_dict.pkl\",'wb') as f:\n",
    "    pickle.dump(violation_dict,f)\n",
    "\n",
    "\n",
    "  colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n",
    "  plt.semilogy(violation_dict['t'],violation_dict['5'],linestyle='--',label='2200_5',color=colors[5])\n",
    "  plt.semilogy(violation_dict['t'],violation_dict['4'],linestyle='--',label='2200_4',color=colors[4])\n",
    "  plt.semilogy(violation_dict['t'],violation_dict['3'],linestyle='--',label='2200_3',color=colors[3])\n",
    "  plt.semilogy(violation_dict['t'],violation_dict['2'],linestyle='--',label='2200_2',color=colors[2])\n",
    "  plt.semilogy(violation_dict['t'],violation_dict['1'],linestyle='--',label='2200_1',color=colors[1])\n",
    "  plt.semilogy(violation_dict['t'],violation_dict['0'],linestyle='--',label='2200_0',color=colors[0])\n",
    "\n",
    "  plt.xlabel('t')\n",
    "  plt.ylabel(\"violations\")\n",
    "  plt.legend()\n",
    "  plt.tight_layout()\n",
    "  plt.savefig(cce_data.parent/\"violations.png\")\n",
    "  plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from spherical_functions import LM_index as lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm(2,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_file = Path(\"/resnick/groups/sxs/hchaudha/spec_runs/CCE_stuff/Lev4_061CCE/BondiCceR0334/red_cce.h5\")\n",
    "\n",
    "with h5py.File(h5_file, 'r') as hf:\n",
    "    print(\"Keys: \", list(hf.keys()))\n",
    "    print(\"Keys: \", list(hf['SpectreR0334.cce'].keys()))\n",
    "    print(hf['SpectreR0334.cce']['Psi4'].shape)\n",
    "    print(hf['SpectreR0334.cce']['EthInertialRetardedTime'].shape)\n",
    "\n",
    "    data = np.array(hf['SpectreR0334.cce']['Strain'][1:-1:100,:])\n",
    "    # plt.plot(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = data[:,0]\n",
    "y = data[:,9]\n",
    "# plt.plot(t,y)\n",
    "# plt.plot(t,data[:,10])\n",
    "plt.plot(t,np.sqrt(data[:,10]**2+data[:,9]**2))\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1/r sized sphereC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_max = 1000\n",
    "r_min = 54\n",
    "numC = 15\n",
    "\n",
    "a = 1.1\n",
    "GM_sum = (a**numC - 1)/(a-1)\n",
    "r0 = (r_max - r_min)/GM_sum\n",
    "\n",
    "# [r0*a**i for i in range(numC)]\n",
    "size = [r0*a**i for i in range(numC)]\n",
    "boundaries = [r_min]\n",
    "for bnd in (np.cumsum([r0*a**i for i in range(numC)]) + r_min):\n",
    "    boundaries.append(bnd)\n",
    "boundaries, size\n",
    "[int(i) for i in boundaries], [int(i) for i in size]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sxs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
