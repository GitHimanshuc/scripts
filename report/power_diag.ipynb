{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from random import choice as rc\n",
    "import re\n",
    "from typing import List\n",
    "import pyarrow as pa\n",
    "import pickle\n",
    "import string\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams[\"figure.figsize\"] = (10,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_str_with_underscore(str_list):\n",
    "    a = str_list[0]\n",
    "    for i in str_list[1:]:\n",
    "        a = a + f\"_{i}\" \n",
    "    return a\n",
    "\n",
    "def get_top_name_from_number(top_number:int, subdomain_name:str)->str:\n",
    "    if re.match(r\"Sphere\", subdomain_name):\n",
    "        return ['Bf0I1', 'Bf1S2', 'Bf1S2'][top_number]\n",
    "    elif re.match(r\"Cylinder\", subdomain_name):\n",
    "        return ['Bf0I1', 'Bf1S1', 'Bf2I1'][top_number]\n",
    "    elif re.match(r\"FilledCylinder\", subdomain_name):\n",
    "        return ['Bf0I1', 'Bf1B2Radial', 'Bf1B2'][top_number]\n",
    "    else:\n",
    "        raise Exception(f\"{subdomain_name=} not recognized!\")\n",
    "\n",
    "def get_domain_name(col_name):\n",
    "  def AMR_domains_to_decimal(subdoamin_name):\n",
    "    # SphereC28.0.1\n",
    "    a = subdoamin_name.split(\".\")\n",
    "    # a = [SphereC28,0,1]\n",
    "    decimal_rep = a[0]+\".\"\n",
    "    # decimal_rep = SphereC28.\n",
    "    for i in a[1:]:\n",
    "      decimal_rep = decimal_rep + i\n",
    "    # decimal_rep = SphereC28.01\n",
    "    return decimal_rep\n",
    "\n",
    "  if \"on\" in col_name:\n",
    "    return AMR_domains_to_decimal(col_name.split(\" \")[-1])\n",
    "  if \".\" in col_name:\n",
    "    return AMR_domains_to_decimal(col_name.split(\" \")[-1])\n",
    "  elif \"_\" in col_name:\n",
    "    return col_name.split(\"_\")[0]\n",
    "  elif \"MinimumGridSpacing\" in col_name:\n",
    "    return col_name.split(\"[\")[-1][:-1]\n",
    "  else:\n",
    "    return col_name\n",
    "    # raise Exception(f\"{col_name} type not implemented in return_sorted_domain_names\")\n",
    "\n",
    "def filtered_domain_names(domain_names, filter):\n",
    "    return [i for i in domain_names if re.match(filter, get_domain_name(i))]\n",
    "\n",
    "def sort_spheres(sphere_list,reverse=False):\n",
    "    if len(sphere_list) == 0:\n",
    "        return []\n",
    "    if \"SphereA\" in sphere_list[0]:\n",
    "        return sorted(sphere_list, key=lambda x: float(get_domain_name(x).lstrip('SphereA')), reverse=reverse)\n",
    "    elif \"SphereB\" in sphere_list[0]:\n",
    "        return sorted(sphere_list, key=lambda x: float(get_domain_name(x).lstrip('SphereB')), reverse=reverse)\n",
    "    elif \"SphereC\" in sphere_list[0]:\n",
    "        return sorted(sphere_list, key=lambda x: float(get_domain_name(x).lstrip('SphereC')), reverse=reverse)\n",
    "    elif \"SphereD\" in sphere_list[0]:\n",
    "        return sorted(sphere_list, key=lambda x: float(get_domain_name(x).lstrip('SphereD')), reverse=reverse)\n",
    "    elif \"SphereE\" in sphere_list[0]:\n",
    "        return sorted(sphere_list, key=lambda x: float(get_domain_name(x).lstrip('SphereE')), reverse=reverse)\n",
    "\n",
    "def return_sorted_domain_names(domain_names):\n",
    "\n",
    "  FilledCylinderCA = filtered_domain_names(domain_names, r'FilledCylinder.{0,2}CA')\n",
    "  CylinderCA = filtered_domain_names(domain_names, r'Cylinder.{0,2}CA')\n",
    "  FilledCylinderEA = filtered_domain_names(domain_names, r'FilledCylinder.{0,2}EA')\n",
    "  CylinderEA = filtered_domain_names(domain_names, r'Cylinder.{0,2}EA')\n",
    "  SphereA = sort_spheres(filtered_domain_names(domain_names, 'SphereA'), reverse=True)\n",
    "  CylinderSMA = filtered_domain_names(domain_names, r'CylinderS.{0,2}MA')\n",
    "  FilledCylinderMA = filtered_domain_names(domain_names, r'FilledCylinder.{0,2}MA')\n",
    "\n",
    "  FilledCylinderMB = filtered_domain_names(domain_names, r'FilledCylinder.{0,2}MB')\n",
    "  CylinderSMB = filtered_domain_names(domain_names, r'CylinderS.{0,2}MB')\n",
    "  SphereB = sort_spheres(filtered_domain_names(domain_names, 'SphereB'), reverse=True)\n",
    "  CylinderEB = filtered_domain_names(domain_names, r'Cylinder.{0,2}EB')\n",
    "  FilledCylinderEB = filtered_domain_names(domain_names, r'FilledCylinder.{0,2}EB')\n",
    "  CylinderCB = filtered_domain_names(domain_names, r'Cylinder.{0,2}CB')\n",
    "  FilledCylinderCB = filtered_domain_names(domain_names, r'FilledCylinder.{0,2}CB')\n",
    "\n",
    "  SphereC = sort_spheres(filtered_domain_names(domain_names, 'SphereC'), reverse=False)\n",
    "  SphereD = sort_spheres(filtered_domain_names(domain_names, 'SphereD'), reverse=False)\n",
    "  SphereE = sort_spheres(filtered_domain_names(domain_names, 'SphereE'), reverse=False)\n",
    "\n",
    "\n",
    "  combined_columns = [FilledCylinderCA, CylinderCA, FilledCylinderEA, CylinderEA, SphereA, CylinderSMA, FilledCylinderMA, FilledCylinderMB, CylinderSMB, SphereB, CylinderEB, FilledCylinderEB, CylinderCB, FilledCylinderCB, SphereC, SphereD, SphereE]\n",
    "  combined_columns = [item for sublist in combined_columns for item in sublist]\n",
    "\n",
    "  # Just append the domains not following any patterns in the front. Mostly domains surrounding sphereA for high spin and mass ratios\n",
    "  combined_columns_set = set(combined_columns)\n",
    "  domain_names_set = set()\n",
    "  for i in domain_names:\n",
    "    domain_names_set.add(i)\n",
    "  subdomains_not_sorted = list(domain_names_set - combined_columns_set)\n",
    "  return subdomains_not_sorted+combined_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def limit_by_col_val(min_val,max_val,col_name,df):\n",
    "  filter = (df[col_name]>=min_val) &(df[col_name] <=max_val)\n",
    "  return df[filter]\n",
    "\n",
    "def read_dat_file(file_name):\n",
    "  cols_names = []\n",
    "  # Read column names\n",
    "  with open(file_name,'r') as f:\n",
    "      lines = f.readlines()\n",
    "      for line in lines:\n",
    "        if \"#\" not in line:\n",
    "          # From now onwards it will be all data\n",
    "          break\n",
    "        elif \"=\" in line:\n",
    "          if (\"[\" not in line) and (\"]\" not in line):\n",
    "             continue\n",
    "          cols_names.append(line.split('=')[-1][1:-1].strip())\n",
    "        else:\n",
    "          continue\n",
    "\n",
    "  return pd.read_csv(file_name,sep=\"\\s+\",comment=\"#\",names=cols_names)\n",
    "\n",
    "def read_dat_file_single_bh(file_name):\n",
    "  cols_names = []\n",
    "  # Find the max number of columns\n",
    "  with open(file_name,'r') as f:\n",
    "    max_columns = max(len(line.split()) for line in f if not line.startswith('#'))\n",
    "  return pd.read_csv(file_name,sep=\"\\s+\",comment=\"#\",header=None,names=[str(i) for i in np.arange(-1,max_columns)]).rename(columns={'-1': 't'})\n",
    "\n",
    "\n",
    "def find_subdomains(path:Path):\n",
    "  subdomain_set = set()\n",
    "  for i in path.iterdir():\n",
    "    if i.is_dir():\n",
    "      subdomain_set.add(i.stem)\n",
    "\n",
    "  return list(subdomain_set)\n",
    "\n",
    "def find_topologies(path:Path):\n",
    "  topologies_set = set()\n",
    "  for i in path.iterdir():\n",
    "    if i.is_file():\n",
    "      topologies_set.add(i.stem.split(\"_\")[0])\n",
    "\n",
    "  return list(topologies_set)\n",
    "\n",
    "def find_dat_file_names(path:Path):\n",
    "  file_name_set = set()\n",
    "  for i in path.iterdir():\n",
    "    if i.is_file():\n",
    "      file_name_set.add(i.stem.split(\"_\")[1])\n",
    "\n",
    "  return list(file_name_set)\n",
    "\n",
    "def get_top_name_and_mode(name):\n",
    "  # Bf0I1(12 modes).dat -> Bf0I1, 12\n",
    "  top_name = name.split(\"(\")[0]\n",
    "  mode = int(name.split(\"(\")[-1].split(\" \")[0])\n",
    "  return top_name,mode\n",
    "\n",
    "def find_highest_modes_for_topologies(path:Path):\n",
    "  highest_mode_dict = {}\n",
    "  for i in path.iterdir():\n",
    "    if i.is_file():\n",
    "      top_name, mode = get_top_name_and_mode(i.stem)\n",
    "      if top_name in highest_mode_dict:\n",
    "        if highest_mode_dict[top_name] < mode:\n",
    "          highest_mode_dict[top_name] = mode\n",
    "      else:\n",
    "        highest_mode_dict[top_name] = mode\n",
    "\n",
    "  return highest_mode_dict\n",
    "\n",
    "def make_mode_dataframe(path:Path):\n",
    "  highest_mode_dict = find_highest_modes_for_topologies(path)\n",
    "  top_dataframe_list = {i:[] for i in highest_mode_dict}\n",
    "\n",
    "  for i in path.iterdir():\n",
    "    for top_name in highest_mode_dict:\n",
    "      if (top_name+\"(\") in i.stem:\n",
    "        top_dataframe_list[top_name].append(read_dat_file(i))\n",
    "\n",
    "  top_mode_df_dict = {}\n",
    "  for i,df_list in top_dataframe_list.items():\n",
    "    result = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "    # Remove duplicates based on 't' column (keep first occurrence)\n",
    "    # result = result.drop_duplicates(subset='t', keep='first')\n",
    "\n",
    "    # Sort by 't' and reset index\n",
    "    top_mode_df_dict[i] = result.sort_values('t').reset_index(drop=True)\n",
    "  return top_mode_df_dict\n",
    "\n",
    "def filter_columns(cols: List[str], include_patterns: List[str] = None, \n",
    "                  exclude_patterns: List[str] = None) -> List[str]:\n",
    "    \"\"\"\n",
    "    Filter a list of column names using include and exclude regex patterns.\n",
    "    \n",
    "    Args:\n",
    "        cols: List of column names to filter\n",
    "        include_patterns: List of regex patterns to include (if None, includes all)\n",
    "        exclude_patterns: List of regex patterns to exclude (if None, excludes none)\n",
    "    \n",
    "    Returns:\n",
    "        List of filtered column names\n",
    "    \n",
    "    Examples:\n",
    "        >>> cols = ['age_2020', 'age_2021', 'height_2020', 'weight_2021']\n",
    "        >>> filter_columns(cols, ['age_.*'], ['.*2021'])\n",
    "        ['age_2020']\n",
    "    \"\"\"\n",
    "    # Handle None inputs\n",
    "    include_patterns = include_patterns or ['.*']\n",
    "    exclude_patterns = exclude_patterns or []\n",
    "    \n",
    "    # First, get columns that match any include pattern\n",
    "    included_cols = set()\n",
    "    for pattern in include_patterns:\n",
    "        included_cols.update(\n",
    "            col for col in cols \n",
    "            if re.search(pattern, col)\n",
    "        )\n",
    "    \n",
    "    # Then remove any columns that match exclude patterns\n",
    "    for pattern in exclude_patterns:\n",
    "        included_cols = {\n",
    "            col for col in included_cols \n",
    "            if not re.search(pattern, col)\n",
    "        }\n",
    "    \n",
    "    return sorted(list(included_cols))\n",
    "\n",
    "def chain_filter_columns(cols: List[str], include_patterns: List[str] = None, \n",
    "                        exclude_patterns: List[str] = None) -> List[str]:\n",
    "    \"\"\"\n",
    "    Filter columns sequentially using chained include and exclude regex patterns.\n",
    "    Each pattern filters from the result of the previous pattern.\n",
    "    \n",
    "    Args:\n",
    "        cols: List of column names to filter\n",
    "        include_patterns: List of regex patterns to include (if None, includes all)\n",
    "        exclude_patterns: List of regex patterns to exclude (if None, excludes none)\n",
    "    \n",
    "    Returns:\n",
    "        List of filtered column names\n",
    "    \n",
    "    Examples:\n",
    "        >>> cols = ['age_2020_q1', 'age_2020_q2', 'age_2021_q1', 'height_2020_q1']\n",
    "        >>> chain_filter_columns(cols, ['age_.*', '.*q1'], ['.*2021.*'])\n",
    "        ['age_2020_q1']\n",
    "    \"\"\"\n",
    "    # Handle None inputs\n",
    "    include_patterns = include_patterns or ['.*']\n",
    "    exclude_patterns = exclude_patterns or []\n",
    "    \n",
    "    # Start with all columns\n",
    "    filtered_cols = set(cols)\n",
    "    \n",
    "    # Apply include patterns sequentially\n",
    "    for pattern in include_patterns:\n",
    "        filtered_cols = {\n",
    "            col for col in filtered_cols \n",
    "            if re.search(pattern, col)\n",
    "        }\n",
    "    \n",
    "    # Apply exclude patterns sequentially\n",
    "    for pattern in exclude_patterns:\n",
    "        filtered_cols = {\n",
    "            col for col in filtered_cols \n",
    "            if not re.search(pattern, col)\n",
    "        }\n",
    "    \n",
    "    return sorted(list(filtered_cols))\n",
    "\n",
    "def sort_by_coefs_numbers(col_list:List[str]):\n",
    "  with_coef_list = []\n",
    "  without_coef_list = []\n",
    "  for col in col_list:\n",
    "    if 'coef' not in col:\n",
    "      without_coef_list.append(col)\n",
    "    else:\n",
    "      with_coef_list.append(col)\n",
    "  return without_coef_list+sorted(with_coef_list, key=lambda x: int(x.split(\"_\")[-1][4:]))\n",
    "\n",
    "def get_extreme_coef_for_each_domain(df, min_or_max='min'):\n",
    "    col_names = df.columns\n",
    "    subdomains = set([i.split(\"_\")[0] for i in col_names]) - set(['t(M)'])\n",
    "    exterme_coef = {'t(M)':df['t(M)']}\n",
    "    for sd in subdomains:\n",
    "        sd_cols = [i for i in col_names if f\"{sd}_\" in i]\n",
    "        if min_or_max == 'max':\n",
    "            exterme_coef[sd] = df[sd_cols].max(axis=1)\n",
    "        elif min_or_max == 'min':\n",
    "            exterme_coef[sd] = df[sd_cols].min(axis=1)\n",
    "        else:\n",
    "            raise Exception(f\"Only supported values of min_or_max are min and max and not {min_or_max=}\")\n",
    "\n",
    "    return pd.DataFrame(exterme_coef)\n",
    "\n",
    "def load_power_diagonistics(PowDiag_path:Path):\n",
    "  pow_diag_dict = {}\n",
    "  for sd in find_subdomains(PowDiag_path):\n",
    "    pow_diag_dict[sd] = {}\n",
    "    sd_path = PowDiag_path/f\"{sd}.dir\"\n",
    "\n",
    "    psi_pd = make_mode_dataframe(sd_path/f\"Powerpsi.dir\")\n",
    "    kappa_pd = make_mode_dataframe(sd_path/f\"Powerkappa.dir\")\n",
    "    # For each subdomain save things by topology\n",
    "    for top in find_topologies(sd_path):\n",
    "      pow_diag_dict[sd][top]={}\n",
    "      psi_pd_sorted_cols = sort_by_coefs_numbers(psi_pd[top].columns.to_list())\n",
    "      pow_diag_dict[sd][top][f'psi_ps'] = psi_pd[top][psi_pd_sorted_cols]\n",
    "\n",
    "      kappa_pd_sorted_cols = sort_by_coefs_numbers(kappa_pd[top].columns.to_list())\n",
    "      pow_diag_dict[sd][top][f'kappa_ps'] = kappa_pd[top][kappa_pd_sorted_cols]\n",
    "\n",
    "      for dat_file in find_dat_file_names(sd_path):\n",
    "        pow_diag_dict[sd][top][f'{dat_file}'] = read_dat_file(sd_path/f\"{top}_{dat_file}.dat\")\n",
    "  \n",
    "  return pow_diag_dict\n",
    "\n",
    "\n",
    "def load_power_diagonistics_flat(PowDiag_path:Path, reload:bool=False, return_df:bool=True, load_dat_files_only:list[str]=None):\n",
    "  \n",
    "  cache_data = PowDiag_path/\"pandas.pkl\"\n",
    "  if cache_data.exists():\n",
    "    if not reload:\n",
    "        with open(cache_data, 'rb') as f:\n",
    "            pow_diag_dict = pickle.load(f)\n",
    "            print(f\"Loaded from cache {cache_data}\")\n",
    "        return pow_diag_dict\n",
    "\n",
    "  # Same as load_power_diagonistics but no nested dicts. This makes it easy to filter\n",
    "  pow_diag_dict = {}\n",
    "  for sd in find_subdomains(PowDiag_path):\n",
    "    sd_path = PowDiag_path/f\"{sd}.dir\"\n",
    "\n",
    "    for top in find_topologies(sd_path):\n",
    "      for dat_file in find_dat_file_names(sd_path):\n",
    "        if load_dat_files_only is not None:\n",
    "            for allowed_dat_files in load_dat_files_only:\n",
    "                if re.search(allowed_dat_files, dat_file) is None:\n",
    "                    continue\n",
    "                else:\n",
    "                    print(dat_file)\n",
    "        pow_diag_dict[f'{sd}_{top}_{dat_file}'] = read_dat_file(sd_path/f\"{top}_{dat_file}.dat\")\n",
    "    if load_dat_files_only is not None:\n",
    "        print(sd_path)\n",
    "        continue\n",
    "\n",
    "    psi_pd = make_mode_dataframe(sd_path/f\"Powerpsi.dir\")\n",
    "    kappa_pd = make_mode_dataframe(sd_path/f\"Powerkappa.dir\")\n",
    "    # For each subdomain save things by topology\n",
    "    for top in find_topologies(sd_path):\n",
    "      psi_pd_sorted_cols = sort_by_coefs_numbers(psi_pd[top].columns.to_list())\n",
    "      pow_diag_dict[f'{sd}_{top}_psi_ps'] = psi_pd[top][psi_pd_sorted_cols]\n",
    "\n",
    "      kappa_pd_sorted_cols = sort_by_coefs_numbers(kappa_pd[top].columns.to_list())\n",
    "      pow_diag_dict[f'{sd}_{top}_kappa_ps'] = kappa_pd[top][kappa_pd_sorted_cols]\n",
    "\n",
    "    print(sd_path)\n",
    "  \n",
    "  if return_df:\n",
    "    # This can be definitely merged with the stuff above but it's fast enough anyways\n",
    "    flat_dict = {}\n",
    "    flat_dict['t'] = pow_diag_dict[rc(list(pow_diag_dict.keys()))]['t']\n",
    "    for key,item in pow_diag_dict.items():\n",
    "      for col in item.columns:\n",
    "        if 't' == col:\n",
    "          continue \n",
    "        else:\n",
    "          flat_dict[f\"{key}_{col}\"] = item[col]\n",
    "\n",
    "    flat_df = pd.DataFrame(flat_dict)\n",
    "    with open(cache_data, 'wb') as f:\n",
    "        pickle.dump(flat_df, f)\n",
    "        print(f\"Cached at {cache_data}\")\n",
    "\n",
    "    return flat_df\n",
    "\n",
    "\n",
    "  return pow_diag_dict\n",
    "\n",
    "\n",
    "def convert_series_to_coeff_df(data, top_num):\n",
    "    irr_top_regex = 0\n",
    "    match top_num:\n",
    "        case 0:\n",
    "            irr_top_regex = r'Bf0' # First top\n",
    "        case 1:\n",
    "            irr_top_regex = r'Bf1(S\\d|B2R)' # Second top, S2 for spheres, B2 for filled cylinders\n",
    "        case 2:\n",
    "            irr_top_regex = r'((Bf1S2|Bf1B2_)|Bf2)' # Thrid top S2 for spheres, B2 radial for filled cylinders\n",
    "        case _:\n",
    "            raise Exception(f\"{top_num=} should be one of [0,1,2]\")\n",
    "        \n",
    "\n",
    "    indices = set(data.index) - set(['t(M)'])\n",
    "    indices = set([i for i in indices if re.search(irr_top_regex,i)])\n",
    "\n",
    "    subdomains = set([i.split(\"_\")[0] for i in indices]) \n",
    "    # The coefs are sorted?? Do not assume but they are\n",
    "\n",
    "    data_dict = {sd:{} for sd in subdomains}\n",
    "\n",
    "    coef_number = lambda x: int(x.split(\"_\")[-1][4:])\n",
    "\n",
    "    max_coef = 0\n",
    "    for sd in subdomains:\n",
    "        for idx in indices:\n",
    "            if f\"{sd}_\" in idx:\n",
    "                if pd.notna(data[idx]):\n",
    "                    data_dict[sd][coef_number(idx)] = data[idx]\n",
    "        data_dict[sd] = dict(sorted(data_dict[sd].items()))\n",
    "        if len(data_dict[sd]) > max_coef:\n",
    "            max_coef = len(data_dict[sd])\n",
    "\n",
    "\n",
    "    pd_data = pd.DataFrame(data_dict)\n",
    "    return pd_data\n",
    "\n",
    "def series_closest_to_time(t,df):\n",
    "    time_index = np.where(df['t(M)']>t)[0][0]\n",
    "    time = df['t(M)'][time_index]\n",
    "    return time, df.iloc[time_index].copy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = Path(\"/groups/sxs/hchaudha/spec_runs/del/filtering/6_set1_L3_Lev3/extracted-PowerDiagnostics/SphereC0.dir/Powerpsi.dir/Bf0I1(19 modes).dat\")\n",
    "file = Path(\"/groups/sxs/hchaudha/spec_runs/del/filtering/16_set1_L3_Lev3/extracted-PowerDiagnostics/SphereC0.dir/Powerpsi.dir/Bf0I1(20 modes).dat\")\n",
    "# file = Path(\"/groups/sxs/hchaudha/spec_runs/del/filtering/16_set1_L3_Lev3/extracted-PowerDiagnostics/SphereC0.dir/Bf0I1_HighestThirdConvergenceFactor.dat\")\n",
    "# file = Path(\"/groups/sxs/hchaudha/spec_runs/del/filtering/6_set1_L3_Lev3/extracted-PowerDiagnostics/SphereC0.dir/Bf0I1_TruncationError.dat\")\n",
    "# file = Path(\"/groups/sxs/hchaudha/spec_runs/del/filtering/13_set1_L4_1500_Lev4/extracted-PowerDiagnostics/SphereC10.dir/Powerpsi.dir/Bf1S2(15 modes).dat\")\n",
    "file = Path(\"/groups/sxs/hchaudha/spec_runs/del/filtering/16_set1_L3_HP32_AF_Lev3/extracted-PowerDiagnostics/SphereC0.dir/Powerkappa.dir/Bf0I1(15 modes).dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BBH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = read_dat_file(file)\n",
    "h5_paths = []\n",
    "# h5_paths.append(Path('/groups/sxs/hchaudha/spec_runs/del/filtering/13_set1_L4_1500_Lev4'))\n",
    "# h5_paths.append(Path('/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/h5_files_Lev5'))\n",
    "# h5_paths.append(Path('/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_master/h5_files_Lev3'))\n",
    "# h5_paths.append(Path('/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_master/h5_files_Lev4'))\n",
    "# h5_paths.append(Path('/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_master/h5_files_Lev5'))\n",
    "# h5_paths.append(Path('/groups/sxs/hchaudha/spec_runs/6_segs/6_set3_L6/h5_files_Lev6/'))\n",
    "# h5_paths.append(Path('/groups/sxs/hchaudha/spec_runs/6_segs/6_set1_L6/h5_files_Lev0/'))\n",
    "# h5_paths.append(Path('/groups/sxs/hchaudha/spec_runs/6_segs/6_set1_L6/h5_files_Lev1/'))\n",
    "# h5_paths.append(Path('/groups/sxs/hchaudha/spec_runs/6_segs/6_set1_L6/h5_files_Lev2/'))\n",
    "# h5_paths.append(Path('/groups/sxs/hchaudha/spec_runs/6_segs/6_set1_L6/h5_files_Lev3/'))\n",
    "# h5_paths.append(Path('/groups/sxs/hchaudha/spec_runs/6_segs/6_set1_L6/h5_files_Lev4/'))\n",
    "# h5_paths.append(Path('/groups/sxs/hchaudha/spec_runs/6_segs/6_set1_L6/h5_files_Lev5/'))\n",
    "# h5_paths.append(Path('/groups/sxs/hchaudha/spec_runs/6_segs/6_set1_L6/h5_files_Lev6/'))\n",
    "# h5_paths.append(Path('/groups/sxs/hchaudha/spec_runs/6_segs/6_set1_L6/h5_files_Lev0/'))\n",
    "# h5_paths.append(Path('/groups/sxs/hchaudha/spec_runs/6_segs/6_set1_L3/h5_files_Lev3'))\n",
    "# h5_paths.append(Path('/groups/sxs/hchaudha/spec_runs/16_set1_L3/h5_files_Lev3/'))\n",
    "# h5_paths.append(Path('/groups/sxs/hchaudha/spec_runs/16_set1_L3_HP28/h5_files_Lev3'))\n",
    "# h5_paths.append(Path('/groups/sxs/hchaudha/spec_runs/6_segs/6_set1_L6/h5_files_Lev6/'))\n",
    "# h5_paths.append(Path('/groups/sxs/hchaudha/spec_runs/17_set_main_q3_18_L3/h5_files_Lev3'))\n",
    "# h5_paths.append(Path('/groups/sxs/hchaudha/spec_runs/17_set1_q3_18_L3/h5_files_Lev3'))\n",
    "# h5_paths.append(Path('/groups/sxs/hchaudha/spec_runs/17_set3_q3_18_L3/h5_files_Lev3'))\n",
    "\n",
    "# h5_paths.append(Path(\"/groups/sxs/hchaudha/spec_runs/20_set1_L3_fine_cylinders/temp_h5_files_Lev3\"))\n",
    "# h5_paths.append(Path(\"/groups/sxs/hchaudha/spec_runs/21_set1_L3_fine_cylinders_minExtent/temp_h5_files_Lev3\"))\n",
    "# h5_paths.append(Path(\"/groups/sxs/hchaudha/spec_runs/22_set1_L1_long/h5_files_Lev1\"))\n",
    "# h5_paths.append(Path(\"/groups/sxs/hchaudha/spec_runs/22_set1_L3_long/h5_files_Lev3\"))\n",
    "\n",
    "# h5_paths.append(Path(\"/groups/sxs/hchaudha/spec_runs/26_main_L6_long/h5_files_8000M_Lev6\"))\n",
    "# h5_paths.append(Path(\"/groups/sxs/hchaudha/spec_runs/26_set1_L6_long/h5_files_Lev6\"))\n",
    "# h5_paths.append(Path(\"/groups/sxs/hchaudha/spec_runs/26_segs/set1_L6_AK_S2_L20_no_Rmin/h5_files_AK_Lev6\"))\n",
    "\n",
    "# h5_paths.append(Path(\"/resnick/groups/sxs/hchaudha/spec_runs/30_RM_set1_L3/h5_files_Lev3\"))\n",
    "# h5_paths.append(Path(\"/resnick/groups/sxs/hchaudha/spec_runs/RM_0_test/h5_files_Lev6\"))\n",
    "# h5_paths.append(Path(\"/resnick/groups/sxs/hchaudha/spec_runs/RM_1_Lev3/h5_files_Lev3\"))\n",
    "# h5_paths.append(Path(\"/resnick/groups/sxs/hchaudha/spec_runs/30_RM_set1_L1/h5_files_Lev1\"))\n",
    "\n",
    "# h5_paths.append(Path(\"/groups/sxs/hchaudha/spec_runs/del\"))\n",
    "\n",
    "h5_paths.append(Path('/groups/sxs/hchaudha/spec_runs/6_segs/6_set1_L6/h5_files_Lev6/'))\n",
    "h5_paths.append(Path('/groups/sxs/hchaudha/spec_runs/6_segs/6_set3_L6/h5_files_Lev6/'))\n",
    "\n",
    "domain = 'SphereA0'\n",
    "domain = 'SphereA4'\n",
    "# domain = 'FilledCylinderMA0'\n",
    "# domain = 'FilledCylinderMA1'\n",
    "# domain = 'CylinderSMB0.0'\n",
    "domain = 'CylinderSMA1.0'\n",
    "# domain = 'CylinderEA0.0.0'\n",
    "# domain = 'CylinderEA1.0.0'\n",
    "# domain = 'FilledCylinderEA0'\n",
    "# domain = 'FilledCylinderEA1'\n",
    "# domain = 'CylinderCA0.0.0'\n",
    "# domain = 'CylinderCA1.0.0'\n",
    "# domain = 'FilledCylinderCA0'\n",
    "# domain = 'FilledCylinderCA1'\n",
    "# domain = 'CylinderCA1.0.0'\n",
    "# domain = 'SphereC0'\n",
    "# domain = 'SphereC6'\n",
    "# domain = 'SphereC0'\n",
    "# domain = 'SphereC6'\n",
    "\n",
    "if \"RM\" in str(h5_paths[-1]):\n",
    "    psi_or_kappa = 'RMpsi'\n",
    "else:\n",
    "    psi_or_kappa = 'psi'\n",
    "# psi_or_kappa = 'kappa'\n",
    "\n",
    "folder_paths = [Path(f\"{h5_path}/extracted-PowerDiagnostics/{domain}.dir/Power{psi_or_kappa}.dir\") for h5_path in h5_paths]\n",
    "top_data_dict = {join_str_with_underscore(str(folder_path).split(\"/\")[-5:-3]+[domain]) : make_mode_dataframe(folder_path) for folder_path in folder_paths}\n",
    "print(top_data_dict[list(top_data_dict.keys())[0]].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_name = get_top_name_from_number(0,domain)\n",
    "top_name = get_top_name_from_number(1,domain)\n",
    "top_name = get_top_name_from_number(2,domain)\n",
    "\n",
    "\n",
    "# top_name = list(top_data.keys())[0]\n",
    "t_min = 0\n",
    "t_min = 2000\n",
    "t_min = 3000\n",
    "# t_min = 9700\n",
    "t_max = 40000\n",
    "# t_max = 8400\n",
    "\n",
    "min_coef = -1\n",
    "# min_coef = 10\n",
    "max_coef = 100\n",
    "# max_coef = -4\n",
    "plot_slice = slice(0,None)\n",
    "# plot_slice = slice(0,-4)\n",
    "# plot_slice = slice(-1,None)\n",
    "\n",
    "title = \"\"\n",
    "# plt.figure(figsize=(10, 7))\n",
    "has_more_than_one = len(list(top_data_dict.keys())) > 1\n",
    "style_list = ['-',':','--','-.']\n",
    "num_legends = 0\n",
    "single_legend,max_col = True,-1\n",
    "for key_num,A,key in zip(range(100),string.ascii_uppercase,top_data_dict):\n",
    "\n",
    "    # if 'Lev5' not in key:\n",
    "    #     continue\n",
    "\n",
    "    plt.gca().set_prop_cycle(None)\n",
    "    data = top_data_dict[key][top_name]\n",
    "    data = limit_by_col_val(t_min,t_max,'t',data)\n",
    "    data = data.dropna(axis=1, how='all')  # Some columns will have just nans remove those\n",
    "    column_names = data.columns[1:]\n",
    "    visual_data = data[column_names]\n",
    "\n",
    "    cols_to_use = [i for i in data.columns if 't' not in i]\n",
    "    df = np.log10(data[cols_to_use])\n",
    "    df['row_min'] = df.min(axis=1)\n",
    "    df['row_max'] = df.max(axis=1)\n",
    "    df['row_mean'] = df.mean(axis=1)\n",
    "    df['row_std'] = df.std(axis=1)\n",
    "\n",
    "    # plt.plot(df['row_min'])\n",
    "    # plt.plot(df['row_mean'])\n",
    "    # plt.plot(df['row_max'])\n",
    "    # plt.plot(df['row_std'])\n",
    "    for i in cols_to_use[plot_slice]:\n",
    "        coef_num = int(i[4:])\n",
    "        if coef_num < min_coef or coef_num > max_coef:\n",
    "            continue\n",
    "        # plt.plot(data['t'], df[f'{i}'])\n",
    "        label = f\"{i}\"\n",
    "        if has_more_than_one:\n",
    "            if (max_col < coef_num):\n",
    "                label = f\"{A}: {i}\"\n",
    "                num_legends = num_legends + 1\n",
    "            else:\n",
    "                label = None\n",
    "            max_col = max(coef_num,max_col)\n",
    "        plt.plot(data['t'], df[f'{i}'], label = label, linestyle = style_list[key_num%len(style_list)])\n",
    "\n",
    "    if has_more_than_one:\n",
    "        title  = title+ f\"{style_list[key_num%len(style_list)]}  {A}: \"\n",
    "    title = title+f'{key}_{top_name}\\n'\n",
    "\n",
    "if num_legends > 20:\n",
    "    plt.legend(ncol=int(np.ceil(num_legends/20)))\n",
    "else:\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.title(title[:-1])\n",
    "plt.xlabel('t(M)')\n",
    "plt.ylabel(f'Power {psi_or_kappa}')\n",
    "plt.tight_layout() \n",
    "plt.grid(False)\n",
    "# plt.ylim(-16,-12)\n",
    "plt.show()\n",
    "# x = data['t']\n",
    "# y = df['row_mean']\n",
    "# y_err = df['row_std']\n",
    "# plt.errorbar(x, y, yerr=y_err, fmt='-o', label='Data with Error Bars', ecolor='red', capsize=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_name = get_top_name_from_number(0,domain)\n",
    "top_name = get_top_name_from_number(1,domain)\n",
    "# top_name = get_top_name_from_number(2,domain)\n",
    "\n",
    "# top_name = list(top_data.keys())[0]\n",
    "t_min = 0\n",
    "# t_min = 800\n",
    "t_min = 1400\n",
    "t_min = 3000\n",
    "t_min = 9000\n",
    "t_max = 40000\n",
    "# t_max = 4000\n",
    "\n",
    "min_coef = -1\n",
    "# min_coef = 7\n",
    "max_coef = 100\n",
    "# max_coef = 10\n",
    "plot_slice = slice(0,None)\n",
    "if 'f0' in top_name:\n",
    "    plot_slice = slice(-1,None) # use for cheby last mode\n",
    "elif 'S2' in top_name:\n",
    "    plot_slice = slice(-5,-4) # use for S2 5th from last\n",
    "else:\n",
    "    plot_slice = slice(0,None) # No idea what to do\n",
    "\n",
    "title = \"\"\n",
    "# plt.figure(figsize=(10, 7))\n",
    "has_more_than_one = len(list(top_data_dict.keys())) > 1\n",
    "style_list = ['-',':','--','-.']\n",
    "num_legends = 0\n",
    "single_legend,max_col = True,0\n",
    "for key_num,A,key in zip(range(100),string.ascii_uppercase,top_data_dict):\n",
    "    # plt.gca().set_prop_cycle(None)\n",
    "    data = top_data_dict[key][top_name]\n",
    "    data = limit_by_col_val(t_min,t_max,'t',data)\n",
    "    data = data.dropna(axis=1, how='all')  # Some columns will have just nans remove those\n",
    "    column_names = data.columns[1:]\n",
    "    visual_data = data[column_names]\n",
    "\n",
    "    cols_to_use = [i for i in data.columns if 't' not in i]\n",
    "    df = np.log10(data[cols_to_use])\n",
    "    df['row_min'] = df.min(axis=1)\n",
    "    df['row_max'] = df.max(axis=1)\n",
    "    df['row_mean'] = df.mean(axis=1)\n",
    "    df['row_std'] = df.std(axis=1)\n",
    "\n",
    "    # plt.plot(df['row_min'])\n",
    "    # plt.plot(df['row_mean'])\n",
    "    # plt.plot(df['row_max'])\n",
    "    # plt.plot(df['row_std'])\n",
    "    for i in cols_to_use[plot_slice]:\n",
    "        coef_num = int(i[4:])\n",
    "        if coef_num < min_coef or coef_num > max_coef:\n",
    "            continue\n",
    "        # plt.plot(data['t'], df[f'{i}'])\n",
    "        label = f\"{key}_{i}\"\n",
    "        plt.plot(data['t'], df[f'{i}'], label = label, linestyle = style_list[key_num%len(style_list)])\n",
    "\n",
    "    # if has_more_than_one:\n",
    "    #     title  = title+ f\"{style_list[key_num%len(style_list)]}  {A}: \"\n",
    "    # title = title+f'{key}_{top_name}\\n'\n",
    "    title = f' {domain}:{top_name}'\n",
    "\n",
    "if num_legends > 20:\n",
    "    plt.legend(ncol=int(np.ceil(num_legends/20)))\n",
    "else:\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.title(title[:-1])\n",
    "plt.xlabel('t(M)')\n",
    "plt.ylabel(f'Power {psi_or_kappa}')\n",
    "plt.tight_layout() \n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "# x = data['t']\n",
    "# y = df['row_mean']\n",
    "# y_err = df['row_std']\n",
    "# plt.errorbar(x, y, yerr=y_err, fmt='-o', label='Data with Error Bars', ecolor='red', capsize=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### APS plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_name = get_top_name_from_number(0,domain)\n",
    "# top_name = get_top_name_from_number(1,domain)\n",
    "# top_name = get_top_name_from_number(2,domain)\n",
    "\n",
    "\n",
    "# top_name = list(top_data.keys())[0]\n",
    "t_min = 0\n",
    "t_min = 800\n",
    "t_min = 3000\n",
    "# t_min = 7000\n",
    "t_max = 40000\n",
    "# t_max = 4000\n",
    "\n",
    "min_coef = -1\n",
    "# min_coef = 7\n",
    "max_coef = 100\n",
    "# max_coef = 10\n",
    "plot_slice = slice(0,None)\n",
    "# plot_slice = slice(-1,None)\n",
    "\n",
    "title = \"\"\n",
    "# plt.figure(figsize=(10, 7))\n",
    "has_more_than_one = len(list(top_data_dict.keys())) > 1\n",
    "style_list = ['-',':','--','-.']\n",
    "num_legends = 0\n",
    "single_legend,max_col = True,0\n",
    "for key_num,A,key in zip(range(100),string.ascii_uppercase,top_data_dict):\n",
    "    with plt.style.context(\"ggplot\"):\n",
    "        plt.rcParams[\"figure.figsize\"] = (8, 5.5)\n",
    "        plt.gca().set_prop_cycle(None)\n",
    "        data = top_data_dict[key][top_name]\n",
    "        data = limit_by_col_val(t_min,t_max,'t',data)\n",
    "        data = data.dropna(axis=1, how='all')  # Some columns will have just nans remove those\n",
    "        column_names = data.columns[1:]\n",
    "        visual_data = data[column_names]\n",
    "\n",
    "        cols_to_use = [i for i in data.columns if 't' not in i]\n",
    "        df = np.log10(data[cols_to_use])\n",
    "\n",
    "        for i in cols_to_use[plot_slice]:\n",
    "            coef_num = int(i[4:])\n",
    "            if coef_num < min_coef or coef_num > max_coef:\n",
    "                continue\n",
    "            label = f\"$a_{{{i[4:]}}}$\"\n",
    "            plt.plot(data['t'], np.power(10,df[f'{i}']), label = label, linestyle = style_list[key_num%len(style_list)])\n",
    "        \n",
    "        plt.yscale('log')\n",
    "\n",
    "        title = title+f'{key}_{top_name}\\n'\n",
    "\n",
    "if num_legends > 20:\n",
    "    plt.legend(ncol=int(np.ceil(num_legends/20)))\n",
    "else:\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "if domain == \"SphereC6\":\n",
    "    front = \"Wave Zone, \"\n",
    "else:\n",
    "    front = \"Near the horizon, \"\n",
    "\n",
    "if psi_or_kappa == 'psi':\n",
    "    title = front+r\"norm($g_{ab}$)\"\n",
    "else:\n",
    "    title = front+r\"norm($\\partial g_{ab}$)\"\n",
    "\n",
    "plt.title(title)\n",
    "plt.xlabel('t(M)')\n",
    "plt.ylabel(f'abs(coeffs)')\n",
    "plt.tight_layout() \n",
    "plt.grid(False)\n",
    "\n",
    "if domain == \"SphereC6\":\n",
    "    plt.savefig(Path(\"/groups/sxs/hchaudha/scripts/report/figures\")/f\"spec_wave_{psi_or_kappa}.png\", dpi=600)\n",
    "else:\n",
    "    plt.savefig(Path(\"/groups/sxs/hchaudha/scripts/report/figures\")/f\"spec_near_bh_{psi_or_kappa}.png\", dpi=600)\n",
    "\n",
    "plt.show()\n",
    "# x = data['t']\n",
    "# y = df['row_mean']\n",
    "# y_err = df['row_std']\n",
    "# plt.errorbar(x, y, yerr=y_err, fmt='-o', label='Data with Error Bars', ecolor='red', capsize=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = read_dat_file(file)\n",
    "dat_paths = []\n",
    "# dat_paths.append(Path('/groups/sxs/hchaudha/spec_runs/single_bh/17_zero_spin_AMR/Lev5_265/'))\n",
    "# dat_paths.append(Path('/groups/sxs/hchaudha/spec_runs/single_bh/20_zero_spin_AMR_L5_10000M/Lev5_9565_longer'))\n",
    "dat_paths.append(Path('/resnick/groups/sxs/hchaudha/spec_runs/single_bh_res/0_ghce_test/Lev7_4665'))\n",
    "\n",
    "domain = 'SphereD0'\n",
    "domain = 'SphereE49'\n",
    "\n",
    "top_name = get_top_name_from_number(0,domain)\n",
    "# top_name = get_top_name_from_number(1,domain)\n",
    "# top_name = get_top_name_from_number(2,domain)\n",
    "\n",
    "psi_or_kappa = 'kappa'\n",
    "psi_or_kappa = 'psi'\n",
    "psi_or_kappa = 'RMpsi'\n",
    "\n",
    "folder_paths = [Path(f\"{dat_path}/Run/AMRDiagnostics/{top_name}Power{psi_or_kappa}_{domain}.dat\") for dat_path in dat_paths]\n",
    "top_data_dict = {}\n",
    "for folder_path in folder_paths:\n",
    "    key_name = str(folder_paths).split(\"/\")[-4]\n",
    "    top_data_dict[key_name] = read_dat_file_single_bh(folder_path)\n",
    "    top_data_dict[key_name] = top_data_dict[key_name].rename(columns={'time': 't'})\n",
    "print(top_data_dict[list(top_data_dict.keys())[0]].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_name = list(top_data.keys())[0]\n",
    "t_min = -1\n",
    "# t_min = 800\n",
    "# t_min = 3000\n",
    "# t_min = 7000\n",
    "t_max = 40000\n",
    "# t_max = 4000\n",
    "\n",
    "min_coef = -1\n",
    "# min_coef = 7\n",
    "max_coef = 100\n",
    "# max_coef = 10\n",
    "plot_slice = slice(0,None)\n",
    "# plot_slice = slice(-1,None)\n",
    "\n",
    "title = \"\"\n",
    "# plt.figure(figsize=(10, 7))\n",
    "has_more_than_one = len(list(top_data_dict.keys())) > 1\n",
    "style_list = ['-',':','--','-.']\n",
    "num_legends = 0\n",
    "single_legend,max_col = True,0\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (6,6)\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "for key_num,A,key in zip(range(100),string.ascii_uppercase,top_data_dict):\n",
    "\n",
    "    # if 'Lev5' not in key:\n",
    "    #     continue\n",
    "\n",
    "    plt.gca().set_prop_cycle(None)\n",
    "    data = top_data_dict[key]\n",
    "    data = limit_by_col_val(t_min,t_max,'t',data)\n",
    "    data = data.dropna(axis=1, how='all')  # Some columns will have just nans remove those\n",
    "    column_names = data.columns[1:]\n",
    "    visual_data = data[column_names]\n",
    "\n",
    "    cols_to_use = [i for i in data.columns if 't' not in i]\n",
    "    df = np.log10(data[cols_to_use])\n",
    "    df['row_min'] = df.min(axis=1)\n",
    "    df['row_max'] = df.max(axis=1)\n",
    "    df['row_mean'] = df.mean(axis=1)\n",
    "    df['row_std'] = df.std(axis=1)\n",
    "\n",
    "    # plt.plot(df['row_min'])\n",
    "    # plt.plot(df['row_mean'])\n",
    "    # plt.plot(df['row_max'])\n",
    "    # plt.plot(df['row_std'])\n",
    "    for i in cols_to_use[plot_slice]:\n",
    "        coef_num = int(i)\n",
    "        if coef_num < min_coef or coef_num > max_coef:\n",
    "            continue\n",
    "        # plt.plot(data['t'], df[f'{i}'])\n",
    "        label = f\"{i}\"\n",
    "        if has_more_than_one:\n",
    "            if (max_col < coef_num):\n",
    "                label = f\"{A}: {i}\"\n",
    "                num_legends = num_legends + 1\n",
    "            else:\n",
    "                label = None\n",
    "            max_col = max(coef_num,max_col)\n",
    "        plt.plot(data['t'], df[f'{i}'], label = label, linestyle = style_list[key_num%len(style_list)])\n",
    "\n",
    "    if has_more_than_one:\n",
    "        title  = title+ f\"{style_list[key_num%len(style_list)]}  {A}: \"\n",
    "    title = title+f'{key}_{domain}_{top_name}\\n'\n",
    "\n",
    "if num_legends > 20:\n",
    "    plt.legend(ncol=int(np.ceil(num_legends/20)))\n",
    "else:\n",
    "    plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.title(title[:-1])\n",
    "plt.xlabel('t(M)')\n",
    "plt.ylabel(f'Power {psi_or_kappa}')\n",
    "plt.tight_layout() \n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "# x = data['t']\n",
    "# y = df['row_mean']\n",
    "# y_err = df['row_std']\n",
    "# plt.errorbar(x, y, yerr=y_err, fmt='-o', label='Data with Error Bars', ecolor='red', capsize=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AMR_diag_paths = Path(\"/groups/sxs/hchaudha/spec_runs/single_bh/20_zero_spin_AMR_L5_10000M/Lev5_9565_3/Run/AMRDiagnostics\")\n",
    "AMR_diag_paths = Path(\"/groups/sxs/hchaudha/spec_runs/single_bh/20_zero_spin_AMR_L5_10000M/Lev5_765/Run/AMRDiagnostics\")\n",
    "\n",
    "files = list(AMR_diag_paths.glob(\"*.dat\"))\n",
    "domains = set()\n",
    "for file in files:\n",
    "    domain = file.stem.split(\"_\")[1]\n",
    "    domains.add(domain)\n",
    "\n",
    "pow_dict = {}\n",
    "for domain in domains:\n",
    "    for var in ['psi','kappa']:\n",
    "        for top in ['Bf0I1','Bf1S2']:\n",
    "            file_name = f\"{top}Power{var}_{domain}.dat\"\n",
    "            file_path = AMR_diag_paths/f\"{file_name}\"\n",
    "\n",
    "            pow_dict[f'{domain}_{top}_TruncationError_GridDiagPower{var}'] = read_dat_file_single_bh(file_path)\n",
    "\n",
    "\n",
    "flat_dict = {}\n",
    "flat_dict['t'] = pow_dict[rc(list(pow_dict.keys()))]['t']\n",
    "for key,item in pow_dict.items():\n",
    "    for col in item.columns:\n",
    "        if 't' == col:\n",
    "            continue \n",
    "        else:\n",
    "            flat_dict[f\"{key}_{col}\"] = np.log10(item[col])\n",
    "\n",
    "flat_df = pd.DataFrame(flat_dict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load all of power diagnostics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PowDiag_path = Path('/groups/sxs/hchaudha/spec_runs/6_segs/6_set3_L6/h5_files_Lev6/extracted-PowerDiagnostics')\n",
    "# PowDiag_path = Path('/groups/sxs/hchaudha/spec_runs/6_segs/6_set1_L3/h5_files_Lev3/extracted-PowerDiagnostics')\n",
    "# PowDiag_path = Path('/groups/sxs/hchaudha/spec_runs/6_segs/6_set1_L6/h5_files_Lev3/extracted-PowerDiagnostics')\n",
    "# PowDiag_path = Path('/groups/sxs/hchaudha/spec_runs/6_segs/6_set1_L6/h5_files_Lev4/extracted-PowerDiagnostics')\n",
    "# PowDiag_path = Path('/groups/sxs/hchaudha/spec_runs/6_segs/6_set1_L6/h5_files_Lev5/extracted-PowerDiagnostics')\n",
    "# PowDiag_path = Path('/groups/sxs/hchaudha/spec_runs/6_segs/6_set1_L6/h5_files_Lev6/extracted-PowerDiagnostics')\n",
    "# PowDiag_path = Path(\"/groups/sxs/hchaudha/spec_runs/16_set1_L3/h5_files_Lev3/extracted-PowerDiagnostics\")\n",
    "# PowDiag_path = Path(\"/groups/sxs/hchaudha/spec_runs/22_set1_L3_long/h5_files_Lev3/extracted-PowerDiagnostics\")\n",
    "PowDiag_path = Path(\"/groups/sxs/hchaudha/spec_runs/26_set1_L6_long/h5_files_Lev6/extracted-PowerDiagnostics\")\n",
    "# PowDiag_path = Path(\"/groups/sxs/hchaudha/spec_runs/26_main_L6_long/h5_files_8000M_Lev6/extracted-PowerDiagnostics\")\n",
    "# PowDiag_path = Path(\"/groups/sxs/hchaudha/spec_runs/del/extracted-PowerDiagnostics\")\n",
    "flat_df = load_power_diagonistics_flat(PowDiag_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_list = [ r'SphereA0' ,r'Bf0I1', r'psi_ps', r'coef']\n",
    "include_list = [  r'TruncationError_', r'kappa']\n",
    "# include_list = [  r'TruncationError_', r'psi']\n",
    "\n",
    "topologies,topdim = [r'Bf0'],0 # First top\n",
    "topologies,topdim = [r'Bf1(S\\d|B2R)'],1 # Second top, S2 for spheres, B2 for filled cylinders\n",
    "topologies,topdim = [r'((Bf1S2|Bf1B2_)|Bf2)'],2 # Thrid top S2 for spheres, B2 radial for filled cylinders\n",
    "\n",
    "exclude_list = [ ]\n",
    "# Example usage with a DataFrame\n",
    "filtered_cols = chain_filter_columns(\n",
    "    cols=flat_df.columns.tolist(),\n",
    "    include_patterns=include_list+topologies,\n",
    "    exclude_patterns=exclude_list\n",
    ")\n",
    "\n",
    "# You can then use these columns to filter your DataFrame\n",
    "filtered_cols = sort_by_coefs_numbers(filtered_cols)\n",
    "filtered_df = flat_df[filtered_cols].copy()\n",
    "filtered_df.loc[:, 't(M)'] = flat_df['t']\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minT = 0\n",
    "# minT = .2\n",
    "# minT = 90\n",
    "# minT = 1200\n",
    "# minT = 3000\n",
    "# minT = 3500\n",
    "minT = 4000\n",
    "minT = 8000\n",
    "\n",
    "maxT = 40000\n",
    "# maxT = 1530\n",
    "# maxT = 3500\n",
    "# maxT = 300\n",
    "# maxT = 800\n",
    "maxT = 8500\n",
    "\n",
    "title = \"\".join(filtered_df.columns.to_list()[0].split(\"_\")[1:])\n",
    "data = limit_by_col_val(minT,maxT,'t(M)',filtered_df)\n",
    "data = data.iloc[::1].dropna(axis=1, how='all')\n",
    "data = data.rename(columns={i:\"\"+i.split(\"_\")[0] for i in data.columns})\n",
    "\n",
    "domain_col_list = chain_filter_columns(\n",
    "    cols=data.columns.tolist(),\n",
    "    include_patterns=[ r'.*'],\n",
    "    # include_patterns=[ r'SphereA0' ,r'Bf0I1', r'psi_ps', r'coef'],\n",
    "    # exclude_patterns=[],\n",
    "    exclude_patterns=[r't\\(M\\)',r'SphereC']\n",
    ")\n",
    "visual_data = data[domain_col_list]\n",
    "# visual_data = np.log10(visual_data)\n",
    "# print(visual_data.columns)\n",
    "# Plot using imshow\n",
    "\n",
    "column_names = list(visual_data.columns)\n",
    "# column_names = [i.split(\" \")[-1] for i in visual_data.columns]\n",
    "column_names = return_sorted_domain_names(column_names)\n",
    "# print(column_names)\n",
    "\n",
    "vmin_log,vmax_log = None,None\n",
    "# vmin_log,vmax_log = -16.060739785509355 , -5.2211449021336955\n",
    "# vmin_log,vmax_log = -10.267013515417048 , -7.6772687168580624\n",
    "# vmin_log,vmax_log = -9 , None\n",
    "if vmin_log is None:\n",
    "  vmin_log = visual_data.min().min()\n",
    "if vmax_log is None:\n",
    "  vmax_log = visual_data.max().max()\n",
    "print(vmin_log,\",\",vmax_log)\n",
    "\n",
    "print(len(domain_col_list))\n",
    "plt.figure(figsize=(15, 10))\n",
    "# plt.figure(figsize=(45, 10))\n",
    "imshow_plot = plt.imshow(\n",
    "    visual_data[column_names], \n",
    "    aspect='auto', \n",
    "    cmap='RdYlGn_r', \n",
    "    origin='lower',interpolation='none',\n",
    "    vmin=vmin_log, \n",
    "    vmax=vmax_log\n",
    ")\n",
    "\n",
    "# Set x-ticks and labels\n",
    "plt.xticks(\n",
    "    ticks=np.arange(len(visual_data.columns)), \n",
    "    labels=[i.split(\" \")[-1] for i in column_names], \n",
    "    rotation=90\n",
    ")\n",
    "\n",
    "ytick_step = 1\n",
    "ytick_step = len(visual_data) // 10  # Show about 10 ticks\n",
    "plt.yticks(\n",
    "    ticks=np.arange(0, len(visual_data), ytick_step), \n",
    "    labels=data['t(M)'][::ytick_step].astype(int)\n",
    ")\n",
    "\n",
    "# Create colorbar\n",
    "colorbar = plt.colorbar(imshow_plot, label=f'{title}')\n",
    "\n",
    "# Determine colorbar ticks that align with the fixed vmin and vmax\n",
    "# tick_vals = np.linspace(vmin_log, vmax_log, num=5)\n",
    "\n",
    "# Set these ticks on the colorbar\n",
    "# colorbar.set_ticks(tick_vals)\n",
    "\n",
    "# Convert ticks back to the original scale for labeling\n",
    "# colorbar.set_ticklabels([f'{10**val:.2e}' for val in tick_vals])\n",
    "\n",
    "plt.ylabel('t(M)')\n",
    "# plt.title(f'{PowDiag_path.parent},   top_dim={topdim}')\n",
    "plt.tight_layout() \n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_list = [ r'SphereA0' ,r'Bf0I1', 'Number']\n",
    "exclude_list = [  r'coef']\n",
    "# Example usage with a DataFrame\n",
    "filtered_cols = chain_filter_columns(\n",
    "    cols=flat_df.columns.tolist(),\n",
    "    include_patterns=include_list,\n",
    "    exclude_patterns=exclude_list\n",
    ")\n",
    "\n",
    "# You can then use these columns to filter your DataFrame\n",
    "filtered_cols = ['t']+sort_by_coefs_numbers(filtered_cols)\n",
    "filtered_df = flat_df[filtered_cols]\n",
    "filtered_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "for col in filtered_df.columns:\n",
    "  if 't' == col:\n",
    "    continue\n",
    "  plt.plot(filtered_df['t'], filtered_df[col],label=col)\n",
    "  # plt.plot(filtered_df['t'], np.log10(np.abs(filtered_df[col])),label=col)\n",
    "plt.legend()\n",
    "plt.xlabel('t')\n",
    "# plt.ylabel('Convergence Factor')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### power in last unfiltered mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_list = [ r'SphereA0' ,r'Bf0I1', r'psi_ps', r'coef']\n",
    "include_list = [r'psi', r'HighestUnfiltered']\n",
    "# include_list = [ r'kappa_ps', r'coef']\n",
    "# include_list = [ r'psi_ps', r'coef']\n",
    "# include_list = [  r'TruncationError_', r'kappa']\n",
    "# include_list = [  r'TruncationError_', r'psi']\n",
    "\n",
    "topologies,topdim = [r'Bf0'],0 # First top\n",
    "topologies,topdim = [r'Bf1(S\\d|B2R)'],1 # Second top, S2 for spheres, B2 for filled cylinders\n",
    "topologies,topdim = [r'((Bf1S2|Bf1B2_)|Bf2)'],2 # Thrid top S2 for spheres, B2 radial for filled cylinders\n",
    "\n",
    "exclude_list = [ ]\n",
    "# Example usage with a DataFrame\n",
    "filtered_cols = chain_filter_columns(\n",
    "    cols=flat_df.columns.tolist(),\n",
    "    include_patterns=include_list+topologies,\n",
    "    exclude_patterns=exclude_list\n",
    ")\n",
    "\n",
    "\n",
    "# You can then use these columns to filter your DataFrame\n",
    "filtered_cols = sort_by_coefs_numbers(filtered_cols)\n",
    "filtered_df = flat_df[filtered_cols].copy()\n",
    "filtered_df.loc[:, 't(M)'] = flat_df['t']\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minT = 0\n",
    "minT = .2\n",
    "# minT = 90\n",
    "# minT = 1200\n",
    "# minT = 3000\n",
    "# minT = 3500\n",
    "# minT = 7500\n",
    "\n",
    "maxT = 40000\n",
    "# maxT = 1530\n",
    "# maxT = 3500\n",
    "# maxT = 300\n",
    "# maxT = 800\n",
    "# maxT = 2\n",
    "\n",
    "psi_or_kappa = None\n",
    "if 'psi_' in filtered_cols[0]:\n",
    "    psi_or_kappa = 'psi'\n",
    "else:\n",
    "    psi_or_kappa = 'kappa'\n",
    "\n",
    "data = filtered_df.copy()\n",
    "colorbar_label = f\"{psi_or_kappa} :  Power in highest unfiltered mode\"\n",
    "\n",
    "data = limit_by_col_val(minT,maxT,'t(M)',data)\n",
    "\n",
    "domain_col_list = chain_filter_columns(\n",
    "    cols=data.columns.tolist(),\n",
    "    include_patterns=[ r'.*',],\n",
    "    # include_patterns=[ r'SphereA0' ,r'Bf0I1', r'psi_ps', r'coef'],\n",
    "    # exclude_patterns=[]\n",
    "    exclude_patterns=[r't\\(M\\)']\n",
    ")\n",
    "\n",
    "visual_data = data[domain_col_list]\n",
    "# visual_data = np.log10(visual_data)\n",
    "# visual_data = visual_data>-14\n",
    "# print(visual_data.columns)\n",
    "# Plot using imshow\n",
    "\n",
    "column_names = list(visual_data.columns)\n",
    "# column_names = [i.split(\" \")[-1] for i in visual_data.columns]\n",
    "column_names = return_sorted_domain_names(column_names)\n",
    "# print(column_names)\n",
    "\n",
    "vmin_log,vmax_log = None,None\n",
    "# vmin_log,vmax_log = -16.060739785509355 , -5.2211449021336955\n",
    "# vmin_log,vmax_log = -10.267013515417048 , -7.6772687168580624\n",
    "# vmin_log,vmax_log = -9 , None\n",
    "if vmin_log is None:\n",
    "  vmin_log = visual_data.min().min()\n",
    "if vmax_log is None:\n",
    "  vmax_log = visual_data.max().max()\n",
    "print(vmin_log,\",\",vmax_log)\n",
    "\n",
    "print(len(domain_col_list))\n",
    "plt.figure(figsize=(15, 10))\n",
    "# plt.figure(figsize=(45, 10))\n",
    "imshow_plot = plt.imshow(\n",
    "    visual_data[column_names], \n",
    "    aspect='auto', \n",
    "    cmap='RdYlGn_r', \n",
    "    origin='lower',interpolation='none',\n",
    "    vmin=vmin_log, \n",
    "    vmax=vmax_log\n",
    ")\n",
    "\n",
    "# Set x-ticks and labels\n",
    "plt.xticks(\n",
    "    ticks=np.arange(len(visual_data.columns)), \n",
    "    labels=[i.split(\"_\")[0] for i in column_names], \n",
    "    rotation=90\n",
    ")\n",
    "\n",
    "ytick_step = 1\n",
    "ytick_step = len(visual_data) // 10  # Show about 10 ticks\n",
    "plt.yticks(\n",
    "    ticks=np.arange(0, len(visual_data), ytick_step), \n",
    "    labels=data['t(M)'][::ytick_step].astype(int)\n",
    ")\n",
    "\n",
    "# Create colorbar\n",
    "colorbar = plt.colorbar(imshow_plot, label=f'{colorbar_label}')\n",
    "\n",
    "# Determine colorbar ticks that align with the fixed vmin and vmax\n",
    "# tick_vals = np.linspace(vmin_log, vmax_log, num=5)\n",
    "\n",
    "# Set these ticks on the colorbar\n",
    "# colorbar.set_ticks(tick_vals)\n",
    "\n",
    "# Convert ticks back to the original scale for labeling\n",
    "# colorbar.set_ticklabels([f'{10**val:.2e}' for val in tick_vals])\n",
    "\n",
    "plt.ylabel('t(M)')\n",
    "include_list = [r'psi', r'HighestUnfiltered']\n",
    "plt.title(f'{PowDiag_path.parent},   top_dim={topdim}')\n",
    "plt.tight_layout() \n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min/Max power in coeffs/modes\n",
    "\n",
    "Use the plotting above if you just want top get the highest non filtered mode. This one loads all the coeffs and allows for more processing (for now only min and max are implemented which is not that useful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "include_list = [ r'SphereA0' ,r'Bf0I1', r'psi_ps', r'coef']\n",
    "# include_list = [ r'kappa_ps', r'coef']\n",
    "include_list = [ r'psi_ps', r'coef']\n",
    "# include_list = [  r'TruncationError_', r'kappa']\n",
    "# include_list = [  r'TruncationError_', r'psi']\n",
    "\n",
    "topologies,topdim = [r'Bf0'],0 # First top\n",
    "topologies,topdim = [r'Bf1(S\\d|B2R)'],1 # Second top, S2 for spheres, B2 for filled cylinders\n",
    "# topologies,topdim = [r'((Bf1S2|Bf1B2_)|Bf2)'],2 # Thrid top S2 for spheres, B2 radial for filled cylinders\n",
    "\n",
    "exclude_list = [ ]\n",
    "# Example usage with a DataFrame\n",
    "filtered_cols = chain_filter_columns(\n",
    "    cols=flat_df.columns.tolist(),\n",
    "    include_patterns=include_list+topologies,\n",
    "    exclude_patterns=exclude_list\n",
    ")\n",
    "\n",
    "\n",
    "# You can then use these columns to filter your DataFrame\n",
    "filtered_cols = sort_by_coefs_numbers(filtered_cols)\n",
    "filtered_df = flat_df[filtered_cols].copy()\n",
    "filtered_df.loc[:, 't(M)'] = flat_df['t']\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minT = 0\n",
    "minT = .2\n",
    "# minT = 90\n",
    "minT = 1200\n",
    "# minT = 3000\n",
    "# minT = 3500\n",
    "# minT = 7500\n",
    "\n",
    "maxT = 40000\n",
    "# maxT = 1530\n",
    "# maxT = 3500\n",
    "# maxT = 300\n",
    "# maxT = 800\n",
    "# maxT = 2\n",
    "\n",
    "min_or_max = 'max'\n",
    "min_or_max = 'min'\n",
    "psi_or_kappa = None\n",
    "if 'psi_' in filtered_cols[0]:\n",
    "    psi_or_kappa = 'psi'\n",
    "else:\n",
    "    psi_or_kappa = 'kappa'\n",
    "\n",
    "data = get_extreme_coef_for_each_domain(filtered_df, min_or_max=min_or_max)\n",
    "colorbar_label = f\"{psi_or_kappa} : {min_or_max} power coeff\"\n",
    "\n",
    "data = limit_by_col_val(minT,maxT,'t(M)',data)\n",
    "\n",
    "domain_col_list = chain_filter_columns(\n",
    "    cols=data.columns.tolist(),\n",
    "    include_patterns=[ r'.*',],\n",
    "    # include_patterns=[ r'SphereA0' ,r'Bf0I1', r'psi_ps', r'coef'],\n",
    "    # exclude_patterns=[]\n",
    "    exclude_patterns=[r't\\(M\\)']\n",
    ")\n",
    "\n",
    "visual_data = data[domain_col_list]\n",
    "visual_data = np.log10(visual_data)\n",
    "# visual_data = visual_data>-14\n",
    "# print(visual_data.columns)\n",
    "# Plot using imshow\n",
    "\n",
    "column_names = list(visual_data.columns)\n",
    "# column_names = [i.split(\" \")[-1] for i in visual_data.columns]\n",
    "column_names = return_sorted_domain_names(column_names)\n",
    "# print(column_names)\n",
    "\n",
    "vmin_log,vmax_log = None,None\n",
    "# vmin_log,vmax_log = -16.060739785509355 , -5.2211449021336955\n",
    "# vmin_log,vmax_log = -10.267013515417048 , -7.6772687168580624\n",
    "# vmin_log,vmax_log = -9 , None\n",
    "if vmin_log is None:\n",
    "  vmin_log = visual_data.min().min()\n",
    "if vmax_log is None:\n",
    "  vmax_log = visual_data.max().max()\n",
    "print(vmin_log,\",\",vmax_log)\n",
    "\n",
    "print(len(domain_col_list))\n",
    "plt.figure(figsize=(15, 10))\n",
    "# plt.figure(figsize=(45, 10))\n",
    "imshow_plot = plt.imshow(\n",
    "    visual_data[column_names], \n",
    "    aspect='auto', \n",
    "    cmap='RdYlGn_r', \n",
    "    origin='lower',interpolation='none',\n",
    "    vmin=vmin_log, \n",
    "    vmax=vmax_log\n",
    ")\n",
    "\n",
    "# Set x-ticks and labels\n",
    "plt.xticks(\n",
    "    ticks=np.arange(len(visual_data.columns)), \n",
    "    labels=[i.split(\" \")[-1] for i in column_names], \n",
    "    rotation=90\n",
    ")\n",
    "\n",
    "ytick_step = 1\n",
    "ytick_step = len(visual_data) // 10  # Show about 10 ticks\n",
    "plt.yticks(\n",
    "    ticks=np.arange(0, len(visual_data), ytick_step), \n",
    "    labels=data['t(M)'][::ytick_step].astype(int)\n",
    ")\n",
    "\n",
    "# Create colorbar\n",
    "colorbar = plt.colorbar(imshow_plot, label=f'{colorbar_label}')\n",
    "\n",
    "# Determine colorbar ticks that align with the fixed vmin and vmax\n",
    "# tick_vals = np.linspace(vmin_log, vmax_log, num=5)\n",
    "\n",
    "# Set these ticks on the colorbar\n",
    "# colorbar.set_ticks(tick_vals)\n",
    "\n",
    "# Convert ticks back to the original scale for labeling\n",
    "# colorbar.set_ticklabels([f'{10**val:.2e}' for val in tick_vals])\n",
    "\n",
    "plt.ylabel('t(M)')\n",
    "plt.title(f'{PowDiag_path.parent},   top_dim={topdim}')\n",
    "plt.tight_layout() \n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The power spectrum at a given time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include_list = [ r'SphereA0' ,r'Bf0I1', r'psi_ps', r'coef']\n",
    "# include_list = [r'psi_ps', r'coef']\n",
    "# include_list = [ r'kappa_ps', r'coef']\n",
    "# include_list = [  r'TruncationError_', r'kappa']\n",
    "include_list = [  r'TruncationError_', r'psi']\n",
    "\n",
    "topologies,topdim = [],'all' # First top\n",
    "# topologies,topdim = [r'Bf0'],0 # First top\n",
    "# topologies,topdim = [r'Bf1(S\\d|B2R)'],1 # Second top, S2 for spheres, B2 for filled cylinders\n",
    "# topologies,topdim = [r'((Bf1S2|Bf1B2_)|Bf2)'],2 # Thrid top S2 for spheres, B2 radial for filled cylinders\n",
    "\n",
    "exclude_list = [ ]\n",
    "# Example usage with a DataFrame\n",
    "filtered_cols = chain_filter_columns(\n",
    "    cols=flat_df.columns.tolist(),\n",
    "    include_patterns=include_list+topologies,\n",
    "    exclude_patterns=exclude_list\n",
    ")\n",
    "\n",
    "# You can then use these columns to filter your DataFrame\n",
    "filtered_cols = sort_by_coefs_numbers(filtered_cols)\n",
    "filtered_df = flat_df[filtered_cols].copy()\n",
    "filtered_df.loc[:, 't(M)'] = flat_df['t']\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = 3500\n",
    "time = 7500\n",
    "time = 0\n",
    "irr_top_num = 0\n",
    "remove_first_n_coeffs = 0\n",
    "# remove_first_n_coeffs = 6\n",
    "time,series = series_closest_to_time(time,filtered_df)\n",
    "data = convert_series_to_coeff_df(series,irr_top_num)\n",
    "\n",
    "psi_or_kappa = None\n",
    "if 'psi_' in filtered_cols[0]:\n",
    "    psi_or_kappa = 'psi'\n",
    "else:\n",
    "    psi_or_kappa = 'kappa'\n",
    "\n",
    "colorbar_label = f\"{psi_or_kappa} : power coeff\"\n",
    "\n",
    "\n",
    "# domain_col_list = chain_filter_columns(\n",
    "#     cols=data.columns.tolist(),\n",
    "#     include_patterns=[ r'.*',],\n",
    "#     # include_patterns=[ r'SphereA0' ,r'Bf0I1', r'psi_ps', r'coef'],\n",
    "#     # exclude_patterns=[]\n",
    "#     exclude_patterns=[r't\\(M\\)']\n",
    "# )\n",
    "\n",
    "visual_data = np.log10(data)\n",
    "\n",
    "column_names = list(visual_data.columns)\n",
    "column_names = return_sorted_domain_names(column_names)\n",
    "visual_data = visual_data[column_names].iloc[remove_first_n_coeffs:,:]\n",
    "\n",
    "vmin_log,vmax_log = None,None\n",
    "if vmin_log is None:\n",
    "  vmin_log = visual_data.min().min()\n",
    "if vmax_log is None:\n",
    "  vmax_log = visual_data.max().max()\n",
    "print(vmin_log,\",\",vmax_log)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "# plt.figure(figsize=(45, 10))\n",
    "imshow_plot = plt.imshow(\n",
    "    visual_data, \n",
    "    aspect='auto', \n",
    "    cmap='RdYlGn_r', \n",
    "    origin='lower',interpolation='none',\n",
    "    vmin=vmin_log, \n",
    "    vmax=vmax_log\n",
    ")\n",
    "\n",
    "# Set x-ticks and labels\n",
    "plt.xticks(\n",
    "    ticks=np.arange(len(visual_data.columns)), \n",
    "    labels=[i.split(\" \")[-1] for i in column_names], \n",
    "    rotation=90\n",
    ")\n",
    "\n",
    "plt.yticks(\n",
    "    ticks=np.arange(0, len(visual_data), 1), \n",
    "    labels=np.arange(remove_first_n_coeffs, remove_first_n_coeffs+ len(visual_data), 1), \n",
    ")\n",
    "\n",
    "# Create colorbar\n",
    "colorbar = plt.colorbar(imshow_plot, label=f'{colorbar_label}')\n",
    "plt.ylabel('Power in Coeffs')\n",
    "plt.title(f'{PowDiag_path.parent}\\n Time={time:.2f} , {irr_top_num=}')\n",
    "plt.tight_layout() \n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = 3500\n",
    "time = 7500\n",
    "irr_top_num = 2\n",
    "remove_first_n_coeffs = 0\n",
    "remove_first_n_coeffs = 6\n",
    "time,series = series_closest_to_time(time,filtered_df)\n",
    "data = convert_series_to_coeff_df(series,irr_top_num)\n",
    "\n",
    "psi_or_kappa = None\n",
    "if 'psi_' in filtered_cols[0]:\n",
    "    psi_or_kappa = 'psi'\n",
    "else:\n",
    "    psi_or_kappa = 'kappa'\n",
    "\n",
    "colorbar_label = f\"{psi_or_kappa} : power coeff\"\n",
    "\n",
    "\n",
    "# domain_col_list = chain_filter_columns(\n",
    "#     cols=data.columns.tolist(),\n",
    "#     include_patterns=[ r'.*',],\n",
    "#     # include_patterns=[ r'SphereA0' ,r'Bf0I1', r'psi_ps', r'coef'],\n",
    "#     # exclude_patterns=[]\n",
    "#     exclude_patterns=[r't\\(M\\)']\n",
    "# )\n",
    "\n",
    "visual_data = np.log10(data)\n",
    "\n",
    "column_names = list(visual_data.columns)\n",
    "column_names = return_sorted_domain_names(column_names)\n",
    "visual_data = visual_data[column_names].iloc[remove_first_n_coeffs:,:]\n",
    "\n",
    "vmin_log,vmax_log = None,None\n",
    "if vmin_log is None:\n",
    "  vmin_log = visual_data.min().min()\n",
    "if vmax_log is None:\n",
    "  vmax_log = visual_data.max().max()\n",
    "print(vmin_log,\",\",vmax_log)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "# plt.figure(figsize=(45, 10))\n",
    "imshow_plot = plt.imshow(\n",
    "    visual_data, \n",
    "    aspect='auto', \n",
    "    cmap='RdYlGn_r', \n",
    "    origin='lower',interpolation='none',\n",
    "    vmin=vmin_log, \n",
    "    vmax=vmax_log\n",
    ")\n",
    "\n",
    "# Add text annotations to each cell\n",
    "for i in range(visual_data.shape[0]):\n",
    "    for j in range(visual_data.shape[1]):\n",
    "        # Choose text color based on cell value for better visibility\n",
    "        value = visual_data.iloc[i, j]\n",
    "        if np.isnan(value):\n",
    "           continue\n",
    "        # color = 'white' if value > (vmin_log + vmax_log)/2 else 'black'\n",
    "        color = 'black'\n",
    "        # Add text annotation\n",
    "        plt.text(j, i, f'{value:.2f}',  # Scientific notation\n",
    "                ha='center', \n",
    "                va='center', \n",
    "                color=color,rotation=90,\n",
    "                fontsize=8)  # Adjust fontsize as needed\n",
    "\n",
    "# Set x-ticks and labels\n",
    "plt.xticks(\n",
    "    ticks=np.arange(len(visual_data.columns)), \n",
    "    labels=[i.split(\" \")[-1] for i in column_names], \n",
    "    rotation=90\n",
    ")\n",
    "\n",
    "plt.yticks(\n",
    "    ticks=np.arange(0, len(visual_data), 1), \n",
    "    labels=np.arange(remove_first_n_coeffs, remove_first_n_coeffs+ len(visual_data), 1), \n",
    ")\n",
    "\n",
    "# Create colorbar\n",
    "colorbar = plt.colorbar(imshow_plot, label=f'{colorbar_label}')\n",
    "plt.ylabel('Power in Coeffs')\n",
    "plt.title(f'{PowDiag_path.parent}\\n Time={time:.2f} , {irr_top_num=}')\n",
    "plt.tight_layout() \n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### all on a single plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time = 7500\n",
    "power_cutoff = -24 # remove all coeffs smaller than this. These are usually the filtered coeffs.\n",
    "remove_first_n_coeffs = (0,0,0)\n",
    "remove_first_n_coeffs = (8,8,8)\n",
    "time,series = series_closest_to_time(time,filtered_df)\n",
    "\n",
    "psi_or_kappa = None\n",
    "if 'psi_' in filtered_cols[0]:\n",
    "    psi_or_kappa = 'psi'\n",
    "else:\n",
    "    psi_or_kappa = 'kappa'\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1, figsize=(15, 15), constrained_layout=True)\n",
    "\n",
    "for i, ax in zip(range(3),axes):\n",
    "\n",
    "    data = convert_series_to_coeff_df(series,i)\n",
    "    colorbar_label = f\"{psi_or_kappa}(Extent {i}) : power coeff\"\n",
    "\n",
    "    visual_data = np.log10(data)\n",
    "\n",
    "    visual_data[visual_data<power_cutoff] = 1e-20\n",
    "    # visual_data = visual_data[visual_data>power_cutoff]\n",
    "\n",
    "    column_names = list(visual_data.columns)\n",
    "    column_names = return_sorted_domain_names(column_names)\n",
    "    visual_data = visual_data[column_names].iloc[remove_first_n_coeffs[i]:,:]\n",
    "\n",
    "    vmin_log,vmax_log = None,None\n",
    "    if vmin_log is None:\n",
    "        vmin_log = visual_data.min().min()\n",
    "    if vmax_log is None:\n",
    "        vmax_log = visual_data.max().max()\n",
    "    print(vmin_log,\",\",vmax_log)\n",
    "\n",
    "    imshow_plot = ax.imshow(\n",
    "        visual_data, \n",
    "        aspect='auto', \n",
    "        cmap='RdYlGn_r', \n",
    "        origin='lower',interpolation='none',\n",
    "        vmin=vmin_log, \n",
    "        vmax=vmax_log\n",
    "    )\n",
    "\n",
    "    if i == 2:\n",
    "        # Set x-ticks and labels\n",
    "        ax.set_xticks(\n",
    "            ticks=np.arange(len(visual_data.columns)), \n",
    "            labels=[i.split(\" \")[-1] for i in column_names], \n",
    "            rotation=90\n",
    "        )\n",
    "\n",
    "    ax.set_yticks(\n",
    "        ticks=np.arange(0, len(visual_data), 1), \n",
    "        labels=np.arange(remove_first_n_coeffs[i], remove_first_n_coeffs[i]+ len(visual_data), 1), \n",
    "    )\n",
    "\n",
    "    # ax.set_title(f\"{column_name[i]}, {filter_suffix[-1]}\")\n",
    "\n",
    "    # Create colorbar\n",
    "    # fig.colorbar(imshow_plot, label=f'{colorbar_label}',ax=ax)\n",
    "    plt.colorbar(imshow_plot, label=f'{colorbar_label}',ax=ax)\n",
    "    ax.set_ylabel('Power in Coeffs')\n",
    "    ax.grid(False)\n",
    " \n",
    "plt.suptitle(f'{PowDiag_path.parent}\\n Time={time:.2f}, {power_cutoff=}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### df dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PowDiag_path = Path(\"/groups/sxs/hchaudha/spec_runs/16_set1_L3/h5_files_Lev3/extracted-PowerDiagnostics\")\n",
    "dict_df = load_power_diagonistics(PowDiag_path)\n",
    "dict_df.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter subdomains\n",
    "# include_list = [ r'SphereA[2-9]']\n",
    "include_list = [ ]\n",
    "exclude_list = [  r'Cylinder',r'SphereC']\n",
    "# Example usage with a DataFrame\n",
    "filtered_cols = chain_filter_columns(\n",
    "    cols=dict_df.keys(),\n",
    "    include_patterns=include_list,\n",
    "    exclude_patterns=exclude_list\n",
    ")\n",
    "filtered_dict = {key:dict_df[key] for key in filtered_cols}\n",
    "top_set = set()\n",
    "for k,i in filtered_dict.items():\n",
    "  top_set.update(i.keys())\n",
    "print(filtered_dict.keys())\n",
    "print(top_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INCOMPLETE!!!!!\n",
    "# filter subdomains\n",
    "include_list = [ 'Bf0I1']\n",
    "exclude_list = [ ]\n",
    "# Example usage with a DataFrame\n",
    "filtered_cols = chain_filter_columns(\n",
    "    cols=dict_df.keys(),\n",
    "    include_patterns=include_list,\n",
    "    exclude_patterns=exclude_list\n",
    ")\n",
    "filtered_dict = {key:dict_df[key] for key in filtered_cols}\n",
    "filtered_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exp damping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exp_damping(p,a,N):\n",
    "  return np.exp(-a*(np.arange(N)/(N-1))**(2*p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1-exp_damping(36,36,15), 1-exp_damping(30,36,15), 1-exp_damping(28,36,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(1-exp_damping(28,36,15),label='28,36', marker='o')\n",
    "plt.plot(1-exp_damping(30,36,15),label='30,36', marker='o')\n",
    "plt.plot(1-exp_damping(32,36,15),label='32,36', marker='o')\n",
    "plt.plot(1-exp_damping(36,36,15),label='36,36', marker='o')\n",
    "plt.yscale('log')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile\n",
    "profiler = cProfile.Profile()\n",
    "profiler.enable()\n",
    "profiler.disable()\n",
    "\n",
    "# Print sorted results\n",
    "profiler.print_stats(sort='cumulative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.escape(\"\"\"      BjorhusCharSpeedCutoff = -1.e-10;\n",
    "      InternalBdryMethod     = MultiPenalty;\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sxs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
