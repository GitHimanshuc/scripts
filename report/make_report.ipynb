{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numba import njit\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams[\"figure.figsize\"] = (10,8)\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dat_file(file_name):\n",
    "  cols_names = []\n",
    "\n",
    "  temp_file = \"./temp.csv\"\n",
    "  with open(file_name,'r') as f:\n",
    "    with open(temp_file,'w') as w:\n",
    "      lines = f.readlines()\n",
    "      for line in lines:\n",
    "        if(line[0] != '#'): # This is data\n",
    "          w.writelines(line)\n",
    "        if(line[0:3] == '# [' or line[0:4] == '#  ['): # Some dat files have comments on the top\n",
    "          cols_names.append(line.split('=')[-1][1:-1].strip())\n",
    "\n",
    "\n",
    "  return pd.read_csv(temp_file,delim_whitespace=True,names=cols_names)\n",
    "\n",
    "def plot_and_save(data,x_arr,y_arr,file_location):\n",
    "  for x_axis,y_axis in zip(x_arr,y_arr):\n",
    "    plt.plot(data[x_axis],data[y_axis])\n",
    "    plt.xlabel(x_axis)\n",
    "    plt.ylabel(y_axis)\n",
    "    title = file_location.split(\"/\")[-1][:-4]+\" \\\"\"+y_axis+\"\\\" vs \\\"\"+x_axis+\"\\\"\"\n",
    "    plt.title(title)\n",
    "\n",
    "    plt.savefig(file_location[:-4]+\"_\\\"\"+y_axis+\"\\\"_vs_\\\"\"+x_axis+\"\\\"\")\n",
    "\n",
    "\n",
    "\n",
    "def read_dat_file_across_AA(file_pattern):\n",
    "\n",
    "  path_pattern = file_pattern\n",
    "  path_collection = []\n",
    "\n",
    "\n",
    "  for folder_name in glob.iglob(path_pattern, recursive=True):\n",
    "      if os.path.isdir(folder_name) or os.path.isfile(folder_name):\n",
    "          path_collection.append(folder_name)\n",
    "          print(folder_name)\n",
    "\n",
    "\n",
    "  read_data_collection = []\n",
    "  for path in path_collection:\n",
    "    read_data_collection.append(read_dat_file(path))\n",
    "\n",
    "  data = pd.concat(read_data_collection)\n",
    "  print(data.columns)\n",
    "  return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_EV_folder_path = \"/panfs/ds09/sxs/himanshu/gauge_stuff/gauge_driver_runs/runs/gauge_driver_kerr_target_50_50_0_16_16_01/Ev\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': 'DiagCutXCorrection.dat',\n",
       " 'file_path': '/panfs/ds09/sxs/himanshu/gauge_stuff/gauge_driver_runs/runs/gauge_driver_kerr_target_50_50_0_16_16_01/Ev/Lev1_AA/Run/DiagCutXCorrection.dat',\n",
       " 'columns': ['time',\n",
       "  'state',\n",
       "  'RelativeCutXDistanceA',\n",
       "  'RelativeCutXDistanceB',\n",
       "  'MappedCrossingXA',\n",
       "  'MappedCrossingXB',\n",
       "  'TargetCutX',\n",
       "  'TargetCutXFunc',\n",
       "  'MappedCutX',\n",
       "  'GridCutX',\n",
       "  'CutXCrossingTimeA',\n",
       "  'CutXCrossingTimeB',\n",
       "  'ExcCrossingTimeAB',\n",
       "  'SuggestedDampingTime',\n",
       "  'Q']}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"./column_data_for_dat_files.json\") as report_data:\n",
    "  data = json.load(report_data)\n",
    "\n",
    "data['columns_of_dat_files'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save all columns and data files paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DiagCutXCorrection.dat\n",
      "DiagAhSpeedA.dat\n",
      "DiagAhSpeedB.dat\n",
      "DiagInclinationAngle.dat\n",
      "MinimumGridSpacing.dat\n",
      "GrAdjustMaxTstepToDampingTimes.dat\n",
      "OdeErrorRelative.dat\n",
      "TStepperDiag.dat\n",
      "GrAdjustSubChunksToDampingTimes.dat\n",
      "MemoryInfo.dat\n",
      "TimeInfo.dat\n",
      "FailedTStepperDiag.dat\n",
      "SmoothCoordSepHorizon.dat\n",
      "HorizonSepMeasures.dat\n",
      "MinCharSpeedAhA.dat\n",
      "MinCharSpeedAhB.dat\n",
      "RescaledRadAhA.dat\n",
      "RescaledRadAhB.dat\n",
      "AhA.dat\n",
      "Trajectory_AhA.dat\n",
      "AhACoefs.dat\n",
      "AhB.dat\n",
      "Trajectory_AhB.dat\n",
      "AhBCoefs.dat\n",
      "CharSpeeds_Min_SliceLFF.SphereA0.dat\n",
      "CharSpeeds_Min_SliceUFF.SphereC34.dat\n",
      "CharSpeeds_Min_SliceLFF.SphereB0.dat\n",
      "CharSpeeds_Max_SliceLFF.SphereA0.dat\n",
      "CharSpeeds_Max_SliceUFF.SphereC34.dat\n",
      "CharSpeeds_Max_SliceLFF.SphereB0.dat\n",
      "GhCe_Norms.dat\n",
      "GhCeExt_Norms.dat\n",
      "NormalizedGhCe_Norms.dat\n",
      "GhCe.dat\n",
      "GhCeExt.dat\n",
      "GhCeExt_L2.dat\n",
      "GhCe_VolL2.dat\n",
      "GhCe_L2.dat\n",
      "GhCe_Linf.dat\n",
      "NormalizedGhCe_Linf.dat\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lev_golb=\"/panfs/ds09/sxs/himanshu/gauge_stuff/gauge_driver_runs/runs/gauge_driver_kerr_target_50_50_0_16_16_01/Ev/Lev1_AA\"\n",
    "dat_files_glob=lev_golb+\"/Run/**/**.dat\"\n",
    "path_pattern = dat_files_glob\n",
    "\n",
    "path_collection = []\n",
    "for folder_name in glob.iglob(path_pattern, recursive=True):\n",
    "    if os.path.isdir(folder_name) or os.path.isfile(folder_name):\n",
    "        path_collection.append(folder_name)\n",
    "        print(folder_name.split(\"/\")[-1])\n",
    "\n",
    "\n",
    "column_data_for_dat_files = {\n",
    "  'columns_of_dat_files' : [\n",
    "  ] \n",
    "}\n",
    "\n",
    "for file_path in path_collection:\n",
    "  file_name = file_path.split(\"/\")[-1]\n",
    "  columns_list =  list(read_dat_file(file_path).columns)\n",
    "  column_data_for_dat_files['columns_of_dat_files'].append({\n",
    "    'file_name': file_name,\n",
    "    'file_path': file_path,\n",
    "    'columns': columns_list\n",
    "  })\n",
    "\n",
    "\n",
    "with open('./column_data_for_dat_files.json', 'w') as outfile:\n",
    "  json.dump(column_data_for_dat_files, outfile, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('sxs')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "009adc1c8ee1f76b2251d0bb13ed6e10d4fef5bd0a6f7d195d9f2892e5880fe6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
