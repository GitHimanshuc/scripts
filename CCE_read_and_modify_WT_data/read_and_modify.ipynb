{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21516cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "import shutil\n",
    "import subprocess\n",
    "import sys\n",
    "from functools import partial\n",
    "\n",
    "from itertools import cycle\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict\n",
    "\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import scri\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import curve_fit\n",
    "from spherical_functions import LM_index as lm\n",
    "\n",
    "\n",
    "base_path = Path(\"/resnick/groups/sxs/hchaudha/spec_runs/CCE_stuff/noise_in_WT_data/runs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e4880f",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e61216f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Lm_info_from_col_name(col_name):\n",
    "    real = \"Re\" in col_name\n",
    "    L = int(col_name.split(\"(\")[1].split(\",\")[0].strip())\n",
    "    m = int(col_name.split(\"(\")[1].split(\",\")[1][:-1].strip())\n",
    "    return L,m,real\n",
    "\n",
    "def set_higher_L_modes_to_zero(\n",
    "    input_file, output_file, min_L_to_keep=1e10\n",
    "):\n",
    "    shutil.copy(input_file, output_file)\n",
    "    with h5py.File(output_file, \"r+\") as outfile:\n",
    "        for key, data in outfile.items():\n",
    "            if \"Version\" in key:\n",
    "                continue\n",
    "            if isinstance(data, h5py.Dataset):\n",
    "                print(f\"----Modifying {key}\")\n",
    "                legend = data.attrs['Legend']\n",
    "                for i,col_name in enumerate(list(legend)):\n",
    "                    if col_name == 'time':\n",
    "                        continue\n",
    "                    L, m, real = get_Lm_info_from_col_name(col_name)\n",
    "                    if L > min_L_to_keep:\n",
    "                        data[:, i] = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a25b86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_uniform_noise(\n",
    "    input_file, output_file, noise_amp=1e-16, add_relative_noise=False, min_t = -10.0\n",
    "):\n",
    "    shutil.copy(input_file, output_file)\n",
    "    with h5py.File(output_file, \"r+\") as outfile:\n",
    "        for key, data in outfile.items():\n",
    "            if \"Version\" in key:\n",
    "                continue\n",
    "            if isinstance(data, h5py.Dataset):\n",
    "                print(f\"----Modifying {key}\")\n",
    "                t = data[:, 0]\n",
    "                #find the index of the first time greater than min_t\n",
    "                first_index = np.searchsorted(t, min_t)\n",
    "                if add_relative_noise:\n",
    "                    data[first_index:, 1:] = data[first_index:, 1:] * (\n",
    "                        1\n",
    "                        + noise_amp\n",
    "                        * np.random.uniform(low=-1, high=1, size=data[first_index:, 1:].shape)\n",
    "                    )\n",
    "                else:\n",
    "                    data[first_index:, 1:] = data[first_index:, 1:] + noise_amp * (\n",
    "                        np.random.uniform(low=-1, high=1, size=data[first_index:, 1:].shape)\n",
    "                    )\n",
    "\n",
    "\n",
    "def remove_values_below_tolerance(\n",
    "    input_file, output_file, tolerance=1e-16, use_relative_tolerance=False\n",
    "):\n",
    "    shutil.copy(input_file, output_file)\n",
    "    with h5py.File(output_file, \"r+\") as outfile:\n",
    "        for key, data in outfile.items():\n",
    "            if \"Version\" in key:\n",
    "                continue\n",
    "            if isinstance(data, h5py.Dataset):\n",
    "                print(f\"----Modifying {key}\")\n",
    "                data_no_t = data[:, 1:]\n",
    "\n",
    "                if use_relative_tolerance:\n",
    "                    max_per_row = np.max(np.abs(data_no_t), axis=1)\n",
    "                    thresh = (tolerance * max_per_row)[:, np.newaxis]\n",
    "                else:\n",
    "                    # absolute threshold\n",
    "                    thresh = tolerance\n",
    "                cleaned = np.where(np.abs(data_no_t) < thresh, 0, data_no_t)\n",
    "                data[:, 1:] = cleaned\n",
    "\n",
    "def just_link(input_file, output_file):\n",
    "    os.symlink(input_file, output_file)\n",
    "\n",
    "def get_diff_WT_data(file1,file2):\n",
    "    with h5py.File(file1, \"r\") as f1, h5py.File(file2, \"r\") as f2:\n",
    "        vars = ['Beta.dat', 'DrJ.dat', 'DuR.dat', 'H.dat', 'J.dat', 'Q.dat', 'R.dat', 'U.dat', 'W.dat']\n",
    "        diff_data = {}\n",
    "        for key in vars:\n",
    "            print(f\"----Taking diff: {key}\")\n",
    "            diff_data[key] = np.array(f2[key])\n",
    "            diff_data[key] = diff_data[key][:,1:] - f1[key][:,1:]\n",
    "        return diff_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662b176f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_config_file(\n",
    "    BoundaryDataPath: Path,\n",
    "    InputSavePath: Path = None,\n",
    "    which_ID: str = \"ConformalFactor\",\n",
    "    options_dict_user={},\n",
    "    observer_vol_data = False,\n",
    ") -> Path:\n",
    "    options_dict = {\n",
    "        \"Cce.Evolution.TimeStepper.AdamsBashforth.Order\": 3,\n",
    "        \"Cce.Evolution.StepChoosers.Constant\": 0.1,\n",
    "        \"Cce.Evolution.StepChoosers.ErrorControl(SwshVars).AbsoluteTolerance\": 1e-9,\n",
    "        \"Cce.Evolution.StepChoosers.ErrorControl(SwshVars).RelativeTolerance\": 1e-7,\n",
    "        \"Cce.Evolution.StepChoosers.ErrorControl(CoordVars).AbsoluteTolerance\": 1e-9,\n",
    "        \"Cce.Evolution.StepChoosers.ErrorControl(CoordVars).RelativeTolerance\": 1e-8,\n",
    "        \"Cce.LMax\": 20,\n",
    "        \"Cce.NumberOfRadialPoints\": 15,\n",
    "        \"Cce.ObservationLMax\": 8,\n",
    "        \"Cce.H5Interpolator.BarycentricRationalSpanInterpolator.MinOrder\": 10,\n",
    "        \"Cce.H5Interpolator.BarycentricRationalSpanInterpolator.MaxOrder\": 10,\n",
    "        \"Cce.H5LookaheadTimes\": 10000,\n",
    "        \"Cce.Filtering.RadialFilterHalfPower\": 64,\n",
    "        \"Cce.Filtering.RadialFilterAlpha\": 35.0,\n",
    "        \"Cce.Filtering.FilterLMax\": 18,\n",
    "        \"Cce.ScriInterpOrder\": 5,\n",
    "        \"Cce.ScriOutputDensity\": 1,\n",
    "    }\n",
    "\n",
    "    for key in options_dict_user.keys():\n",
    "        if key not in options_dict:\n",
    "            raise ValueError(f\"Key {key} is not a valid option.\")\n",
    "        else:\n",
    "            options_dict[key] = options_dict_user[key]\n",
    "\n",
    "    CCE_ID_data = \"\"\n",
    "    match which_ID:\n",
    "        case \"ConformalFactor\":\n",
    "            CCE_ID_data = \"\"\"\n",
    "    ConformalFactor:\n",
    "      AngularCoordTolerance: 1e-13\n",
    "      MaxIterations: 1000 # Do extra iterations in case we improve.\n",
    "      RequireConvergence: False # Often don't converge to 1e-13, but that's fine\n",
    "      OptimizeL0Mode: True\n",
    "      UseBetaIntegralEstimate: False\n",
    "      ConformalFactorIterationHeuristic: SpinWeight1CoordPerturbation\n",
    "      UseInputModes: False\n",
    "      InputModes: []\n",
    "\"\"\"\n",
    "        case \"InverseCubic\":\n",
    "            CCE_ID_data = \"\"\"\n",
    "    InverseCubic:\n",
    "\"\"\"\n",
    "        case \"ZeroNonSmooth\":\n",
    "            CCE_ID_data = \"\"\"\n",
    "    ZeroNonSmooth:\n",
    "      AngularCoordTolerance: 1e-13\n",
    "      MaxIterations: 1000\n",
    "      RequireConvergence: False\n",
    "\"\"\"\n",
    "        case \"NoIncomingRadiation\":\n",
    "            CCE_ID_data = \"\"\"\n",
    "    NoIncomingRadiation:\n",
    "      AngularCoordTolerance: 1e-13\n",
    "      MaxIterations: 1000\n",
    "      RequireConvergence: False\n",
    "\"\"\"\n",
    "    if InputSavePath is None:\n",
    "        InputSavePath = BoundaryDataPath.parent / \"cce.yaml\"\n",
    "    assert InputSavePath.parent.exists()\n",
    "\n",
    "    config_file = f\"\"\"\n",
    "# Distributed under the MIT License.\n",
    "# See LICENSE.txt for details.\n",
    "\n",
    "# This block is used by testing and the SpECTRE command line interface.\n",
    "Executable: CharacteristicExtract\n",
    "Testing:\n",
    "  Check: parse\n",
    "  Priority: High\n",
    "\n",
    "---\n",
    "Evolution:\n",
    "  InitialTimeStep: 0.25\n",
    "  MinimumTimeStep: 1e-7\n",
    "  InitialSlabSize: 10.0\n",
    "\n",
    "ResourceInfo:\n",
    "  AvoidGlobalProc0: false\n",
    "  Singletons: Auto\n",
    "\n",
    "Observers:\n",
    "  VolumeFileName: \"vol_{str(InputSavePath.stem)}\"\n",
    "  ReductionFileName: \"red_{str(InputSavePath.stem)}\"\n",
    "\n",
    "EventsAndTriggersAtSlabs:\n",
    "  # Write the CCE time step every Slab. A Slab is a fixed length of simulation\n",
    "  # time and is not influenced by the dynamically adjusted step size.\n",
    "  - Trigger:\n",
    "      Slabs:\n",
    "        EvenlySpaced:\n",
    "          Offset: 0\n",
    "          Interval: 1\n",
    "    Events:\n",
    "      - ObserveTimeStep:\n",
    "          # The output is written into the \"ReductionFileName\" HDF5 file under\n",
    "          # \"/SubfileName.dat\"\n",
    "          SubfileName: CceTimeStep\n",
    "          PrintTimeToTerminal: true\n",
    "    #   - ObserveFields:\n",
    "    #       VariablesToObserve:\n",
    "    #         - BondiBeta\n",
    "    #         - Du(J)\n",
    "    #         - DuRDividedByR\n",
    "    #         - Dy(BondiBeta)\n",
    "    #         - Dy(Du(J))\n",
    "    #         - Dy(Dy(BondiBeta))\n",
    "    #         - Dy(Dy(Du(J)))\n",
    "    #         - Dy(Dy(J))\n",
    "    #         - Dy(Dy(Q))\n",
    "    #         - Dy(Dy(U))\n",
    "    #         - Dy(Dy(W))\n",
    "    #         - Dy(H)\n",
    "    #         - Dy(J)\n",
    "    #         - Dy(Q)\n",
    "    #         - Dy(U)\n",
    "    #         - Dy(W)\n",
    "    #         - EthRDividedByR\n",
    "    #         - H\n",
    "    #         - InertialRetardedTime\n",
    "    #         - J\n",
    "    #         - OneMinusY\n",
    "    #         - Psi0\n",
    "    #         - Psi1\n",
    "    #         - Q\n",
    "    #         - R\n",
    "    #         - U\n",
    "    #         - W\n",
    "\n",
    "EventsAndTriggersAtSteps:\n",
    "\n",
    "Cce:\n",
    "  Evolution:\n",
    "    TimeStepper:\n",
    "      AdamsBashforth:\n",
    "        Order: {options_dict['Cce.Evolution.TimeStepper.AdamsBashforth.Order']} # Going to higher order doesn't seem necessary for CCE\n",
    "    StepChoosers:\n",
    "      - Constant: {options_dict['Cce.Evolution.StepChoosers.Constant']} # Don't take steps bigger than 0.1M\n",
    "      - LimitIncrease:\n",
    "          Factor: 2\n",
    "      - ErrorControl(SwshVars):\n",
    "          AbsoluteTolerance: {options_dict['Cce.Evolution.StepChoosers.ErrorControl(SwshVars).AbsoluteTolerance']}\n",
    "          RelativeTolerance: {options_dict['Cce.Evolution.StepChoosers.ErrorControl(SwshVars).RelativeTolerance']}\n",
    "          # These factors control how much the time step is changed at once.\n",
    "          MaxFactor: 2\n",
    "          MinFactor: 0.25\n",
    "          # How close to the \"perfect\" time step we take. Since the \"perfect\"\n",
    "          # value assumes a linear system, we need some safety factor since our\n",
    "          # system is nonlinear, and also so that we reduce how often we retake\n",
    "          # time steps.\n",
    "          SafetyFactor: 0.9\n",
    "      - ErrorControl(CoordVars):\n",
    "          AbsoluteTolerance: {options_dict['Cce.Evolution.StepChoosers.ErrorControl(CoordVars).AbsoluteTolerance']}\n",
    "          RelativeTolerance: {options_dict['Cce.Evolution.StepChoosers.ErrorControl(CoordVars).RelativeTolerance']}\n",
    "          # These factors control how much the time step is changed at once.\n",
    "          MaxFactor: 2\n",
    "          MinFactor: 0.25\n",
    "          # How close to the \"perfect\" time step we take. Since the \"perfect\"\n",
    "          # value assumes a linear system, we need some safety factor since our\n",
    "          # system is nonlinear, and also so that we reduce how often we retake\n",
    "          # time steps.\n",
    "          SafetyFactor: 0.9\n",
    "\n",
    "  # The number of angular modes used by the CCE evolution. This must be larger\n",
    "  # than ObservationLMax. We always use all of the m modes for the LMax since\n",
    "  # using fewer m modes causes aliasing-driven instabilities.\n",
    "  LMax: {options_dict['Cce.LMax']}\n",
    "  # Probably don't need more than 15 radial grid points, but could increase\n",
    "  # up to ~20\n",
    "  NumberOfRadialPoints: {options_dict['Cce.NumberOfRadialPoints']}\n",
    "  # The maximum ell we use for writing waveform output. While CCE can dump\n",
    "  # more, you should be cautious with higher modes since mode mixing, truncation\n",
    "  # error, and systematic numerical effects can have significant contamination\n",
    "  # in these modes.\n",
    "  ObservationLMax: {options_dict['Cce.ObservationLMax']}\n",
    "\n",
    "  InitializeJ:\n",
    "    # To see what other J-initialization procedures are available, comment\n",
    "    # out this group of options and do, e.g. \"Blah:\" The code will print\n",
    "    # an error message with the available options and a help string.\n",
    "    # More details can be found at spectre-code.org.\n",
    "{CCE_ID_data}\n",
    "\n",
    "  StartTime: Auto\n",
    "  EndTime: Auto\n",
    "  ExtractionRadius: Auto\n",
    "\n",
    "  BoundaryDataFilename: {BoundaryDataPath.name}\n",
    "  H5Interpolator:\n",
    "    BarycentricRationalSpanInterpolator:\n",
    "      MinOrder: {options_dict['Cce.H5Interpolator.BarycentricRationalSpanInterpolator.MinOrder']}\n",
    "      MaxOrder: {options_dict['Cce.H5Interpolator.BarycentricRationalSpanInterpolator.MaxOrder']}\n",
    "\n",
    "  H5LookaheadTimes: {options_dict['Cce.H5LookaheadTimes']}\n",
    "\n",
    "  Filtering:\n",
    "    RadialFilterHalfPower: {options_dict['Cce.Filtering.RadialFilterHalfPower']}\n",
    "    RadialFilterAlpha: {options_dict['Cce.Filtering.RadialFilterAlpha']}\n",
    "    FilterLMax: {options_dict['Cce.Filtering.FilterLMax']}\n",
    "\n",
    "  ScriInterpOrder: {options_dict['Cce.ScriInterpOrder']}\n",
    "  ScriOutputDensity: {options_dict['Cce.ScriOutputDensity']}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "    with InputSavePath.open(\"w\") as f:\n",
    "        f.writelines(config_file)\n",
    "\n",
    "    return InputSavePath\n",
    "\n",
    "\n",
    "def make_submit_file(\n",
    "    save_folder_path: Path,\n",
    "    cce_input_file_path: Path,\n",
    "    CCE_Executable_path: Path,\n",
    "    write_scripts_only=False,\n",
    "):\n",
    "    submit_script = f\"\"\"#!/bin/bash -\n",
    "#SBATCH -J CCE_{save_folder_path.stem}             # Job Name\n",
    "#SBATCH -o CCE.stdout                 # Output file name\n",
    "#SBATCH -e CCE.stderr                 # Error file name\n",
    "#SBATCH -n 2                          # Number of cores\n",
    "#SBATCH -p expansion                  # Queue name\n",
    "#SBATCH --ntasks-per-node 2           # number of MPI ranks per node\n",
    "#SBATCH -t 24:0:00   # Run time\n",
    "#SBATCH -A sxs                # Account name\n",
    "#SBATCH --no-requeue\n",
    "#SBATCH --reservation=sxs_standing\n",
    "\n",
    "# Spectre related stuff to load JeMalloc\n",
    "export SPECTRE_HOME=/central/groups/sxs/hchaudha/spectre\n",
    ". $SPECTRE_HOME/support/Environments/caltech_hpc_gcc.sh\n",
    "spectre_load_modules\n",
    "\n",
    "# Go to the correct folder with the boundary data\n",
    "cd {save_folder_path}\n",
    "\n",
    "# run CCE\n",
    "{CCE_Executable_path} --input-file ./{cce_input_file_path.name}\n",
    "\"\"\"\n",
    "    submit_script_path = save_folder_path / \"submit.sh\"\n",
    "    submit_script_path.write_text(submit_script)\n",
    "\n",
    "    if not write_scripts_only:\n",
    "        command = f\"cd {save_folder_path} && qsub {submit_script_path}\"\n",
    "        status = subprocess.run(command, capture_output=True, shell=True, text=True)\n",
    "        if status.returncode == 0:\n",
    "            print(f\"Succesfully submitted {submit_script_path}\\n{status.stdout}\")\n",
    "        else:\n",
    "            sys.exit(\n",
    "                f\"Job submission failed for {submit_script_path} with error: \\n{status.stdout} \\n{status.stderr}\"\n",
    "            )\n",
    "\n",
    "\n",
    "def create_CCE_folder(\n",
    "    NewCCEPath: Path,\n",
    "    BondiBaseH5File: Path,\n",
    "    CCE_Executable_path: Path,\n",
    "    WT_data_modification_function,\n",
    "    CCE_ID: str = \"ConformalFactor\",\n",
    "    options_dict_user={},\n",
    "    write_scripts_only=False,\n",
    "\n",
    "):\n",
    "    NewCCEPath = NewCCEPath.resolve()\n",
    "    BondiBaseH5File = BondiBaseH5File.resolve()\n",
    "    CCE_Executable_path = CCE_Executable_path.resolve()\n",
    "\n",
    "    if not BondiBaseH5File.exists():\n",
    "        raise Exception(f\"{BondiBaseH5File} does not exist!\")\n",
    "    if not CCE_Executable_path.exists():\n",
    "        raise Exception(f\"{CCE_Executable_path} does not exist!\")\n",
    "\n",
    "    NewCCEPath.mkdir(parents=True, exist_ok=False)\n",
    "\n",
    "    WT_data_modification_function(BondiBaseH5File, NewCCEPath/BondiBaseH5File.name)\n",
    "\n",
    "    make_config_file(\n",
    "        BoundaryDataPath=NewCCEPath / BondiBaseH5File.name,\n",
    "        InputSavePath=NewCCEPath / \"cce.yaml\",\n",
    "        which_ID=CCE_ID,\n",
    "        options_dict_user=options_dict_user,\n",
    "    )\n",
    "\n",
    "    make_submit_file(\n",
    "        save_folder_path=NewCCEPath,\n",
    "        cce_input_file_path=NewCCEPath / \"cce.yaml\",\n",
    "        CCE_Executable_path=CCE_Executable_path,\n",
    "        write_scripts_only=write_scripts_only,\n",
    "    )\n",
    "\n",
    "    print(\"DONE!\\n\\n\\n\\n\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dc6870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_CCE_folder(\n",
    "#     NewCCEPath=Path(\n",
    "#         \"/resnick/groups/sxs/hchaudha/spec_runs/CCE_stuff/noise_in_WT_data/runs/original_tol_10\"\n",
    "#     ),\n",
    "#     BondiBaseH5File=Path(\n",
    "#         \"/resnick/groups/sxs/hchaudha/spec_runs/CCE_stuff/noise_in_WT_data/data/BondiCceR0250.h5\"\n",
    "#     ),\n",
    "#     CCE_Executable_path=Path(\n",
    "#         \"/resnick/groups/sxs/hchaudha/spec_runs/CCE_stuff/noise_in_WT_data/data/CharacteristicExtract\"\n",
    "#     ),\n",
    "#     WT_data_modification_function=partial(\n",
    "#         add_uniform_noise, noise_amp=tol, add_relative_noise=True\n",
    "#     ),\n",
    "#     CCE_ID=\"InverseCubic\",\n",
    "#     options_dict_user={\n",
    "#         \"Cce.Evolution.TimeStepper.AdamsBashforth.Order\": 3,\n",
    "#         \"Cce.Evolution.StepChoosers.Constant\": 0.1,\n",
    "#         \"Cce.Evolution.StepChoosers.ErrorControl(SwshVars).AbsoluteTolerance\": 1e-9*10,\n",
    "#         \"Cce.Evolution.StepChoosers.ErrorControl(SwshVars).RelativeTolerance\": 1e-7*10,\n",
    "#         \"Cce.Evolution.StepChoosers.ErrorControl(CoordVars).AbsoluteTolerance\": 1e-9*10,\n",
    "#         \"Cce.Evolution.StepChoosers.ErrorControl(CoordVars).RelativeTolerance\": 1e-8*10,\n",
    "#         \"Cce.LMax\": 20,\n",
    "#         \"Cce.NumberOfRadialPoints\": 15,\n",
    "#         \"Cce.ObservationLMax\": 8,\n",
    "#         \"Cce.H5Interpolator.BarycentricRationalSpanInterpolator.MinOrder\": 10,\n",
    "#         \"Cce.H5Interpolator.BarycentricRationalSpanInterpolator.MaxOrder\": 10,\n",
    "#         \"Cce.H5LookaheadTimes\": 10000,\n",
    "#         \"Cce.Filtering.RadialFilterHalfPower\": 64,\n",
    "#         \"Cce.Filtering.RadialFilterAlpha\": 35.0,\n",
    "#         \"Cce.Filtering.FilterLMax\": 18,\n",
    "#         \"Cce.ScriInterpOrder\": 5,\n",
    "#         \"Cce.ScriOutputDensity\": 1,\n",
    "#     }\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1dc298",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d807d3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bondi_data_path = Path(\"/groups/sxs/hchaudha/scripts/CCE_read_and_modify_WT_data/del/original_data/BondiCceR0250.h5\")\n",
    "save_base_path = Path(\"/groups/sxs/hchaudha/scripts/CCE_read_and_modify_WT_data/del/modified_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5bb17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_uniform_noise(bondi_data_path, save_base_path / \"BondiCceR0250_noisy.h5\", noise_amp=1e-15, add_relative_noise=True)\n",
    "diff_dict = get_diff_WT_data(bondi_data_path, save_base_path / \"BondiCceR0250_noisy.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b783c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_values_below_tolerance(\n",
    "    bondi_data_path,\n",
    "    save_base_path / \"BondiCceR0250_filtered.h5\",\n",
    "    tolerance=1e-12,\n",
    "    use_relative_tolerance=True,\n",
    ")\n",
    "diff_dict = get_diff_WT_data(\n",
    "    bondi_data_path, save_base_path / \"BondiCceR0250_filtered.h5\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6654d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in diff_dict.items():\n",
    "    print(f\"{key}: {np.max(value[:,1:])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec83e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with h5py.File(bondi_data_path, \"r\") as f:\n",
    "with h5py.File(save_base_path / \"BondiCceR0250_filtered.h5\", \"r\") as f:\n",
    "    vars = [\n",
    "        \"Beta.dat\",\n",
    "        \"DrJ.dat\",\n",
    "        \"DuR.dat\",\n",
    "        \"H.dat\",\n",
    "        \"J.dat\",\n",
    "        \"Q.dat\",\n",
    "        \"R.dat\",\n",
    "        \"U.dat\",\n",
    "        \"W.dat\",\n",
    "    ]\n",
    "    L2_vals = {}\n",
    "    print(f.keys())\n",
    "    for key in vars:\n",
    "        print(f\"{key}: {f[key].shape}\")\n",
    "        L2_vals[key] = np.max(f[key][2000:,1:],axis=1)\n",
    "        # L2_vals[key] = np.array(f[key][2000:, 1:])\n",
    "        # L2_vals[key] = np.linalg.norm(f[key][2000:,1:],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad40dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in L2_vals.items():\n",
    "    if key != 'R.dat':\n",
    "        continue\n",
    "    # if key != 'H.dat':\n",
    "    #     continue\n",
    "    print(f\"{key}: {value.shape}\")\n",
    "    plt.plot(value, label=key)\n",
    "plt.xlabel('Time')\n",
    "plt.yscale('log')\n",
    "plt.ylabel('L2 Norm')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4e9387",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.abs(L2_vals['J.dat'][1000,:]), label='R.dat')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebaaa362",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path(\"/resnick/groups/sxs/hchaudha/spec_runs/CCE_stuff/noise_in_WT_data/runs\")\n",
    "red_file1_path = base_path / \"uni_noise_abs_1e-22/red_cce.h5\"\n",
    "red_file2_path = base_path / \"uni_noise_abs_1e-14/red_cce.h5\"\n",
    "\n",
    "red_file1_path = base_path / \"uni_noise_rel_1e-16/red_cce.h5\"\n",
    "red_file2_path = base_path / \"uni_noise_rel_1e-08/red_cce.h5\"\n",
    "red_file2_path = Path(\"/resnick/groups/sxs/hchaudha/spec_runs/CCE_stuff/noise_in_WT_data/runs/uni_noise_abs_1e-22/red_cce.h5\")\n",
    "\n",
    "\n",
    "red_file1_path = base_path / \"filter_rel_1e-16/red_cce.h5\"\n",
    "# red_file2_path = base_path / \"filter_rel_1e-08/red_cce.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef4485b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(red_file1_path, \"r\") as f1, h5py.File(red_file2_path, \"r\") as f2:\n",
    "    red_vars = ['News', 'Psi0', 'Psi1', 'Psi2', 'Psi3', 'Psi4', 'Strain']\n",
    "    val1 = f1['SpectreR0250.cce'][red_vars[0]][()]\n",
    "    val2 = f2['SpectreR0250.cce'][red_vars[0]][()]\n",
    "    t = val1[:, 0]\n",
    "    l2_diff = np.linalg.norm(val1[:, 1:] - val2[:, 1:], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfbec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(t,l2_diff, label='Diff')\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3202a3",
   "metadata": {},
   "source": [
    "## Use L to change things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10590fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bondi_data_path = Path(\"/groups/sxs/hchaudha/scripts/CCE_read_and_modify_WT_data/del/original_data/BondiCceR0250.h5\")\n",
    "save_base_path = Path(\"/groups/sxs/hchaudha/scripts/CCE_read_and_modify_WT_data/del/modified_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b047ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_higher_L_modes_to_zero(\n",
    "    bondi_data_path, save_base_path/\"L10_zero.h5\", min_L_to_keep=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6319624",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with h5py.File(save_base_path/\"L10_zero.h5\", \"r\") as f:\n",
    "    vars = ['Beta.dat', 'DrJ.dat', 'DuR.dat', 'H.dat', 'J.dat', 'Q.dat', 'R.dat', 'U.dat', 'W.dat']\n",
    "    vars = ['Beta.dat']\n",
    "    for key in vars:\n",
    "        legend = f[key].attrs['Legend']\n",
    "        for i,col_name in enumerate(list(legend)):\n",
    "            if col_name == 'time':\n",
    "                continue\n",
    "            L, m, real = get_Lm_info_from_col_name(col_name)\n",
    "            print(f\"{col_name} : {np.linalg.norm(f[key][:, i])}\")\n",
    "        #     print(f\"{col_name}: {real}, {L}, {m}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cc7715",
   "metadata": {},
   "source": [
    "# Comparison plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dba1986",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path(\"/resnick/groups/sxs/hchaudha/spec_runs/CCE_stuff/noise_in_WT_data/runs\")\n",
    "save_fig_plot = Path(\"/resnick/groups/sxs/hchaudha/spec_runs/CCE_stuff/noise_in_WT_data/runs/figures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_run = base_path / \"original/red_cce.h5\"\n",
    "l2_diff_dict = {\n",
    "    \"1e-08\": {},\n",
    "    \"1e-10\": {},\n",
    "    \"1e-12\": {},\n",
    "    \"1e-16\": {},\n",
    "    \"1e-18\": {},\n",
    "    \"1e-20\": {},\n",
    "    \"1e-22\": {},\n",
    "}\n",
    "red_vars = ['News', 'Psi0', 'Psi1', 'Psi2', 'Psi3', 'Psi4', 'Strain']\n",
    "with h5py.File(base_run, \"r\") as f:\n",
    "    for key in l2_diff_dict.keys():\n",
    "        run2 = base_path / f\"uni_noise_abs_{key}/red_cce.h5\"\n",
    "        with h5py.File(run2, \"r\") as f2:\n",
    "            for var in red_vars:\n",
    "                val1 = f['SpectreR0250.cce'][var]\n",
    "                val2 = f2['SpectreR0250.cce'][var]\n",
    "                l2_diff = np.linalg.norm(val1[:, 1:] - val2[:, 1:], axis=1)\n",
    "                l2_diff_dict[key][var] = l2_diff\n",
    "                print(f\"{key} {var}\")\n",
    "    t = f['SpectreR0250.cce'][red_vars[0]][:, 0]\n",
    "\n",
    "invert_l2_diff_dict = {}\n",
    "for key, value in l2_diff_dict.items():\n",
    "    for var, l2_diff in value.items():\n",
    "        if var not in invert_l2_diff_dict:\n",
    "            invert_l2_diff_dict[var] = {}\n",
    "        invert_l2_diff_dict[var][key] = l2_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f739ed67",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in red_vars:\n",
    "    for run, value in invert_l2_diff_dict[var].items():\n",
    "        plt.plot(t, value, label=run)\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('L2 Diff Norm')\n",
    "    plt.legend()\n",
    "    plt.title(f'uni_noise_abs: Diff {var}')\n",
    "    plt.yscale('log')\n",
    "    plt.savefig(save_fig_plot / f\"uni_noise_abs_diff_{var}.png\")\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1371a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_run = base_path / \"original/red_cce.h5\"\n",
    "l2_diff_dict = {\n",
    "    \"1e-05\": {},\n",
    "    \"1e-06\": {},\n",
    "    \"1e-07\": {},\n",
    "    \"1e-08\": {},\n",
    "    \"1e-10\": {},\n",
    "    \"1e-12\": {},\n",
    "    \"1e-14\": {},\n",
    "    \"1e-16\": {},\n",
    "}\n",
    "red_vars = ['News', 'Psi0', 'Psi1', 'Psi2', 'Psi3', 'Psi4', 'Strain']\n",
    "red_vars = ['News']\n",
    "with h5py.File(base_run, \"r\") as f:\n",
    "    for key in l2_diff_dict.keys():\n",
    "        run2 = base_path / f\"uni_noise_rel_{key}/red_cce.h5\"\n",
    "        with h5py.File(run2, \"r\") as f2:\n",
    "            for var in red_vars:\n",
    "                val1 = f['SpectreR0250.cce'][var]\n",
    "                val2 = f2['SpectreR0250.cce'][var]\n",
    "                l2_diff = np.linalg.norm(val1[:, 1:] - val2[:, 1:], axis=1)\n",
    "                l2_diff_dict[key][var] = l2_diff\n",
    "                print(f\"{key} {var}\")\n",
    "    t = f['SpectreR0250.cce'][red_vars[0]][:, 0]\n",
    "\n",
    "invert_l2_diff_dict = {}\n",
    "for key, value in l2_diff_dict.items():\n",
    "    for var, l2_diff in value.items():\n",
    "        if var not in invert_l2_diff_dict:\n",
    "            invert_l2_diff_dict[var] = {}\n",
    "        invert_l2_diff_dict[var][key] = l2_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e20815",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in red_vars:\n",
    "    for run, value in invert_l2_diff_dict[var].items():\n",
    "        plt.plot(t, value, label=run)\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('L2 Diff Norm')\n",
    "    plt.legend()\n",
    "    plt.title(f'uni_noise_rel: Diff {var}')\n",
    "    plt.yscale('log')\n",
    "    plt.savefig(save_fig_plot / f\"uni_noise_rel_diff_{var}.png\")\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c5c5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_run = base_path / \"original/red_cce.h5\"\n",
    "l2_diff_dict = {\n",
    "    \"1e-05\": {},\n",
    "    \"1e-06\": {},\n",
    "    \"1e-07\": {},\n",
    "    \"1e-08\": {},\n",
    "    \"1e-10\": {},\n",
    "    \"1e-12\": {},\n",
    "    \"1e-14\": {},\n",
    "    \"1e-16\": {},\n",
    "}\n",
    "red_vars = ['News', 'Psi0', 'Psi1', 'Psi2', 'Psi3', 'Psi4', 'Strain']\n",
    "red_vars = ['News', 'Strain']\n",
    "with h5py.File(base_run, \"r\") as f:\n",
    "    for key in l2_diff_dict.keys():\n",
    "        run2 = base_path / f\"filter_rel_{key}/red_cce.h5\"\n",
    "        with h5py.File(run2, \"r\") as f2:\n",
    "            for var in red_vars:\n",
    "                val1 = f['SpectreR0250.cce'][var][()]\n",
    "                val2 = f2['SpectreR0250.cce'][var][()]\n",
    "                \n",
    "                t1, data1 = val1[:, 0], val1[:, 1:]\n",
    "                t2, data2 = val2[:, 0], val2[:, 1:]\n",
    "\n",
    "                # Define common time grid using intersection or union\n",
    "                common_time = np.union1d(t1, t2)\n",
    "\n",
    "                # Interpolate both data sets to the common time grid\n",
    "                interp1 = interp1d(t1, data1, axis=0, bounds_error=False, fill_value=\"extrapolate\",kind='cubic')\n",
    "                interp2 = interp1d(t2, data2, axis=0, bounds_error=False, fill_value=\"extrapolate\",kind='cubic')\n",
    "\n",
    "                aligned1 = interp1(common_time)\n",
    "                aligned2 = interp2(common_time)\n",
    "\n",
    "                # Compute L2 norm of the difference across angular modes\n",
    "                l2_diff = np.linalg.norm(aligned1 - aligned2, axis=1)\n",
    "                l2_diff_dict[key][var] = (common_time,l2_diff)\n",
    "                print(f\"{key} {var}\")\n",
    "\n",
    "invert_l2_diff_dict = {}\n",
    "for key, value in l2_diff_dict.items():\n",
    "    for var, l2_diff in value.items():\n",
    "        if var not in invert_l2_diff_dict:\n",
    "            invert_l2_diff_dict[var] = {}\n",
    "        invert_l2_diff_dict[var][key] = l2_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9422c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in red_vars:\n",
    "    for run, value in invert_l2_diff_dict[var].items():\n",
    "        common_time, value = value\n",
    "        plt.plot(common_time, value, label=run)\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('L2 Diff Norm')\n",
    "    plt.legend()\n",
    "    plt.title(f'filter_rel(cubic): Diff {var}')\n",
    "    plt.yscale('log')\n",
    "    plt.savefig(save_fig_plot / f\"filter_rel(cubic)_{var}.png\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c02d313",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in red_vars:\n",
    "    for run, value in invert_l2_diff_dict[var].items():\n",
    "        plt.plot(t, value, label=run)\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('L2 Diff Norm')\n",
    "    plt.legend()\n",
    "    plt.title(f'filter_rel: Diff {var}')\n",
    "    plt.yscale('log')\n",
    "    plt.savefig(save_fig_plot / f\"filter_rel_diff_{var}.png\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef88008",
   "metadata": {},
   "source": [
    "## Original comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d181760c",
   "metadata": {},
   "source": [
    "#### Ode tol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a303114",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig_folder_path = save_fig_plot/'diff_base'\n",
    "if not save_fig_folder_path.exists():\n",
    "    save_fig_folder_path.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cba5f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_run = base_path / \"original/red_cce.h5\"\n",
    "base_run = base_path / \"original_tol_0.001/red_cce.h5\"\n",
    "l2_diff_dict_ode = {\n",
    "    \"original_tol_1000\": {},\n",
    "    \"original_tol_500\": {},\n",
    "    \"original_tol_100\": {},\n",
    "    \"original_tol_50\": {},\n",
    "    \"original_tol_20\": {},\n",
    "    \"original_tol_10\": {},\n",
    "    \"original_tol_5\": {},\n",
    "    \"original\": {},\n",
    "    \"original_tol_1.1\": {},\n",
    "    \"original_tol_010\": {},\n",
    "    \"original_tol_0.2\": {},\n",
    "    \"original_tol_0.02\": {},\n",
    "    \"original_tol_0.01\": {},\n",
    "    # \"original_tol_0.001\": {},\n",
    "}\n",
    "base_run = base_path / \"rad_20_11factor_tol_0.2/red_cce.h5\"\n",
    "l2_diff_dict_ode = {\n",
    "    \"rad_20_11factor_tol_1000\": {},\n",
    "    \"rad_20_11factor_tol_500\": {},\n",
    "    \"rad_20_11factor_tol_100\": {},\n",
    "    \"rad_20_11factor_tol_50\": {},\n",
    "    \"rad_20_11factor_tol_20\": {},\n",
    "    \"rad_20_11factor_tol_5\": {},\n",
    "    \"rad_20_11factor_tol_1.1\": {},\n",
    "    \"rad_20_11factor_tol_1\": {},\n",
    "    \"rad_20_11factor_tol_0.2\": {},\n",
    "    # \"rad_20_11factor_tol_0.02\": {},\n",
    "    # \"rad_20_11factor_tol_0.01\": {},\n",
    "    # \"rad_20_11factor_tol_0.001\": {},\n",
    "}\n",
    "\n",
    "base_run = base_path / \"1rad30_ode_tol/r30_tol_0.01/red_cce.h5\"\n",
    "l2_diff_dict_ode = {\n",
    "    \"1rad30_ode_tol/r30_tol_0.1\": {},\n",
    "    # \"1rad30_ode_tol/r30_tol_0.01\":{},\n",
    "    # \"1rad30_ode_tol/r30_tol_0.001\":{},\n",
    "    \"1rad30_ode_tol/r30_tol_1.1\": {},\n",
    "    \"1rad30_ode_tol/r30_tol_10\": {},\n",
    "    \"1rad30_ode_tol/r30_tol_100\": {},\n",
    "    \"1rad30_ode_tol/r30_tol_1000\": {},\n",
    "}\n",
    "base_run = base_path / \"1rad30_ode_tol/r30_start_2000_tol_1.1/red_cce.h5\"\n",
    "l2_diff_dict_ode = {\n",
    "\"1rad30_ode_tol/r30_start_2000_tol_0.1\":{},\n",
    "\"1rad30_ode_tol/r30_start_2000_tol_0.01\":{},\n",
    "\"1rad30_ode_tol/r30_start_2000_tol_0.001\":{},\n",
    "# \"1rad30_ode_tol/r30_start_2000_tol_1.1\":{},\n",
    "\"1rad30_ode_tol/r30_start_2000_tol_10\":{},\n",
    "\"1rad30_ode_tol/r30_start_2000_tol_100\":{},\n",
    "\"1rad30_ode_tol/r30_start_2000_tol_1000\":{},\n",
    "}\n",
    "\n",
    "# r = 100\n",
    "# base_run = base_path / f\"different_ex_rad_R_convg/{r}_38/red_cce.h5\"\n",
    "# l2_diff_dict_ode = {\n",
    "# f\"different_ex_rad_R_convg/{r}_24\":{},\n",
    "# f\"different_ex_rad_R_convg/{r}_28\":{},\n",
    "# f\"different_ex_rad_R_convg/{r}_30\":{},\n",
    "# f\"different_ex_rad_R_convg/{r}_34\":{},\n",
    "# f\"different_ex_rad_R_convg/{r}_38\":{},\n",
    "# }\n",
    "\n",
    "r=500\n",
    "base_run = base_path / f\"36_segs_R_conv/{r}_38/red_cce.h5\"\n",
    "l2_diff_dict_ode = {\n",
    "f\"36_segs_R_conv/{r}_24\":{},\n",
    "f\"36_segs_R_conv/{r}_28\":{},\n",
    "f\"36_segs_R_conv/{r}_30\":{},\n",
    "f\"36_segs_R_conv/{r}_34\":{},\n",
    "# f\"36_segs_R_conv/{r}_38\":{},\n",
    "}\n",
    "\n",
    "r=500\n",
    "base_run = base_path / f\"36_segs_R_conv/{r}_R_30_L_24/red_cce.h5\"\n",
    "l2_diff_dict_ode = {\n",
    "f\"36_segs_R_conv/{r}_R_30_L_14\":{},\n",
    "f\"36_segs_R_conv/{r}_R_30_L_16\":{},\n",
    "f\"36_segs_R_conv/{r}_R_30_L_18\":{},\n",
    "f\"36_segs_R_conv/{r}_R_30_L_20\":{},\n",
    "f\"36_segs_R_conv/{r}_R_30_L_22\":{},\n",
    "}\n",
    "\n",
    "r = 250\n",
    "base_run = base_path / \"max_step_size_test/max_step_0.04/red_cce.h5\"\n",
    "# base_run = base_path / \"max_step_size_test/max_step_0.01/red_cce.h5\"\n",
    "l2_diff_dict_ode = {\n",
    "# \"max_step_0.04\":{},\n",
    "\"max_step_size_test/max_step_0.08\":{},\n",
    "\"max_step_size_test/max_step_0.07\":{},\n",
    "\"max_step_size_test/max_step_0.06\":{},\n",
    "\"max_step_size_test/max_step_0.05\":{},\n",
    "# \"max_step_size_test/max_step_0.04\":{},\n",
    "\"max_step_size_test/max_step_0.03\":{},\n",
    "\"max_step_size_test/max_step_0.02\":{},\n",
    "\"max_step_size_test/max_step_0.01\":{},\n",
    "# \"max_step_size_test/max_step_0.03\":{},\n",
    "}\n",
    "\n",
    "red_vars = [\"News\", \"Psi0\", \"Psi1\", \"Psi2\", \"Psi3\", \"Psi4\", \"Strain\"]\n",
    "# red_vars = [\"Psi0\", \"Psi1\"]\n",
    "\n",
    "\n",
    "with h5py.File(base_run, \"r\") as f:\n",
    "    for key in l2_diff_dict_ode.keys():\n",
    "        run2 = base_path / f\"{key}/red_cce.h5\"\n",
    "        with h5py.File(run2, \"r\") as f2:\n",
    "            for var in red_vars:\n",
    "                val1 = f[f\"SpectreR0{r}.cce\"][var][()]\n",
    "                val2 = f2[f\"SpectreR0{r}.cce\"][var][()]\n",
    "\n",
    "                t1, data1 = val1[:, 0], val1[:, 1:]\n",
    "                t2, data2 = val2[:, 0], val2[:, 1:]\n",
    "\n",
    "                # Define common time grid using intersection or union\n",
    "                max_time = np.min([np.max(t1), np.max(t2)])\n",
    "                min_time = np.max([np.min(t1), np.min(t2)])\n",
    "                # get time grid where delta t is 1\n",
    "                common_time = np.linspace(\n",
    "                    min_time,\n",
    "                    max_time,\n",
    "                    num=int(max_time - min_time),\n",
    "                )\n",
    "\n",
    "                # Interpolate both data sets to the common time grid\n",
    "                interp1 = interp1d(\n",
    "                    t1,\n",
    "                    data1,\n",
    "                    axis=0,\n",
    "                    bounds_error=False,\n",
    "                    fill_value=\"extrapolate\",\n",
    "                    kind=\"cubic\",\n",
    "                )\n",
    "                interp2 = interp1d(\n",
    "                    t2,\n",
    "                    data2,\n",
    "                    axis=0,\n",
    "                    bounds_error=False,\n",
    "                    fill_value=\"extrapolate\",\n",
    "                    kind=\"cubic\",\n",
    "                )\n",
    "\n",
    "                aligned1 = interp1(common_time)\n",
    "                aligned2 = interp2(common_time)\n",
    "\n",
    "                # Compute L2 norm of the difference across angular modes\n",
    "                l2_diff = np.linalg.norm(aligned1 - aligned2, axis=1)\n",
    "                l2_diff_dict_ode[key][var] = (common_time, l2_diff)\n",
    "                print(f\"{key} {var}\")\n",
    "\n",
    "                # break\n",
    "\n",
    "    t = f[f\"SpectreR0{r}.cce\"][red_vars[0]][:, 0]\n",
    "\n",
    "\n",
    "invert_l2_diff_dict_ode = {}\n",
    "for key, value in l2_diff_dict_ode.items():\n",
    "    for var, l2_diff in value.items():\n",
    "        if var not in invert_l2_diff_dict_ode:\n",
    "            invert_l2_diff_dict_ode[var] = {}\n",
    "        invert_l2_diff_dict_ode[var][key] = l2_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e0f9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = plt.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n",
    "linestyles = [\"-\", \"--\", \":\", \"-.\"]\n",
    "\n",
    "t_Min = 150\n",
    "for var in red_vars:\n",
    "    # if var != \"News\":\n",
    "    #     continue\n",
    "    plt.figure()\n",
    "\n",
    "    # Reset cycles for each variable\n",
    "    color_cycle = cycle(colors)\n",
    "    linestyle_cycle = cycle(linestyles)\n",
    "    linestyle = next(linestyle_cycle)\n",
    "\n",
    "    for idx, (run, value) in enumerate(invert_l2_diff_dict_ode[var].items()):\n",
    "        # label = run[9:]\n",
    "        label = run.split(\"/\")[-1]\n",
    "        # if run == \"original_tol_010\":\n",
    "        #     label = \"tol_0.1\"\n",
    "        # label = label.replace(\"_\", \"*\")\n",
    "        # if run == \"original\":\n",
    "        #     label = \"default_tol\"\n",
    "\n",
    "        common_time, value = value\n",
    "        filtered_index = common_time > t_Min\n",
    "\n",
    "        # Advance linestyle every time we exhaust the color list\n",
    "        if idx % len(colors) == 0 and idx != 0:\n",
    "            linestyle = next(linestyle_cycle)\n",
    "\n",
    "        color = next(color_cycle)\n",
    "\n",
    "        plt.plot(\n",
    "            common_time[filtered_index],\n",
    "            value[filtered_index],\n",
    "            label=label,\n",
    "            linestyle=linestyle,\n",
    "            color=color,\n",
    "        )\n",
    "\n",
    "    plt.yscale(\"log\")\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"L2 Diff Norm\")\n",
    "    plt.legend()\n",
    "    # plt.title(f\"base L=24 (tmin={t_Min}): {var}\")\n",
    "    plt.title(f\"base maxt=0.01 (tmin={t_Min}): {var}\")\n",
    "    # plt.savefig(save_fig_folder_path / f\"ode_tol_change_{var}_{t_Min}.png\")\n",
    "    # plt.savefig(Path(\"/resnick/groups/sxs/hchaudha/spec_runs/CCE_stuff/noise_in_WT_data/runs/36_segs_R_conv/figures\") / f\"L_convg_{var}_{t_Min}_R={r}.png\")\n",
    "    plt.savefig(Path(\"/resnick/groups/sxs/hchaudha/spec_runs/CCE_stuff/noise_in_WT_data/runs/max_step_size_test/figures\") / f\"max_step_size_base004_{var}_{t_Min}_R={r}.png\")\n",
    "    # plt.close()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196e5b5f",
   "metadata": {},
   "source": [
    "### L and R points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d632e5",
   "metadata": {},
   "source": [
    "#### L points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb505b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_run = base_path / \"original/red_cce.h5\"\n",
    "base_run = base_path / \"original_LMax_26/red_cce.h5\"\n",
    "l2_diff_dict_L = {\n",
    "    \"original_LMax_14\": {},\n",
    "    \"original_LMax_16\": {},\n",
    "    \"original_LMax_18\": {},\n",
    "    \"original\": {},\n",
    "    \"original_tol_Lmax21\": {},\n",
    "    \"original_LMax_22\": {},\n",
    "    \"original_LMax_24\": {},\n",
    "    # \"original_LMax_26\": {},\n",
    "}\n",
    "\n",
    "r = 100\n",
    "base_run = base_path / f\"different_ex_rad_R_convg/{r}_R_40_L_26/red_cce.h5\"\n",
    "l2_diff_dict_L = {\n",
    "f\"different_ex_rad_R_convg/{r}_R_40_L_16\":{},\n",
    "f\"different_ex_rad_R_convg/{r}_R_40_L_18\":{},\n",
    "f\"different_ex_rad_R_convg/{r}_R_40_L_20\":{},\n",
    "f\"different_ex_rad_R_convg/{r}_R_40_L_22\":{},\n",
    "f\"different_ex_rad_R_convg/{r}_R_40_L_24\":{},\n",
    "# f\"different_ex_rad_R_convg/{r}_R_40_L_26\":{},\n",
    "}\n",
    "\n",
    "red_vars = [\"News\", \"Psi0\", \"Psi1\", \"Psi2\", \"Psi3\", \"Psi4\", \"Strain\"]\n",
    "\n",
    "with h5py.File(base_run, \"r\") as f:\n",
    "    for key in l2_diff_dict_L.keys():\n",
    "        run2 = base_path / f\"{key}/red_cce.h5\"\n",
    "        with h5py.File(run2, \"r\") as f2:\n",
    "            for var in red_vars:\n",
    "                val1 = f[f\"SpectreR0{r}.cce\"][var][()]\n",
    "                val2 = f2[f\"SpectreR0{r}.cce\"][var][()]\n",
    "\n",
    "                t1, data1 = val1[:, 0], val1[:, 1:]\n",
    "                t2, data2 = val2[:, 0], val2[:, 1:]\n",
    "\n",
    "                # Define common time grid using intersection or union\n",
    "                common_time = np.union1d(t1, t2)\n",
    "\n",
    "                # Interpolate both data sets to the common time grid\n",
    "                interp1 = interp1d(\n",
    "                    t1,\n",
    "                    data1,\n",
    "                    axis=0,\n",
    "                    bounds_error=False,\n",
    "                    fill_value=\"extrapolate\",\n",
    "                    kind=\"cubic\",\n",
    "                )\n",
    "                interp2 = interp1d(\n",
    "                    t2,\n",
    "                    data2,\n",
    "                    axis=0,\n",
    "                    bounds_error=False,\n",
    "                    fill_value=\"extrapolate\",\n",
    "                    kind=\"cubic\",\n",
    "                )\n",
    "\n",
    "                aligned1 = interp1(common_time)\n",
    "                aligned2 = interp2(common_time)\n",
    "\n",
    "                # Compute L2 norm of the difference across angular modes\n",
    "                l2_diff = np.linalg.norm(aligned1 - aligned2, axis=1)\n",
    "                l2_diff_dict_L[key][var] = (common_time, l2_diff)\n",
    "                print(f\"{key} {var}\")\n",
    "\n",
    "    t = f[f\"SpectreR0{r}.cce\"][red_vars[0]][:, 0]\n",
    "\n",
    "invert_l2_diff_dict_L = {}\n",
    "for key, value in l2_diff_dict_L.items():\n",
    "    for var, l2_diff in value.items():\n",
    "        if var not in invert_l2_diff_dict_L:\n",
    "            invert_l2_diff_dict_L[var] = {}\n",
    "        invert_l2_diff_dict_L[var][key] = l2_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8febc362",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_Min = 50\n",
    "for var in red_vars:\n",
    "    for run, value in invert_l2_diff_dict_L[var].items():\n",
    "        common_time, value = value\n",
    "        filtered_index = common_time > t_Min\n",
    "        label = run.split(\"/\")[-1]\n",
    "        # if run == \"original\":\n",
    "        #     label = \"LMax_20(default)\"\n",
    "        # if run == \"original_tol_Lmax21\":\n",
    "        #     label = \"LMax_21\"\n",
    "        plt.plot(common_time[filtered_index], value[filtered_index], label=label)\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('L2 Diff Norm')\n",
    "    plt.legend()\n",
    "    plt.title(f'base LMax_26 : {var}')\n",
    "    plt.yscale('log')\n",
    "    # plt.savefig(save_fig_folder_path / f\"L_change_diff_{var}.png\")\n",
    "    # plt.savefig(Path(\"/resnick/groups/sxs/hchaudha/spec_runs/CCE_stuff/noise_in_WT_data/runs/different_ex_rad_R_convg/figures\") / f\"r=100_L_covg_{var}.png\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd22f7e1",
   "metadata": {},
   "source": [
    "#### R points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3d262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_run = base_path / \"original/red_cce.h5\"\n",
    "base_run = base_path / \"original_rad_pts_34/red_cce.h5\"\n",
    "l2_diff_dict_R = {\n",
    "    \"original_rad_pts_12\": {},\n",
    "    # \"original_rad_pts_13\": {},\n",
    "    \"original_rad_pts_14\": {},\n",
    "    # \"original\": {},\n",
    "    \"original_rad_pts_16\": {},\n",
    "    # \"original_rad_pts_17\": {},\n",
    "    \"original_rad_pts_18\": {},\n",
    "    \"original_rad_pts_20\": {},\n",
    "    \"original_rad_pts_22\": {},\n",
    "    \"original_rad_pts_24\": {},\n",
    "    \"original_rad_pts_26\": {},\n",
    "    \"original_rad_pts_28\": {},\n",
    "    \"original_rad_pts_30\": {},\n",
    "    # \"original_rad_pts_34\": {},\n",
    "}\n",
    "\n",
    "r = 100\n",
    "base_run = base_path / \"different_ex_rad_R_convg/100_50/red_cce.h5\"\n",
    "l2_diff_dict_R = {\n",
    "\"different_ex_rad_R_convg/100_24\":{},\n",
    "\"different_ex_rad_R_convg/100_28\":{},\n",
    "\"different_ex_rad_R_convg/100_30\":{},\n",
    "\"different_ex_rad_R_convg/100_34\":{},\n",
    "\"different_ex_rad_R_convg/100_38\":{},\n",
    "\"different_ex_rad_R_convg/100_40\":{},\n",
    "\"different_ex_rad_R_convg/100_42\":{},\n",
    "\"different_ex_rad_R_convg/100_44\":{},\n",
    "\"different_ex_rad_R_convg/100_46\":{},\n",
    "\"different_ex_rad_R_convg/100_48\":{},\n",
    "# \"different_ex_rad_R_convg/100_50\":{},\n",
    "}\n",
    "\n",
    "red_vars = [\"News\", \"Psi0\", \"Psi1\", \"Psi2\", \"Psi3\", \"Psi4\", \"Strain\"]\n",
    "\n",
    "with h5py.File(base_run, \"r\") as f:\n",
    "    for key in l2_diff_dict_R.keys():\n",
    "        run2 = base_path / f\"{key}/red_cce.h5\"\n",
    "        with h5py.File(run2, \"r\") as f2:\n",
    "            for var in red_vars:\n",
    "                val1 = f[f\"SpectreR0{r}.cce\"][var][()]\n",
    "                val2 = f2[f\"SpectreR0{r}.cce\"][var][()]\n",
    "\n",
    "                t1, data1 = val1[:, 0], val1[:, 1:]\n",
    "                t2, data2 = val2[:, 0], val2[:, 1:]\n",
    "\n",
    "                # Define common time grid using intersection or union\n",
    "                common_time = np.union1d(t1, t2)\n",
    "\n",
    "                # Interpolate both data sets to the common time grid\n",
    "                interp1 = interp1d(\n",
    "                    t1,\n",
    "                    data1,\n",
    "                    axis=0,\n",
    "                    bounds_error=False,\n",
    "                    fill_value=\"extrapolate\",\n",
    "                    kind=\"cubic\",\n",
    "                )\n",
    "                interp2 = interp1d(\n",
    "                    t2,\n",
    "                    data2,\n",
    "                    axis=0,\n",
    "                    bounds_error=False,\n",
    "                    fill_value=\"extrapolate\",\n",
    "                    kind=\"cubic\",\n",
    "                )\n",
    "\n",
    "                aligned1 = interp1(common_time)\n",
    "                aligned2 = interp2(common_time)\n",
    "\n",
    "                # Compute L2 norm of the difference across angular modes\n",
    "                l2_diff = np.linalg.norm(aligned1 - aligned2, axis=1)\n",
    "                l2_diff_dict_R[key][var] = (common_time, l2_diff)\n",
    "                print(f\"{key} {var}\")\n",
    "\n",
    "    t = f[f\"SpectreR0{r}.cce\"][red_vars[0]][:, 0]\n",
    "\n",
    "\n",
    "invert_l2_diff_dict_R = {}\n",
    "for key, value in l2_diff_dict_R.items():\n",
    "    for var, l2_diff in value.items():\n",
    "        if var not in invert_l2_diff_dict_R:\n",
    "            invert_l2_diff_dict_R[var] = {}\n",
    "        invert_l2_diff_dict_R[var][key] = l2_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e76280c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_Min = 50\n",
    "for var in red_vars:\n",
    "    for run, value in invert_l2_diff_dict_R[var].items():\n",
    "        common_time, value = value\n",
    "        filtered_index = common_time > t_Min\n",
    "        # label = run[9:]  # Remove 'original_' prefix for clarity\n",
    "        label = run.split(\"/\")[-1]  # Remove 'original_' prefix for clarity\n",
    "        if run == \"original\":\n",
    "            label = \"rad_pts_15(default)\"\n",
    "        plt.plot(common_time[filtered_index], value[filtered_index], label=label)\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('L2 Diff Norm')\n",
    "    plt.legend()\n",
    "    plt.title(f'base rad_pts_50 : {var}')\n",
    "    plt.yscale('log')\n",
    "    # plt.savefig(save_fig_folder_path / f\"rad_pts_change_diff_{var}.png\")\n",
    "    # plt.savefig(Path(\"/resnick/groups/sxs/hchaudha/spec_runs/CCE_stuff/noise_in_WT_data/runs/different_ex_rad_R_convg/figures\") / f\"r=100_R_convg_{var}.png\")\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3098b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "invert_l2_diff_dict_R['News']['original_rad_pts_30']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef25273",
   "metadata": {},
   "source": [
    "### Time step size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c373c2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dt_ode_tol = {\n",
    "    \"original_tol_1000\": None,\n",
    "    # \"original_tol_500\": None,\n",
    "    \"original_tol_100\": None,\n",
    "    # \"original_tol_50\": None,\n",
    "    # \"original_tol_20\": None,\n",
    "    \"original_tol_10\": None,\n",
    "    # \"original_tol_5\": None,\n",
    "    \"original\": None,\n",
    "    # \"original_tol_1.1\": None,\n",
    "    \"original_tol_010\": None,\n",
    "    # \"original_tol_0.2\": None,\n",
    "    # \"original_tol_0.02\": None,\n",
    "    \"original_tol_0.01\": None,\n",
    "    # \"original_tol_0.001\": None,\n",
    "}\n",
    "# dt_ode_tol = {\n",
    "#     \"rad_20_11factor_tol_1000\": None,\n",
    "#     \"rad_20_11factor_tol_500\": None,\n",
    "#     \"rad_20_11factor_tol_100\": None,\n",
    "#     \"rad_20_11factor_tol_50\": None,\n",
    "#     \"rad_20_11factor_tol_20\": None,\n",
    "#     \"rad_20_11factor_tol_5\": None,\n",
    "#     \"rad_20_11factor_tol_1.1\": None,\n",
    "#     \"rad_20_11factor_tol_1\": None,\n",
    "#     \"rad_20_11factor_tol_0.2\": None,\n",
    "#     # \"rad_20_11factor_tol_0.02\": None,\n",
    "#     # \"rad_20_11factor_tol_0.01\": None,\n",
    "#     # \"rad_20_11factor_tol_0.001\": None,\n",
    "# }\n",
    "\n",
    "red_vars = [\"News\", \"Psi0\", \"Psi1\", \"Psi2\", \"Psi3\", \"Psi4\", \"Strain\"]\n",
    "\n",
    "for key in dt_ode_tol.keys():\n",
    "    run2 = base_path / f\"{key}/red_cce.h5\"\n",
    "    with h5py.File(run2, \"r\") as f2:\n",
    "        t = f2['SpectreR0250.cce']['News'][1:, 0]\n",
    "        dt = np.diff(f2['SpectreR0250.cce']['News'][:, 0])\n",
    "        dt_ode_tol[key] = np.zeros((len(t), 2))\n",
    "        dt_ode_tol[key][:, 0] = t\n",
    "        dt_ode_tol[key][:, 1] = dt\n",
    "        print(f\"Done {key}\")\n",
    "        # dt_ode_tol[key] = f2['Cce']['CceTimeStep.dat'][()]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fad107e",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_index = 14000\n",
    "for key, value in dt_ode_tol.items():\n",
    "    plt.plot(value[start_index:, 0], value[start_index:, 1], label=key)\n",
    "    # plt.plot(value[:, 0], np.abs(value[:, 1]-value[-1,1]), label=key)\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Time Step Size')\n",
    "# plt.yscale('log')\n",
    "plt.legend()\n",
    "# plt.savefig(save_fig_folder_path / \"ode_tol_time_step_size.png\")\n",
    "# plt.title('Time Step Size for Different ODE Tolerances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d4a7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run2 = Path(\"/resnick/groups/sxs/hchaudha/spec_runs/CCE_stuff/noise_in_WT_data/runs/rad_20_11factor_tol_1000/red_cce.h5\")\n",
    "# run2 = Path(\"/resnick/groups/sxs/hchaudha/spec_runs/CCE_stuff/noise_in_WT_data/runs/rad_20_11factor_tol_500/red_cce.h5\")\n",
    "run2 = Path(\"/resnick/groups/sxs/hchaudha/spec_runs/CCE_stuff/noise_in_WT_data/runs/1rad30_ode_tol/r30_start_2000_tol_0.1/red_cce.h5\")\n",
    "run2 = Path(\"/resnick/groups/sxs/hchaudha/spec_runs/CCE_stuff/noise_in_WT_data/runs/max_step_size_test/max_step_0.01/red_cce.h5\")\n",
    "# run2 = Path(\"/resnick/groups/sxs/hchaudha/spec_runs/CCE_stuff/noise_in_WT_data/runs/original/red_cce.h5\")\n",
    "with h5py.File(run2, \"r\") as f2:\n",
    "    print(f2.keys())\n",
    "    # print(f2['SpectreR0250.cce'].keys())\n",
    "    val = f2['SpectreR0250.cce']['News'][:,:2]\n",
    "    # val = f2['Cce']['CceTimeStep.dat'][()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee51ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(val[600:,0],np.diff(val[600-1:,0]))\n",
    "# plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17aed33",
   "metadata": {},
   "outputs": [],
   "source": [
    "WT_data = Path(\"/resnick/groups/sxs/hchaudha/spec_runs/CCE_stuff/noise_in_WT_data/data/BondiCceR0250.h5\")\n",
    "\n",
    "with h5py.File(WT_data, \"r\") as f:\n",
    "    print(f.keys())\n",
    "    t = f['Beta.dat'][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d04e60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_path = Path(\"/resnick/groups/sxs/hchaudha/spec_runs/CCE_stuff/noise_in_WT_data/runs/noise_post_junk\")/\"del.h5\"\n",
    "# add_uniform_noise(\n",
    "#     WT_data, save_path, noise_amp=1e-10, add_relative_noise=False, t_min=1000.0\n",
    "# )\n",
    "\n",
    "# with h5py.File(save_path, \"r\") as f:\n",
    "#     with h5py.File(WT_data, \"r\") as f2:\n",
    "#         for key in f.keys():\n",
    "#             if \"Version\" in key:\n",
    "#                 continue\n",
    "#             start_index = np.searchsorted(t, 1000)\n",
    "#             print(f\"{key} : {np.linalg.norm(f[key][:start_index, 1:] - f2[key][:start_index, 1:])}\")\n",
    "#             # print(f\"{key} : {np.linalg.norm(f[key][:, 1:])}\")\n",
    "#             # print(f\"{key} : {np.linalg.norm(f2[key][:, 1:])}\")\n",
    "#             # print(f\"{key} : {f[key].attrs['Legend']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sxs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
