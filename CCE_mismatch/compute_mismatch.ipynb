{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9bd916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "import pickle\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import FindMismatch as FM\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scri\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.optimize import curve_fit\n",
    "from spherical_functions import LM_index as lm\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376d9ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average_valid(array,avg_len):\n",
    "    return np.convolve(array,np.ones(avg_len),'valid')/avg_len\n",
    "\n",
    "def load_and_pickle(data_path:Path, reload_data:bool=False, data_type:str='abd', options:dict={}):\n",
    "  if not data_path.exists():\n",
    "    raise Exception(f\"{data_path} does not exist!\")\n",
    "\n",
    "  saved_data_path = data_path.parent/\"saved.pkl\"\n",
    "  \n",
    "  if saved_data_path.exists() and reload_data == False:\n",
    "    with open(saved_data_path, 'rb') as f:\n",
    "      saved_data = pickle.load(f)\n",
    "      print(f\"Saved data loaded: {saved_data_path}\")\n",
    "  else:\n",
    "    saved_data = {}\n",
    "    if data_type == 'abd':\n",
    "      saved_data['abd']= scri.create_abd_from_h5(\n",
    "          file_name=str(data_path),\n",
    "          file_format=\"spectrecce_v1\",\n",
    "          **options\n",
    "        )\n",
    "      with open(saved_data_path, 'wb') as f:\n",
    "        pickle.dump(saved_data,f)\n",
    "      print(f\"Data loaded and saved at : {saved_data_path}\")\n",
    "\n",
    "  return saved_data\n",
    "\n",
    "def load_bondi_constraints(data_path:Path):\n",
    "  if not data_path.exists():\n",
    "    raise Exception(f\"{data_path} does not exist!\")\n",
    "  saved_data_path = data_path.parent/\"saved.pkl\"\n",
    "  if not saved_data_path.exists():\n",
    "    raise Exception(f\"{saved_data_path} does not exist\")\n",
    "  else:\n",
    "    with open(saved_data_path, 'rb') as f:\n",
    "      saved_data = pickle.load(f)\n",
    "      if 'bondi_violation_norms' in saved_data:\n",
    "        print(f\"bondi_violation_norms loaded for {data_path}\")\n",
    "      else:\n",
    "        print(f\"Computing bondi_violation_norms for: {data_path}\")\n",
    "        saved_data['bondi_violation_norms'] = saved_data['abd'].bondi_violation_norms\n",
    "        with open(saved_data_path, 'wb') as f:\n",
    "          pickle.dump(saved_data,f)\n",
    "\n",
    "        print(f\"Saved bondi_violation_norms for: {data_path}\")\n",
    "    return saved_data\n",
    "\n",
    "def add_bondi_constraints(abd_data:dict):\n",
    "  for key in abd_data:\n",
    "    abd_data[key]['bondi_violation_norms'] = abd_data[key][\"abd\"].bondi_violation_norms\n",
    "    print(f\"bondi_violation_norms computed for {key}\")\n",
    "\n",
    "def create_diff_dict_cce(WT_data_dict:dict, l:int, m:int, base_key:str, t_interpolate:np.ndarray):\n",
    "  h = WT_data_dict[base_key]['abd'].h.interpolate(t_interpolate)\n",
    "  diff_dict = {\"t\": h.t}\n",
    "  y_base = h.data[:,  lm(l,m,h.ell_min)]\n",
    "  y_norm = np.linalg.norm(y_base)\n",
    "  for key in WT_data_dict:\n",
    "    if key == base_key:\n",
    "      continue\n",
    "    h = WT_data_dict[key]['abd'].h.interpolate(t_interpolate)\n",
    "    y_inter = h.data[:,  lm(l,m,h.ell_min)]\n",
    "    diff_dict[key+\"_diff\"] = y_inter-y_base\n",
    "    diff_dict[key+\"_absdiff\"] = np.abs(y_inter-y_base)\n",
    "    diff_dict[key+\"_rel_diff\"] = (y_inter-y_base)/y_norm\n",
    "    diff_dict[key+\"_rel_absdiff\"] = np.abs(y_inter-y_base)/y_norm\n",
    "  return diff_dict\n",
    "\n",
    "def extract_radii(h5_file_path:Path):\n",
    "  radii = set()\n",
    "  with h5py.File(h5_file_path,'r') as f:\n",
    "    names = []\n",
    "    f.visit(names.append)\n",
    "  for name in names:\n",
    "    if \"Version\" in name:\n",
    "      continue\n",
    "    radii.add(name[1:5])\n",
    "  radii = list(radii)\n",
    "  radii.sort()\n",
    "  return radii\n",
    "\n",
    "\n",
    "def generate_columns(num_cols:int,beta_type=False):\n",
    "  if beta_type:\n",
    "    num_cols = num_cols*2\n",
    "  L_max = int(np.sqrt((num_cols-1)/2))-1\n",
    "  # print(L_max,np.sqrt((num_cols-1)/2)-1)\n",
    "  col_names = ['t(M)']\n",
    "  for l in range(0,L_max+1):\n",
    "    for m in range(-l,l+1):\n",
    "      if beta_type:\n",
    "        if m==0:\n",
    "          col_names.append(f\"Re({l},{m})\")\n",
    "        elif m < 0:\n",
    "          continue\n",
    "        else:\n",
    "          col_names.append(f\"Re({l},{m})\")\n",
    "          col_names.append(f\"Im({l},{m})\")\n",
    "      else:\n",
    "        col_names.append(f\"Re({l},{m})\")\n",
    "        col_names.append(f\"Im({l},{m})\")\n",
    "  return col_names\n",
    "\n",
    "\n",
    "def WT_to_pandas(horizon_path:Path):\n",
    "    assert(horizon_path.exists())\n",
    "    df_dict = {}\n",
    "    beta_type_list = ['Beta.dat', 'DuR.dat', 'R.dat', 'W.dat']\n",
    "    with h5py.File(horizon_path,'r') as hf:\n",
    "        # Not all horizon files may have AhC\n",
    "        for key in hf.keys():\n",
    "            if key == \"VersionHist.ver\":\n",
    "              continue \n",
    "            if key in beta_type_list:\n",
    "              df_dict[key] = pd.DataFrame(hf[key], columns=generate_columns(hf[key].shape[1],beta_type=True))\n",
    "            else:\n",
    "              df_dict[key] = pd.DataFrame(hf[key], columns=generate_columns(hf[key].shape[1]))\n",
    "\n",
    "\n",
    "    return df_dict\n",
    "\n",
    "\n",
    "def create_diff_dict(WT_data_dict:dict, mode:str, variable:str, base_key:str):\n",
    "  diff_dict = {\"t(M)\":WT_data_dict[base_key][variable]['t(M)']}\n",
    "  y_base = WT_data_dict[base_key][variable][mode]\n",
    "  y_norm = np.linalg.norm(y_base)\n",
    "  for key in WT_data_dict:\n",
    "    if key == base_key:\n",
    "      continue\n",
    "    y = WT_data_dict[key][variable][mode]\n",
    "    t = WT_data_dict[key][variable]['t(M)']\n",
    "    y_interpolator = interp1d(t, y, kind='cubic',fill_value='extrapolate')\n",
    "    y_inter = y_interpolator(diff_dict['t(M)'])\n",
    "    diff_dict[key+\"_diff\"] = y_inter-y_base\n",
    "    diff_dict[key+\"_absdiff\"] = np.abs(y_inter-y_base)\n",
    "    diff_dict[key+\"_rel_diff\"] = (y_inter-y_base)/y_norm\n",
    "    diff_dict[key+\"_rel_absdiff\"] = np.abs(y_inter-y_base)/y_norm\n",
    "  return diff_dict\n",
    "\n",
    "def filter_by_regex(regex,col_list,exclude=False):\n",
    "  filtered_set = set()\n",
    "  if type(regex) is list:\n",
    "    for reg in regex:\n",
    "      for i in col_list:\n",
    "        if re.search(reg,i):\n",
    "          filtered_set.add(i)\n",
    "  else:\n",
    "    for i in col_list:\n",
    "      if re.search(regex,i):\n",
    "        filtered_set.add(i)\n",
    "\n",
    "  filtered_list = list(filtered_set)\n",
    "  if exclude:\n",
    "    col_list_copy = list(col_list.copy())\n",
    "    for i in filtered_list:\n",
    "      if i in col_list_copy:\n",
    "        col_list_copy.remove(i)\n",
    "    filtered_list = col_list_copy\n",
    "\n",
    "  # Restore the original order\n",
    "  filtered_original_ordered_list = []\n",
    "  for i in list(col_list):\n",
    "    if i in filtered_list:\n",
    "      filtered_original_ordered_list.append(i)\n",
    "  return filtered_original_ordered_list\n",
    "\n",
    "def limit_by_col_val(min_val,max_val,col_name,df):\n",
    "  filter = (df[col_name]>=min_val) &(df[col_name] <=max_val)\n",
    "  return df[filter]\n",
    "\n",
    "def abs_mean_value_upto_l(pd_series,L_max:int):\n",
    "  idx = pd_series.index\n",
    "  abs_cum_sum = 0\n",
    "  num = 0\n",
    "  for i in idx:\n",
    "    L = int(i.split(\",\")[0][3:])\n",
    "    if L > L_max:\n",
    "      continue\n",
    "    else:\n",
    "      abs_cum_sum = abs_cum_sum+abs(pd_series[i])\n",
    "      num = num +1\n",
    "  return abs_cum_sum/num\n",
    "\n",
    "def get_mode(name):\n",
    "  return int(name.split(\"(\")[-1].split(\")\")[0])\n",
    "def get_radii(name):\n",
    "  if name[-5]=='R':\n",
    "    # R0257 -> 0257load_and_pickle\n",
    "    return int(name.split('_')[-1][1:])\n",
    "  else:\n",
    "    return int(name.split('_')[-1])\n",
    "def sort_by_power_modes(col_names):\n",
    "  col_name_copy = list(col_names).copy()\n",
    "  return sorted(col_name_copy, key=lambda x: int(get_mode(x)))\n",
    "\n",
    "def add_L_mode_power(df:pd.DataFrame,L:int, ReOrIm:str):\n",
    "  column_names = df.columns\n",
    "  n = 0\n",
    "  power = 0\n",
    "  for m in range(-L,L+1):\n",
    "    col_name = f'{ReOrIm}({L},{m})'\n",
    "    # print(col_name)\n",
    "    if col_name in column_names:\n",
    "      power = power + df[col_name]*df[col_name]\n",
    "      n = n + 1\n",
    "  if n != 0:\n",
    "    power = power/n\n",
    "    df[f'pow_{ReOrIm}({L})'] = power\n",
    "  return power\n",
    "\n",
    "def add_all_L_mode_power(df:pd.DataFrame,L_max:int):\n",
    "  local_df = df.copy()\n",
    "  total_power_Re = 0\n",
    "  total_power_Im = 0\n",
    "  for l in range(0,L_max+1):\n",
    "    total_power_Re = total_power_Re + add_L_mode_power(local_df,l,\"Re\")\n",
    "    total_power_Im = total_power_Im + add_L_mode_power(local_df,l,\"Im\")\n",
    "    local_df[f\"pow_cum_Re({l})\"] = total_power_Re\n",
    "    local_df[f\"pow_cum_Im({l})\"] = total_power_Im\n",
    "  return local_df\n",
    "\n",
    "\n",
    "def create_power_diff_dict(power_dict:dict, pow_mode:str, variable:str, base_key:str):\n",
    "  diff_dict = {\"t(M)\":power_dict[base_key]['t(M)']}\n",
    "  y_base = power_dict[base_key][variable][pow_mode]\n",
    "  y_norm = np.linalg.norm(y_base)\n",
    "  for key in power_dict:\n",
    "    if key == base_key:\n",
    "      continue\n",
    "    y = power_dict[key][variable][pow_mode]\n",
    "    t = power_dict[key]['t(M)']\n",
    "    y_interpolator = interp1d(t, y, kind='cubic',fill_value='extrapolate')\n",
    "    y_inter = y_interpolator(diff_dict['t(M)'])\n",
    "    diff_dict[key+\"_diff\"] = y_inter-y_base\n",
    "    diff_dict[key+\"_absdiff\"] = np.abs(y_inter-y_base)\n",
    "    diff_dict[key+\"_rel_diff\"] = (y_inter-y_base)/y_norm\n",
    "    diff_dict[key+\"_rel_absdiff\"] = np.abs(y_inter-y_base)/y_norm\n",
    "  return diff_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fc4e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cce_data = {}\n",
    "# cce_data[\"high_accuracy_Lev0_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev0/BondiCceR0257/red_cce.h5\")\n",
    "# cce_data[\"high_accuracy_Lev1_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev1/BondiCceR0257/red_cce.h5\")\n",
    "# cce_data[\"high_accuracy_Lev2_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev2/BondiCceR0257/red_cce.h5\")\n",
    "# cce_data[\"high_accuracy_Lev3_R0258\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/GW_data_lev3/BondiCceR0258/red_cce.h5\")\n",
    "# cce_data[\"high_accuracy_Lev4_R0258\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/GW_data_lev4/BondiCceR0258/red_cce.h5\")\n",
    "# cce_data[\"high_accuracy_Lev5_R0258\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/GW_data_lev5/BondiCceR0258/red_cce.h5\")\n",
    "# cce_data[\"high_accuracy_Lev3_R0472\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/GW_data_lev3/BondiCceR0472/red_cce.h5\")\n",
    "# cce_data[\"high_accuracy_Lev4_R0472\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/GW_data_lev4/BondiCceR0472/red_cce.h5\")\n",
    "# cce_data[\"high_accuracy_Lev5_R0472\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/Ev/GW_data_lev5/BondiCceR0472/red_cce.h5\")\n",
    "# cce_data[\"master_Lev0_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev/GW_data/BondiCceR0257/red_cce.h5\")\n",
    "# cce_data[\"master_Lev1_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev/GW_data_lev1/BondiCceR0257/red_cce.h5\")\n",
    "# cce_data[\"master_Lev2_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev/GW_data_lev2/BondiCceR0257/red_cce.h5\")\n",
    "# cce_data[\"master_Lev3_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_master/Ev/GW_data_lev3/BondiCceR0257/red_cce.h5\")\n",
    "# cce_data[\"master_Lev4_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_master/Ev/GW_data_lev4/BondiCceR0257/red_cce.h5\")\n",
    "# cce_data[\"master_Lev5_R0257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_master/Ev/GW_data_lev5/BondiCceR0257/red_cce.h5\")\n",
    "# cce_data[\"Lev5_bg_ah100_cd_01_uamr_full_R0258\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_bg_ah100_cd_01_uamr_full/GW_data/BondiCceR0258/red_cce.h5\")\n",
    "# cce_data[\"Lev5_bg_ah100_cd_01_uamr_full_R0686\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_bg_ah100_cd_01_uamr_full/GW_data/BondiCceR0686/red_cce.h5\")\n",
    "# cce_data[\"Lev5_bg_ah100_lapse_uamr_fullR0258\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_bg_ah100_lapse_uamr_full/GW_data/BondiCceR0258/red_cce.h5\")\n",
    "# cce_data[\"Lev5_bg_ah100_lapse_uamr_full_R0100\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35_variations/Lev5_bg_ah100_lapse_uamr_full/GW_data/BondiCceR0100/red_cce.h5\")\n",
    "# cce_data[\"high_accuracy_Lev5_R0258_ZeroNonSmooth\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/ZeroNonSmooth/red_Lev5_R0258_VolumeData.h5\")\n",
    "# cce_data[\"high_accuracy_Lev5_R0258_NoIncomingRadiation\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/NoIncomingRadiation/red_Lev5_R0258_VolumeData.h5\")\n",
    "# cce_data[\"high_accuracy_Lev5_R0258_InverseCubic\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/InverseCubic/red_Lev5_R0258_VolumeData.h5\")\n",
    "# cce_data[\"high_accuracy_Lev5_R0258_ConformalFactor10\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/ConformalFactor10/red_Lev5_R0258_VolumeData.h5\")\n",
    "# cce_data[\"high_accuracy_Lev5_R0258_ConformalFactor7\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/ConformalFactor7/red_Lev5_R0258_VolumeData.h5\")\n",
    "# cce_data[\"high_accuracy_Lev5_R0258_ConformalFactor3\"] = Path(\"/groups/sxs/hchaudha/spec_runs/high_accuracy_L35/cce_bondi/Lev5_variations/initial_data/ConformalFactor3/red_Lev5_R0258_VolumeData.h5\")\n",
    "\n",
    "# cce_data[\"Lev01_test_ode_Lev2_257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev2/BondiCceR0257/red_cce.h5\")\n",
    "# cce_data[\"Lev01_test_ode_Lev1_257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/new_ode_tol/high_accuracy_L35/Ev/GW_data_lev1/BondiCceR0257/red_cce.h5\")\n",
    "\n",
    "# cce_data[\"Lev01_test_Lev2_257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev/GW_data_lev2/BondiCceR0257/red_cce.h5\")\n",
    "\n",
    "# cce_data[\"Lev01_test_Lev2_257\"] = Path(\"/groups/sxs/hchaudha/spec_runs/Lev01_test/old_ode_tol/high_accuracy_L35_master/Ev/GW_data_lev2/BondiCceR0257/red_cce.h5\")\n",
    "\n",
    "# levs,run_sets,radius= [],[],[]\n",
    "levs = [0,1,2,3,4,5,6]\n",
    "# levs = [2,3,4,5,6]\n",
    "# levs = [4,5,6]\n",
    "# levs = [1,3,6]\n",
    "# levs = [1,2,3]\n",
    "# levs = [3]\n",
    "# levs = [5,6]\n",
    "# levs = [6]\n",
    "run_sets = [1]\n",
    "radius = [250]\n",
    "radius = [350]\n",
    "# radius = [100,150,200,250,300,350,500,700,900]\n",
    "# radius = [150,200,250,300,350,500,700]\n",
    "# radius = [200,250,300,350,500]\n",
    "for l, s, r in itertools.product(levs, run_sets, radius):\n",
    "    if s == 2 and (l == 0 or l == 1):\n",
    "        continue\n",
    "    if l <= 3:\n",
    "        if s == 1:\n",
    "            cce_data[f\"6_set{s}_L6s{l}_{r}\"] = Path(\n",
    "                f\"/groups/sxs/hchaudha/spec_runs/6_segs/6_set{s}_L6/GW_data_lev{l}/BondiCceR0{r}/red_cce.h5\"\n",
    "            )\n",
    "            cce_data[f\"6_set{s}_L3s{l}_{r}\"] = Path(\n",
    "                f\"/groups/sxs/hchaudha/spec_runs/6_segs/6_set{s}_L3/GW_data_lev{l}/BondiCceR0{r}/red_cce.h5\"\n",
    "            )\n",
    "    else:\n",
    "        cce_data[f\"6_set{s}_L6s{l}_{r}\"] = Path(\n",
    "            f\"/groups/sxs/hchaudha/spec_runs/6_segs/6_set{s}_L6/GW_data_lev{l}/BondiCceR0{r}/red_cce.h5\"\n",
    "        )\n",
    "        pass\n",
    "\n",
    "\n",
    "# cce_data[f\"6_set1_L6s3_CAMR_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/6_segs/6_set1_L6_vars/L6s3_CAMR/GW_data_lev3/BondiCceR0{r}/red_cce.h5\")\n",
    "# cce_data[f\"6_set1_L6s3_min_L_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/6_segs/6_set1_L6_vars/L6s3_min_L/GW_data_lev3/BondiCceR0{r}/red_cce.h5\")\n",
    "\n",
    "# cce_data[f\"7_constAMR_set1_L6_base_{l}_{r}\"] =  Path(f\"/groups/sxs/hchaudha/spec_runs/7_constAMR_set1_L6_base/GW_data_lev{l}/BondiCceR0{r}/red_cce.h5/\")\n",
    "\n",
    "# cce_data[f\"10_4000M_CAMR_set1_L6_base_{l}_{r}\"] =  Path(f\"/groups/sxs/hchaudha/spec_runs/10_4000M_CAMR_set1_L6_base/GW_data_lev{l}/BondiCceR0{r}/red_cce.h5/\")\n",
    "# cce_data[f\"11_4000M_CAMR_set1_L6_maxExt_{l}_{r}\"] =  Path(f\"/groups/sxs/hchaudha/spec_runs/11_4000M_CAMR_set1_L6_maxExt/GW_data_lev{l}/BondiCceR0{r}/red_cce.h5/\")\n",
    "\n",
    "# cce_data[f\"6_set1_L3s3_3\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/6_segs/6_set1_L3/GW_data_lev2/BondiCceR0250/red_cce.h5\")\n",
    "\n",
    "# radius_list = []\n",
    "# radius_list = ['0100','0150','0200','0250','0300','0350','0500','0700','0900','1100','1300','1400']\n",
    "# radius_list = ['0250','0300','0350','0500','0700']\n",
    "# for r in radius_list:\n",
    "#   cce_data[f\"12_set1_L3_1500_{r}\"] =  Path(f\"/groups/sxs/hchaudha/spec_runs/12_set1_L3_1500/GW_data_lev3/BondiCceR{r}/red_cce.h5/\")\n",
    "\n",
    "# radius_list = []\n",
    "# radius_list = ['0100','0150','0200','0250','0300','0350','0500','0700','0900','1100','1300','1500','1700','1900']\n",
    "# radius_list = ['0200','0250','0300','0350','0500','0700']\n",
    "# for r in radius_list:\n",
    "#   cce_data[f\"12_set1_L3_2000_{r}\"] =  Path(f\"/groups/sxs/hchaudha/spec_runs/12_set1_L3_2000/GW_data_lev3/BondiCceR{r}/red_cce.h5/\")\n",
    "\n",
    "# radius_list = []\n",
    "# radius_list = ['0100','0150','0200','0250','0300','0350','0500','0700','0900','1100','1300','1500','1700','1900','2100','2300']\n",
    "# radius_list = ['0200','0250','0300','0350','0500','0700']\n",
    "# for r in radius_list:\n",
    "#   cce_data[f\"12_set1_L3_2500_{r}\"] =  Path(f\"/groups/sxs/hchaudha/spec_runs/12_set1_L3_2500/GW_data_lev3/BondiCceR{r}/red_cce.h5/\")\n",
    "\n",
    "# radius_list = []\n",
    "# radius_list = ['0100', '0150', '0200', '0250', '0300', '0350', '0400', '0500', '0600', '0700', '0800', '0900', '1000', '1100', '1200', '1300', '1400', '1500', '1600', '1700', '1800', '1900', '2000', '2100', '2200', '2300', '2400', '2500', '2600', '2700', '2800', '2900']\n",
    "# # radius_list = ['0250','0300','0350','0500','0700']\n",
    "# for r in radius_list:\n",
    "#   cce_data[f\"13_set1_L3_3000_{r}\"] =  Path(f\"/groups/sxs/hchaudha/spec_runs/13_set1_L3_3000/GW_data_lev3/BondiCceR{r}/red_cce.h5/\")\n",
    "\n",
    "# radius_list = []\n",
    "# radius_list = ['0100', '0150', '0200', '0250', '0300', '0350', '0400', '0500', '0600', '0700', '0800', '0900', '1000', '1100', '1200', '1300', '1400']\n",
    "# radius_list = ['0200','0250','0300','0350','0500','0700']\n",
    "# for r in radius_list:\n",
    "#   cce_data[f\"13_set1_L4_1500_{r}\"] =  Path(f\"/groups/sxs/hchaudha/spec_runs/13_set1_L4_1500/GW_data_lev4/BondiCceR{r}/red_cce.h5/\")\n",
    "\n",
    "# radius_list = []\n",
    "# radius_list = ['0100', '0150', '0200', '0250', '0300', '0350', '0400', '0500', '0600', '0700', '0800', '0900', '1000', '1100', '1200', '1300', '1400', '1500', '1600', '1700', '1800', '1900', '2000', '2100', '2200', '2300', '2400', '2500', '2600', '2700', '2800', '2900']\n",
    "# radius_list = ['0200','0250','0300','0350','0500','0700']\n",
    "# for r in radius_list:\n",
    "#   cce_data[f\"13_set1_L4_3000_{r}\"] =  Path(f\"/groups/sxs/hchaudha/spec_runs/13_set1_L4_3000/GW_data_lev4/BondiCceR{r}/red_cce.h5/\")\n",
    "\n",
    "# radius_list = []\n",
    "# radius_list = ['0100', '0150', '0200', '0250', '0300', '0350', '0400', '0500', '0600', '0700', '0800', '0900']\n",
    "# for r in radius_list:\n",
    "#   cce_data[f\"16_set1_L3_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/16_set1_L3/GW_data_lev3/BondiCceR{r}/red_cce.h5\")\n",
    "#   cce_data[f\"16_set1_L3_HP32_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/16_set1_L3_HP32/GW_data_lev3/BondiCceR{r}/red_cce.h5\")\n",
    "#   cce_data[f\"16_set1_L3_HP28_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/16_set1_L3_HP28/GW_data_lev3/BondiCceR{r}/red_cce.h5\")\n",
    "#   cce_data[f\"16_set1_L3_HP32_AF_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/16_set1_L3_HP32_AF/GW_data_lev3/BondiCceR{r}/red_cce.h5\")\n",
    "\n",
    "# radius_list = []\n",
    "# radius_list = ['0258', '0472', '0686', '0900']\n",
    "# for r in radius_list:\n",
    "#   cce_data[f\"17_main_9_18_L3_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/17_main_9_18_L3/GW_data_lev3/BondiCceR{r}/red_cce.h5\")\n",
    "\n",
    "# radius_list = []\n",
    "# radius_list = ['0258', '0469', '0679', '0890']\n",
    "# for r in radius_list:\n",
    "#   cce_data[f\"17_set_main_q3_18_L3_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/17_set_main_q3_18_L3/GW_data_lev3/BondiCceR{r}/red_cce.h5\")\n",
    "\n",
    "# radius_list = []\n",
    "# radius_list = ['0199', '0353', '0506', '0660']\n",
    "# for r in radius_list:\n",
    "#   cce_data[f\"17_set_main_q3_15_L3_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/17_set_main_q3_15_L3/GW_data_lev3/BondiCceR{r}/red_cce.h5\")\n",
    "\n",
    "# radius_list = []\n",
    "# radius_list = ['0100', '0150', '0200', '0250', '0300', '0350', '0500', '0700', '0900']\n",
    "# radius_list = [ '0300', '0250', '0350','0200']\n",
    "# radius_list = [ '0350']\n",
    "# for r in radius_list:\n",
    "#   cce_data[f\"17_set1_q3_18_L3_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/17_set1_q3_18_L3/GW_data_lev3/BondiCceR{r}/red_cce.h5\")\n",
    "#   cce_data[f\"17_set3_q3_18_L3_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/17_set3_q3_18_L3/GW_data_lev3/BondiCceR{r}/red_cce.h5\")\n",
    "#   cce_data[f\"17_set1_9_18_L3_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/17_set1_9_18_L3/GW_data_lev3/BondiCceR{r}/red_cce.h5\")\n",
    "#   cce_data[f\"17_set3_9_18_L3_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/17_set3_9_18_L3/GW_data_lev3/BondiCceR{r}/red_cce.h5\")\n",
    "#   cce_data[f\"22_set1_L1_long_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/22_set1_L1_long/GW_data_lev1/BondiCceR{r}/red_cce.h5\")\n",
    "#   cce_data[f\"22_set1_L3_long_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/22_set1_L3_long/GW_data_lev3/BondiCceR{r}/red_cce.h5\")\n",
    "#   cce_data[f\"22_L3_AC_L3_no_res_C_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/22_segs/L3_AC_L3_no_res_C/GW_data_lev3/BondiCceR{r}/red_cce.h5\")\n",
    "#   cce_data[f\"22_L3_AC_L3_res_10_C_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/22_segs/L3_AC_L3_res_10_C/GW_data_lev3/BondiCceR{r}/red_cce.h5\")\n",
    "\n",
    "#   cce_data[f\"L1_AC_L2_long_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/22_segs/L1_AC_L2/GW_data_lev2/BondiCceR{r}/red_cce.h5\")\n",
    "#   cce_data[f\"L1_AC_L3_long_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/22_segs/L1_AC_L3/GW_data_lev3/BondiCceR{r}/red_cce.h5\")\n",
    "#   cce_data[f\"L3_AC_L1_long_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/22_segs/L3_AC_L1/GW_data_lev1/BondiCceR{r}/red_cce.h5\")\n",
    "#   cce_data[f\"L3_AC_L2_long_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/22_segs/L3_AC_L2/GW_data_lev2/BondiCceR{r}/red_cce.h5\")\n",
    "#   cce_data[f\"L3_AC_L4_long_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/22_segs/L3_AC_L4/GW_data_lev4/BondiCceR{r}/red_cce.h5\")\n",
    "\n",
    "# levs,radius,start = [],[],[]\n",
    "# levs = [1,3]\n",
    "# levs = [3]\n",
    "# radius = ['0250', '0350']\n",
    "# radius = ['0350']\n",
    "# start = [3000,5000,7000,8000]\n",
    "# start = [3000,7000]\n",
    "# for l,r,s in itertools.product(levs,radius,start):\n",
    "#   cce_data[f\"L{l}_S{s}_r{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/22_cce_test/L{l}/start_{s}/BondiCceR{r}/red_cce.h5\")\n",
    "\n",
    "# levs,radius,start = [],[],[]\n",
    "# levs = ['_IC','_NIR','_ZNS','']\n",
    "# levs = ['_NIR','']\n",
    "# radius = ['0250', '0350']\n",
    "# radius = ['0350']\n",
    "# start = [0,500,1000,3000,7000]\n",
    "# start = [3000,7000]\n",
    "# for l,r,s in itertools.product(levs,radius,start):\n",
    "#   cce_data[f\"L3{l}_S{s}_r{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/22_cce_test/L3/start_{s}{l}/BondiCceR{r}/red_cce.h5\")\n",
    "\n",
    "# radius = ['0020','0035','0050','0075','0100','0150','0200','0250','0300','0400','0500','0600','0800','1000','1500','2000','2500',]\n",
    "# radius = ['0020','0050','0100','0200','0500','1000','1500','2000','2500',]\n",
    "# for r in radius:\n",
    "#   cce_data[f\"14_NIR_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/single_bh/20_zero_spin_AMR_L5_10000M/GW_data/long_16_2565_10000_14_NIR/BondiCceR{r}/red_cce.h5\")\n",
    "\n",
    "\n",
    "# radius = ['0012', '0050', '0112', '0200', '0312', '0450', '0612', '0800', '1012', '1250', '1512', '1800', '2112', '2450', '2812', '3200', '3612', '4050', '4512', '0003', '0004', '0005', '0006', '0007', '0008', '0009', '0010', '0015', '0020', '0030', '0075']\n",
    "# radius = sorted(['0050', '0112', '0200', '0612', '0800', '1012',  '1800',  '3200', '3612', '4050', '4512', '0006', '0020', '0075'])\n",
    "# radius = sorted(['0050', '0112', '0200', '0612', '0800', '1012',  '0006', '0010', '0015', '0020', '0030', '0075','1800',  '3200','4512'])\n",
    "# radius = ['0006']\n",
    "# for r in radius:\n",
    "#   cce_data[f\"ex_rad_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/single_bh_CCE/runs/radius_dependence/ex_rad_{r}/red_cce.h5\")\n",
    "\n",
    "# radius = [0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, 1800, 1900, 2000 ]\n",
    "# radius = [0, 100, 200, 300, 400, 500, 600]\n",
    "# for r in radius[::]:\n",
    "#   cce_data[f\"CF_350_start_{r}\"] = Path(f\"/groups/sxs/hchaudha/spec_runs/22_cce_test/L3_new_executable/runs/ConformalFactor_start_{r}/red_cce.h5\")\n",
    "\n",
    "# for i in Path(\"/groups/sxs/hchaudha/spec_runs/22_cce_test/L3_merged_data/runs\").glob(\"*/red_cce.h5\"):\n",
    "#     cce_data[i.parent.stem] = i\n",
    "# for i in Path(\"/groups/sxs/hchaudha/spec_runs/22_cce_test/L3_merged_data/runs\").glob(\"Delta*/red_cce.h5\"):\n",
    "#     cce_data[i.parent.stem] = i\n",
    "\n",
    "# for i in Path(\"/resnick/groups/sxs/hchaudha/spec_runs/22_cce_test/runs/CF_0\").glob(\n",
    "#     \"Delta*/red_cce.h5\"\n",
    "# ):\n",
    "#     cce_data[i.parent.stem] = i\n",
    "\n",
    "# for i in Path(\"/resnick/groups/sxs/hchaudha/spec_runs/22_set1_L3_long/GW_data_lev3_start_6000\").glob(\n",
    "#     \"BondiCceR*/red_cce.h5\"\n",
    "# ):\n",
    "#     cce_data[\"set1_L3_long_ST_6000M_\"+i.parent.stem[-4:]] = i\n",
    "\n",
    "# for i in Path(\"/resnick/groups/sxs/hchaudha/spec_runs/22_set1_L3_long/GW_data_lev3_start_4000\").glob(\n",
    "#     \"BondiCceR*/red_cce.h5\"\n",
    "# ):\n",
    "#     cce_data[\"set1_L3_long_ST_4000M_\"+i.parent.stem[-4:]] = i\n",
    "\n",
    "# for i in Path(\"/resnick/groups/sxs/hchaudha/spec_runs/22_set1_L3_long/GW_data_lev3_start_2000\").glob(\n",
    "#     \"BondiCceR*/red_cce.h5\"\n",
    "# ):\n",
    "#     cce_data[\"set1_L3_long_ST_2000M_\"+i.parent.stem[-4:]] = i\n",
    "\n",
    "# for i in Path(\"/resnick/groups/sxs/hchaudha/spec_runs/32_RM_set1_L3/GW_data_lev3\").glob(\n",
    "#     \"BondiCceR*/red_cce.h5\"\n",
    "# ):\n",
    "#     cce_data[\"32_RM_set1_L3_\"+i.parent.stem[-4:]] = i\n",
    "\n",
    "\n",
    "def include_radii(name, min, max):\n",
    "    radius = int(name[-4:])\n",
    "    if radius < min or radius > max:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "# for i in Path(\"/resnick/groups/sxs/hchaudha/spec_runs/\").glob(\"29_set1_L3_ID_diff_?/GW_data_lev3/BondiCceR*/red_cce.h5\"):\n",
    "#     if not include_radii(i.parent.stem, 210, 260):\n",
    "#         continue\n",
    "#     cce_data[f\"{str(i).split('/')[-4]}_\"+i.parent.stem[-4:]] = i\n",
    "\n",
    "# for i in Path(\"/resnick/groups/sxs/hchaudha/spec_runs/31_segs/L1s3_cdg1_250/GW_data_lev3\").glob(\n",
    "#     \"BondiCceR*/red_cce.h5\"\n",
    "# ):\n",
    "#     if not include_radii(i.parent.stem, 200, 400):\n",
    "#         continue\n",
    "#     cce_data[\"32_RM_set1_L1s3_cdg1_250_\"+i.parent.stem[-4:]] = i\n",
    "\n",
    "# for i in Path(\"/resnick/groups/sxs/hchaudha/spec_runs/31_segs/L1s3_cdg1_100/GW_data_lev3\").glob(\n",
    "#     \"BondiCceR*/red_cce.h5\"\n",
    "# ):\n",
    "#     if not include_radii(i.parent.stem, 200, 400):\n",
    "#         continue\n",
    "#     cce_data[\"32_RM_set1_L1s3_cdg1_100_\"+i.parent.stem[-4:]] = i\n",
    "\n",
    "# for i in Path(\"/resnick/groups/sxs/hchaudha/spec_runs/31_segs/L1s3_cdg1_10/GW_data_lev3\").glob(\n",
    "#     \"BondiCceR*/red_cce.h5\"\n",
    "# ):\n",
    "#     if not include_radii(i.parent.stem, 200, 400):\n",
    "#         continue\n",
    "#     cce_data[\"32_RM_set1_L1s3_cdg1_10_\"+i.parent.stem[-4:]] = i\n",
    "\n",
    "# for i in Path(\"/resnick/groups/sxs/hchaudha/spec_runs/31_segs/L1s3/GW_data_lev3\").glob(\n",
    "#     \"BondiCceR*/red_cce.h5\"\n",
    "# ):\n",
    "#     if not include_radii(i.parent.stem, 200, 400):\n",
    "#         continue\n",
    "#     cce_data[\"32_RM_set1_L1s3_\"+i.parent.stem[-4:]] = i\n",
    "# cce_data['6_12_250'] = Path(\"/resnick/groups/sxs/hchaudha/spec_runs/6_segs/6_set1_L6/GW_data_lev6_12/BondiCceR0250/red_cce.h5\")\n",
    "# cce_data['6_10_250'] = Path(\"/resnick/groups/sxs/hchaudha/spec_runs/6_segs/6_set1_L6/GW_data_lev6_10/BondiCceR0250/red_cce.h5\")\n",
    "# cce_data['BondiCceR0334'] = Path(\"/resnick/groups/sxs/hchaudha/spec_runs/CCE_stuff/Lev4_061CCE/BondiCceR0334/red_cce.h5\")\n",
    "# cce_data['BondiCceR0586'] = Path(\"/resnick/groups/sxs/hchaudha/spec_runs/CCE_stuff/Lev4_061CCE/BondiCceR0586/red_cce.h5\")\n",
    "# cce_data['BondiCceR0838'] = Path(\"/resnick/groups/sxs/hchaudha/spec_runs/CCE_stuff/Lev4_061CCE/BondiCceR0838/red_cce.h5\")\n",
    "# cce_data['BondiCceR1090'] = Path(\"/resnick/groups/sxs/hchaudha/spec_runs/CCE_stuff/Lev4_061CCE/BondiCceR0838/red_cce.h5\")\n",
    "\n",
    "\n",
    "# for i in Path(\n",
    "#     \"/resnick/groups/sxs/hchaudha/spec_runs/33_const_inn_dom_runs/set1_L3_Lmin18/GW_data_lev3\"\n",
    "# ).glob(\"BondiCceR*/red_cce.h5\"):\n",
    "#     if not include_radii(i.parent.stem, 240, 260):\n",
    "#         continue\n",
    "#     cce_data[\"set1_L3_Lmin18_\" + i.parent.stem[-4:]] = i\n",
    "\n",
    "# for i in Path(\n",
    "#     \"/resnick/groups/sxs/hchaudha/spec_runs/33_const_inn_dom_runs/set1_L3_Lmin20_Rn2/GW_data_lev3\"\n",
    "# ).glob(\"BondiCceR*/red_cce.h5\"):\n",
    "#     if not include_radii(i.parent.stem, 240, 260):\n",
    "#         continue\n",
    "#     cce_data[\"set1_L3_Lmin20_Rn2_\" + i.parent.stem[-4:]] = i\n",
    "\n",
    "# for i in Path(\n",
    "#     \"/resnick/groups/sxs/hchaudha/spec_runs/33_const_inn_dom_runs/set1_L3_Rn1/GW_data_lev3\"\n",
    "# ).glob(\"BondiCceR*/red_cce.h5\"):\n",
    "#     if not include_radii(i.parent.stem, 240, 260):\n",
    "#         continue\n",
    "#     cce_data[\"set1_L3_Rn1_\" + i.parent.stem[-4:]] = i\n",
    "\n",
    "# for i in Path(\n",
    "#     \"/resnick/groups/sxs/hchaudha/spec_runs/33_const_inn_dom_runs/set1_L3_Rn2/GW_data_lev3\"\n",
    "# ).glob(\"BondiCceR*/red_cce.h5\"):\n",
    "#     if not include_radii(i.parent.stem, 240, 260):\n",
    "#         continue\n",
    "#     cce_data[\"set1_L3_Rn2_\" + i.parent.stem[-4:]] = i\n",
    "\n",
    "\n",
    "cce_data = dict(sorted(cce_data.items()))\n",
    "\n",
    "\n",
    "fail_flag = False\n",
    "for key in cce_data:\n",
    "    if not cce_data[key].exists():\n",
    "        fail_flag = True\n",
    "        print(f\"{cce_data[key]} does not exist!\")\n",
    "    if fail_flag:\n",
    "        raise Exception(\"Some paths do not exist!\")\n",
    "\n",
    "print(cce_data.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea264bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_interpolate = np.linspace(-1000,20000,num=2000)\n",
    "# t_interpolate = np.linspace(-1000,4000,num=5000)\n",
    "\n",
    "abd_data = {}\n",
    "failed_keys=  {}\n",
    "for key in cce_data:\n",
    "  try:\n",
    "    abd_data[key] = load_and_pickle(cce_data[key],options = {'t_interpolate':t_interpolate})\n",
    "    abd_data[key] = load_bondi_constraints(cce_data[key])\n",
    "  except Exception as e:\n",
    "    failed_keys[key] = str(e)\n",
    "    print(f\"Failed to load and pickle data for key {key}: {e}\")\n",
    "    continue\n",
    "\n",
    "print(abd_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778a36e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mismatch(abd_data:dict, key1,key2,t1,t2):\n",
    "    W1 = FM.abd_to_WM(abd_data[key1][\"abd\"])\n",
    "    W2 = FM.abd_to_WM(abd_data[key2][\"abd\"])\n",
    "    return FM.SquaredError(W1,W2,t1,t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7204220a",
   "metadata": {},
   "outputs": [],
   "source": [
    "WM_data = {\n",
    "    key: FM.abd_to_WM(abd_data[key][\"abd\"]) for key in abd_data\n",
    "}\n",
    "keys = list(WM_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00396ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = 1200\n",
    "t2 = 4000\n",
    "base_key = None\n",
    "modes = None\n",
    "\n",
    "# modes = 1\n",
    "\n",
    "print(f\"\\n| Key 1 | Key 2 | Squared Error {t1}:{t2}|\")\n",
    "print(\"|-------|-------|----------------|\")\n",
    "\n",
    "for i,j in zip(keys[:-1],keys[1:]):\n",
    "    mis_val =  FM.SquaredError(WM_data[i],WM_data[j], t1=t1, t2=t2,modes=modes)\n",
    "    print(f\"|{i} | {j} | {mis_val:.3e} |\")\n",
    "\n",
    "\n",
    "print(f\"\\n| Key 1 | Key 2 | Squared Error {t1}:{t2}|\")\n",
    "print(\"|-------|-------|----------------|\")\n",
    "if base_key is None:\n",
    "    base_key = keys[-1]\n",
    "for i in keys:\n",
    "    if i == base_key:\n",
    "        continue\n",
    "    mis_val =  FM.SquaredError(WM_data[i],WM_data[base_key], t1=t1, t2=t2,modes=modes)\n",
    "    print(f\"|{i} | {base_key} | {mis_val:.3e} |\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6a2ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = 1200\n",
    "t2 = 4000\n",
    "base_key = None\n",
    "modes = None\n",
    "\n",
    "# modes = 1\n",
    "\n",
    "print(f\"\\n| Key 1 | Key 2 | Squared Error {t1}:{t2}|\")\n",
    "print(\"|-------|-------|----------------|\")\n",
    "\n",
    "mismatch_dict = {}\n",
    "# for i,j in zip(keys[:-1],keys[1:]):\n",
    "\n",
    "sorted_keys = sorted(keys)\n",
    "for i,j in itertools.combinations(keys,2):\n",
    "    mis_val =  FM.SquaredError(WM_data[i],WM_data[j], t1=t1, t2=t2,modes=modes)\n",
    "    print(f\"|{i} | {j} | {mis_val:.3e} |\")\n",
    "    mismatch_dict[i+\"@\"+j] = mis_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c8918e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed6b66e",
   "metadata": {},
   "source": [
    "### How mismatch changes with the number of modes we consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c6cc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indices_of_a_mode(L,ell_min):\n",
    "    indices = []\n",
    "    if L < ell_min:\n",
    "        return indices\n",
    "    for m in range(-L,L+1):\n",
    "        indices.append(lm(L,m,ell_min))\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaf7e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = 1200\n",
    "t2 = 4000\n",
    "base_key = None\n",
    "\n",
    "print(f\"\\n| Key 1 | Key 2 | max_L_mode |Squared Error {t1}:{t2}|\")\n",
    "print(\"|-------|-------|-----|-----------|\")\n",
    "\n",
    "ell_min,_ = WM_data[keys[-1]].ells\n",
    "for i,j in zip(keys[:-1],keys[1:]):\n",
    "    print(\"|~|~|~|~|\")\n",
    "    indices_of_the_modes_to_include = []\n",
    "    for max_mode in range(ell_min,9):\n",
    "        indices_of_the_modes_to_include += indices_of_a_mode(max_mode,ell_min)\n",
    "        mis_val =  FM.SquaredError(WM_data[i],WM_data[j], t1=t1, t2=t2,modes=indices_of_the_modes_to_include)\n",
    "        print(f\"|{i} | {j} | {max_mode} |{mis_val:.3e} |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea05f71",
   "metadata": {},
   "source": [
    "#### Power in each L (absolute+missing a factor of 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de776db",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = 1200\n",
    "t2 = 4000\n",
    "base_key = None\n",
    "mode = None\n",
    "\n",
    "print(f\"\\n| Key 1 | Key 2 | L_mode | h1h2 {t1}:{t2} | h1h1 {t1}:{t2}  | Mismatch |\")\n",
    "print(\"|-------|-------|-----|-----|------|------|\")\n",
    "\n",
    "ell_min,_ = WM_data[keys[-1]].ells\n",
    "for i,j in zip(keys[:-1],keys[1:]):\n",
    "    print(\"|~|~|~|~|~|~|\")\n",
    "    indices_of_the_modes_to_include = []\n",
    "    for max_mode in range(ell_min,9):\n",
    "        indices_of_the_modes_to_include = indices_of_a_mode(max_mode,ell_min)\n",
    "        h1h2,h1h1 =  FM.SquaredError(WM_data[i],WM_data[j], t1=t1, t2=t2,modes=indices_of_the_modes_to_include, return_h1h2_h1h1=True)\n",
    "        print(f\"|{i} | {j} | {max_mode} |{h1h2:.3e} | {h1h1:.3e} | {0.5*h1h2/h1h1:.3e} |\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc45712",
   "metadata": {},
   "outputs": [],
   "source": [
    "key1 = \"6_set1_L6s6_300\"\n",
    "key2 = \"6_set1_L6s6_250\"\n",
    "W1 = WM_data[key1]\n",
    "W2 = WM_data[key2]\n",
    "t1,t2 = 1200,4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96308c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = FM.align2d(W1,W2,t1=1200,t2=2600,nprocs=4)\n",
    "# FM.align2d(W1,W2,t1=1200,t2=1600,include_modes=[(2,2)],nprocs=4)\n",
    "# print(result[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25d3dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# W1_alg = result[1]\n",
    "# FM.SquaredError(W1_alg,W2,t1=t1,t2=t2,mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c9d642",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1_al,W2_al = FM.fix_BMS_NRNR_t12(abd_data[key1][\"abd\"],abd_data[key2][\"abd\"],t1=1200,t2=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a81a7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "abd_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5787f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"6_set1_L6s6_250\"\n",
    "key = \"BondiCceR0334\"\n",
    "t_min = -1000\n",
    "t_max = 40000\n",
    "\n",
    "l,m = 2,2\n",
    "# l,m = 3,1\n",
    "abd_for_key = abd_data[key][\"abd\"]\n",
    "var = abd_for_key.sigma.bar\n",
    "\n",
    "t = abd_for_key.t\n",
    "filtered_indices = (t<t_max) & (t>t_min)\n",
    "t = t[filtered_indices] \n",
    "a = var[filtered_indices, lm(l,m, var.ell_min)]\n",
    "plt.plot(t,np.real(np.array(a)), label=\"real\")\n",
    "plt.plot(t,np.imag(np.array(a)), label=\"imaginary\")\n",
    "plt.plot(t,np.abs(np.array(a)), label=\"abs\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51b5e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"6_set1_L6s6_250\"\n",
    "key = \"BondiCceR0334\"\n",
    "t_min = -1000\n",
    "t_max = 40000\n",
    "\n",
    "l,m = 2,2\n",
    "# l,m = 3,1\n",
    "\n",
    "for key in abd_data:\n",
    "    abd_for_key = abd_data[key][\"abd\"]\n",
    "    var = abd_for_key.sigma.bar\n",
    "\n",
    "    t = abd_for_key.t\n",
    "    filtered_indices = (t<t_max) & (t>t_min)\n",
    "    t = t[filtered_indices] \n",
    "    a = var[filtered_indices, lm(l,m, var.ell_min)]\n",
    "    # plt.plot(t,np.real(np.array(a)), label=\"real\")\n",
    "    # plt.plot(t,np.imag(np.array(a)), label=\"imaginary\")\n",
    "    plt.plot(t,np.abs(np.array(a)), label=f\"abs_{key}\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4a1bf4",
   "metadata": {},
   "source": [
    "### Power in modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7918470d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def power_in_mode(var, l):\n",
    "    power = np.array(np.array(var[:, lm(l, 0, var.ell_min)]))*0.0\n",
    "    for m in range(-l, l+1):\n",
    "        power += np.array(var[:, lm(l, m, var.ell_min)])**2\n",
    "    power = np.sqrt(power)/(2*l+1)\n",
    "    return power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbd47d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "abd_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f07ca6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"6_set1_L6s6_250\"\n",
    "# key = \"6_set1_L6s0_250\"\n",
    "key = \"BondiCceR0334\"\n",
    "# key = \"high_accuracy_Lev5_R0258\"\n",
    "# key = \"high_accuracy_Lev0_R0257\"\n",
    "running_avg_len_M = None\n",
    "# running_avg_len_M = 10 # in M\n",
    "\n",
    "t_min = 0\n",
    "# t_min = 200\n",
    "\n",
    "t_max = 40000\n",
    "t_max = 4000\n",
    "\n",
    "abd_for_key = abd_data[key][\"abd\"]\n",
    "var = abd_for_key.sigma.bar\n",
    "# var = abd_for_key.psi4\n",
    "# var = abd_for_key.psi2\n",
    "# var = abd_for_key.sigma.ddot\n",
    "t = abd_for_key.t\n",
    "filtered_indices = (t<t_max) & (t>t_min)\n",
    "t = t[filtered_indices] \n",
    "\n",
    "# l_max = 12\n",
    "# l_max = 10\n",
    "l_max = 8\n",
    "l_min = 2\n",
    "\n",
    "\n",
    "if running_avg_len_M is not None:\n",
    "    mean_dt = np.mean(t[1:]-t[:-1])\n",
    "    running_avg_len = int(running_avg_len_M/mean_dt)\n",
    "else:\n",
    "    running_avg_len = None\n",
    "for l in range(l_min,l_max+1):\n",
    "    a = power_in_mode(var, l)\n",
    "    a = np.array(a[filtered_indices])\n",
    "    if running_avg_len is not None:\n",
    "        a = np.convolve(a, np.ones(running_avg_len)/running_avg_len, mode='valid')\n",
    "        t_trunc = t[running_avg_len-1:]\n",
    "    else:\n",
    "        a = np.array(a)\n",
    "        t_trunc = t\n",
    "    # plt.plot(t_trunc,np.real(a), label=f\"real_{l}\")\n",
    "    # plt.plot(t_trunc,np.imag(a), label=f\"imaginary_{l}\")\n",
    "    plt.plot(t_trunc,np.abs(a), label=f\"abs_{l}\")\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"Power\")\n",
    "if running_avg_len is not None:\n",
    "    plt.title(f\"{key} : avg_win_len={running_avg_len_M}M, {running_avg_len}\")\n",
    "else:\n",
    "    plt.title(f\"{key}\")\n",
    "plt.legend()\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ea8275",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def find_noise(arr, window=10):\n",
    "    arr = np.asanyarray(arr, dtype=float)\n",
    "    n = arr.size\n",
    "    if n < window:\n",
    "        # Not enough points to form a single window\n",
    "        return np.full(n, np.nan)\n",
    "\n",
    "    # Build a 1-element longer cumulative sum array:\n",
    "    #   cumsum[k] = sum(arr[0:k])\n",
    "    cumsum = np.empty(n + 1, dtype=float)\n",
    "    cumsum[0] = 0.0\n",
    "    cumsum[1:] = np.cumsum(arr)  # numpy.cumsum: cumulative sum of array :contentReference[oaicite:0]{index=0}\n",
    "\n",
    "    # running_mean[i] = (arr[i–window+1] + … + arr[i]) / window\n",
    "    # corresponds to (cumsum[i+1] – cumsum[i+1–window]) / window\n",
    "    cumdiff = cumsum[window:] - cumsum[:-window]\n",
    "    running_mean = cumdiff / window\n",
    "\n",
    "    # Allocate output and pad front with NaNs:\n",
    "    noise = np.empty_like(arr)\n",
    "    noise[:window-1] = np.nan\n",
    "    noise[window-1:] = np.abs(arr[window-1:] - running_mean)\n",
    "\n",
    "    return noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ceb44cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(find_noise(np.real(np.array(a)), window=50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbc1a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "W2_spline = FM.SplineArray(W2.t, W2.data)\n",
    "matchingt = W1.t[(W1.t >= t1) & (W1.t <= t2)]\n",
    "h1h2 = np.sum(\n",
    "    sp.integrate.simpson(\n",
    "        abs(W2_spline(matchingt) - W1.data[(W1.t >= t1) & (W1.t <= t2), :]) ** 2.0,\n",
    "        matchingt,\n",
    "        axis=0,\n",
    "    )\n",
    ")\n",
    "h1h1 = np.sum(\n",
    "    sp.integrate.simpson(\n",
    "        abs(W1.data[(W1.t >= t1) & (W1.t <= t2), :]) ** 2.0, matchingt, axis=0\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c7af96",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1h2 = np.sum(\n",
    "    sp.integrate.simpson(\n",
    "        abs(W2_spline(matchingt) - W1.data[(W1.t >= t1) & (W1.t <= t2), :]) ** 2.0,\n",
    "        x=matchingt,\n",
    "        axis=0,\n",
    "    )\n",
    ")\n",
    "h1h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d31ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1h2 = np.sum(\n",
    "    sp.integrate.cumulative_simpson(\n",
    "        abs(W2_spline(matchingt) - W1.data[(W1.t >= t1) & (W1.t <= t2), :]) ** 2.0,\n",
    "        x=matchingt,\n",
    "        axis=0,\n",
    "    )\n",
    ")\n",
    "h1h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aadfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_arr = []\n",
    "mis_val_arr = []\n",
    "for i in range(3,10):\n",
    "    t2 = i*500\n",
    "    mis_val = find_mismatch(abd_data,'6_set1_L6s6_250','6_set1_L6s5_250',1200,t2)\n",
    "    t2_arr.append(t2)\n",
    "    mis_val_arr.append(mis_val)\n",
    "    print(f\"{t2}: {mis_val}\")\n",
    "plt.plot(t2_arr,mis_val_arr, label=\"250\")\n",
    "\n",
    "t2_arr = []\n",
    "mis_val_arr = []\n",
    "for i in range(3,10):\n",
    "    t2 = i*500\n",
    "    mis_val = find_mismatch(abd_data,'6_set1_L6s6_500','6_set1_L6s5_500',1200,t2)\n",
    "    t2_arr.append(t2)\n",
    "    mis_val_arr.append(mis_val)\n",
    "    print(f\"{t2}: {mis_val}\")\n",
    "plt.plot(t2_arr,mis_val_arr, label=\"500\")\n",
    "plt.xlabel(\"window size\")\n",
    "plt.ylabel(\"Mismatch\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b5fb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "t2_arr = []\n",
    "mis_val_arr = []\n",
    "for i in range(3,20):\n",
    "    t2 = i*500\n",
    "    mis_val = find_mismatch(abd_data,'master_Lev3_R0257','master_Lev4_R0257',1200,t2)\n",
    "    # mis_val = find_mismatch(abd_data,'master_Lev5_R0257','master_Lev4_R0257',1200,t2)\n",
    "    t2_arr.append(t2)\n",
    "    mis_val_arr.append(mis_val)\n",
    "    print(f\"{t2}: {mis_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071f8505",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t2_arr,mis_val_arr)\n",
    "plt.yscale('log')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sxs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
