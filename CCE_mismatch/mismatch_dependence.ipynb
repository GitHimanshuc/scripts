{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c797f9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sxs\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "\n",
    "# sxs.write_config(download=True, cache=True, auto_supersede=False)\n",
    "sxs.read_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8713d8f",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591fb5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_levs(strings):\n",
    "    \"\"\"Extracts unique Lev references like Lev1, Lev2, etc., sorted by numeric value.\"\"\"\n",
    "    levs = set()\n",
    "    for s in strings:\n",
    "        found = re.findall(r\"Lev\\d+\", s)\n",
    "        levs.update(found)\n",
    "    # Sort by numeric part\n",
    "    return sorted(levs, key=lambda x: int(re.search(r\"\\d+\", x).group()))\n",
    "\n",
    "\n",
    "def get_center_diff(key, lev_low, lev_high):\n",
    "    high_lev = sxs.load(f\"{key}/Lev{lev_high}\").horizons\n",
    "    low_lev = sxs.load(f\"{key}/Lev{lev_low}\").horizons\n",
    "\n",
    "    t = low_lev.A.coord_center_inertial.time\n",
    "    diff_A = (\n",
    "        high_lev.A.coord_center_inertial.interpolate(t)\n",
    "        - low_lev.A.coord_center_inertial\n",
    "    )\n",
    "    int_diff_A = sp.integrate.simpson(np.linalg.norm(diff_A, axis=1), diff_A.time)\n",
    "\n",
    "    t = low_lev.B.coord_center_inertial.time\n",
    "    diff_B = (\n",
    "        high_lev.B.coord_center_inertial.interpolate(t)\n",
    "        - low_lev.B.coord_center_inertial\n",
    "    )\n",
    "    int_diff_B = sp.integrate.simpson(np.linalg.norm(diff_B, axis=1), diff_B.time)\n",
    "\n",
    "    return int_diff_A, int_diff_B\n",
    "\n",
    "\n",
    "def get_mismatch(key, mis_dict):\n",
    "    # First get the mismatch value\n",
    "    highest_two_levs = extract_levs(mis_dict[key].keys())[-2:]\n",
    "\n",
    "    # 4d version\n",
    "    # mismatch_key = f\"({highest_two_levs[0]}, {highest_two_levs[1]}) 4d\"\n",
    "    # mis_val = mis_dict[key][mismatch_key][\"mismatch\"]\n",
    "\n",
    "    # Non 4d version?\n",
    "    mismatch_key = f\"({highest_two_levs[0]}, {highest_two_levs[1]})\"\n",
    "    mis_val = mis_dict[key][mismatch_key]\n",
    "\n",
    "    return int(highest_two_levs[0][-1]), int(highest_two_levs[1][-1]), mis_val\n",
    "\n",
    "\n",
    "def get_mismatch_lev(key, mis_dict, lev_low, lev_high):\n",
    "    mismatch_key = f\"({lev_low}, {lev_high})\"\n",
    "    return mis_dict[key][mismatch_key]\n",
    "\n",
    "\n",
    "def get_mismatch_and_center_diff(key, mis_dict, min_lev=None):\n",
    "    lev_low, lev_high, mis_val = get_mismatch(key, mis_dict)\n",
    "    if min_lev is not None:\n",
    "        if lev_low < min_lev:\n",
    "            raise ValueError(\n",
    "                f\"Mismatch level {lev_low} is below minimum level {min_lev}.\"\n",
    "            )\n",
    "    int_diff_A, int_diff_B = get_center_diff(key, lev_low, lev_high)\n",
    "    return mis_val, int_diff_A, int_diff_B\n",
    "\n",
    "\n",
    "def get_mismatch_and_center_diff_between_levs(key, mis_dict, min_num_lev=3):\n",
    "    levs = extract_levs(mis_dict[key].keys())\n",
    "    if len(levs) < min_num_lev:\n",
    "        raise ValueError(\n",
    "            f\"Not enough levels for key {key}. Found {len(levs)}, expected at least {min_num_lev}.\"\n",
    "        )\n",
    "\n",
    "    mis_int_dict = {}\n",
    "    # Non 4d version\n",
    "    for low, high in zip(levs[:-1], levs[1:]):\n",
    "        key_levs = f\"({low}, {high})\"\n",
    "        mis_int_dict[key_levs] = {}\n",
    "        mis_int_dict[key_levs]['mismatch'] = mis_dict[key][key_levs]\n",
    "        int_diff_A, int_diff_B = get_center_diff(key, low[-1], high[-1])\n",
    "        mis_int_dict[key_levs][\"int_diff_A\"] = int_diff_A\n",
    "        mis_int_dict[key_levs][\"int_diff_B\"] = int_diff_B\n",
    "\n",
    "    return mis_int_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0a0bff",
   "metadata": {},
   "source": [
    "# Work Area"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1b9e70",
   "metadata": {},
   "source": [
    "## Load mismatch dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06299d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatch_data = Path(\"./data/data_mismatch.json\")\n",
    "if not mismatch_data.exists():\n",
    "    raise FileNotFoundError(f\"Data mismatch file not found: {mismatch_data}\")\n",
    "\n",
    "mis_dict = json.loads(mismatch_data.read_text())\n",
    "len(mis_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22aa2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_key = list(mis_dict.keys())[10]\n",
    "# base_key = 'SXS:BBH:1359'\n",
    "print(base_key)\n",
    "mis_dict[base_key].keys(), mis_dict[base_key]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59616b64",
   "metadata": {},
   "source": [
    "## Plot center diff vs mismatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981d6039",
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_arr = []\n",
    "center_diff_arr = []\n",
    "\n",
    "for key in list(mis_dict.keys())[::-1][:25]:\n",
    "    mis_val, int_diff_A, int_diff_B = get_mismatch_and_center_diff(key, mis_dict)\n",
    "    print(f\"{key}: {mis_val}, {int_diff_A:.3e}, {int_diff_B:.3e}\")\n",
    "    mis_arr.append(mis_val)\n",
    "    center_diff_arr.append(int_diff_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc4ef63",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter( center_diff_arr,mis_arr)\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd482d52",
   "metadata": {},
   "source": [
    "## Sxs catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56db5f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sxs.load(\"dataframe\", tag=\"3.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7980e2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = df.copy()\n",
    "\n",
    "fdf = fdf[fdf['reference_eccentricity'] < 1e-3]\n",
    "fdf = fdf[fdf['object_types'] == \"BHBH\"]\n",
    "fdf = fdf[fdf['common_horizon_time'] > 6000.0]\n",
    "# fdf = fdf[fdf['common_horizon_time'] < 200000.0]\n",
    "fdf = fdf[fdf['reference_mass_ratio'] < 5]\n",
    "fdf = fdf[fdf['reference_dimensionless_spin1_mag'] < 0.4]\n",
    "fdf = fdf[fdf['reference_dimensionless_spin2_mag'] < 0.4]\n",
    "len(fdf['common_horizon_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0b2896",
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_arr = []\n",
    "center_diff_arr_A = []\n",
    "center_diff_arr_B = []\n",
    "\n",
    "min_lev = 3  # Minimum level to consider for mismatch\n",
    "\n",
    "for filtered_key in fdf.index.to_list():\n",
    "    if filtered_key not in mis_dict:\n",
    "        print(f\"Key {filtered_key} not found in mismatch data, skipping.\")\n",
    "        continue\n",
    "    try:\n",
    "        mis_val, int_diff_A, int_diff_B = get_mismatch_and_center_diff(filtered_key, mis_dict, min_lev=min_lev)\n",
    "    except Exception as e:\n",
    "        print(f\"KeyError for {filtered_key}: {e}, skipping.\")\n",
    "        continue\n",
    "    print(f\"{filtered_key}: {mis_val}, {int_diff_A:.3e}, {int_diff_B:.3e}\")\n",
    "    mis_arr.append(mis_val)\n",
    "    center_diff_arr_A.append(int_diff_A)\n",
    "    center_diff_arr_B.append(int_diff_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c1d848",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter( center_diff_arr_A,mis_arr)\n",
    "plt.ylabel(\"Mismatch\")\n",
    "plt.xlabel(\"Center Diff (A)\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8e84d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter( center_diff_arr_B,mis_arr)\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "plt.ylabel(\"Mismatch\")\n",
    "plt.xlabel(\"Center Diff (B)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fd5eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc['SXS:BBH:3864'].to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942b6c3b",
   "metadata": {},
   "source": [
    "### Lev trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22bf96b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sxs.load(\"dataframe\", tag=\"3.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff1b580",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = df.copy()\n",
    "\n",
    "fdf = fdf[fdf['reference_eccentricity'] < 1e-3]\n",
    "fdf = fdf[fdf['object_types'] == \"BHBH\"]\n",
    "fdf = fdf[fdf['common_horizon_time'] < 6000.0]\n",
    "# fdf = fdf[fdf['common_horizon_time'] < 200000.0]\n",
    "fdf = fdf[fdf['reference_mass_ratio'] < 2]\n",
    "fdf = fdf[fdf['reference_dimensionless_spin1_mag'] < 0.4]\n",
    "fdf = fdf[fdf['reference_dimensionless_spin2_mag'] < 0.4]\n",
    "len(fdf['common_horizon_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df4b275",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = {}\n",
    "min_num_lev = 4  # Minimum level to consider for mismatch\n",
    "\n",
    "for filtered_key in fdf.index.to_list():\n",
    "    if filtered_key not in mis_dict:\n",
    "        print(f\"Key {filtered_key} not found in mismatch data, skipping.\")\n",
    "        continue\n",
    "    try:\n",
    "        filtered_data[filtered_key] = get_mismatch_and_center_diff_between_levs(filtered_key, mis_dict, min_num_lev=min_num_lev)\n",
    "        print(f\"{filtered_key}: {filtered_data[filtered_key]}\")\n",
    "    except Exception as e:\n",
    "        # print(f\"KeyError for {filtered_key}: {e}, skipping.\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2ff75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'SXS:BBH:1132'\n",
    "key = 'SXS:BBH:0198'\n",
    "key = 'SXS:BBH:0310'\n",
    "key = 'SXS:BBH:3864'\n",
    "# key = 'SXS:BBH:4434'\n",
    "mis_int_dict = get_mismatch_and_center_diff_between_levs(key, mis_dict, min_num_lev=min_num_lev)\n",
    "x = [mis_int_dict[k]['int_diff_A'] for k in mis_int_dict]\n",
    "x = [mis_int_dict[k]['int_diff_B'] for k in mis_int_dict]\n",
    "y = [mis_int_dict[k]['mismatch'] for k in mis_int_dict]\n",
    "\n",
    "plt.scatter( x,y)\n",
    "plt.ylabel(\"Mismatch\")\n",
    "plt.xlabel(\"Center Diff (A)\")\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae9267a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_int_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859b6d28",
   "metadata": {},
   "source": [
    "## Merging time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6d21d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_dict(data, num_points_to_skip=10, skip_T_before_merger=1000):\n",
    "    horizon_data = data.A\n",
    "\n",
    "    common_horizon_time = horizon_data.time[-1]  # The merger time\n",
    "    interp_t = horizon_data.time[::num_points_to_skip]\n",
    "    interp_t = interp_t[interp_t < common_horizon_time - skip_T_before_merger]\n",
    "    time_to_merger = common_horizon_time - interp_t\n",
    "\n",
    "    areal_mass_change = np.array(\n",
    "        horizon_data.areal_mass.interpolate(interp_t) - horizon_data.areal_mass[0]\n",
    "    )\n",
    "    christodoulou_mass_change = np.array(\n",
    "        (\n",
    "            horizon_data.christodoulou_mass.interpolate(interp_t)\n",
    "            - horizon_data.christodoulou_mass[0]\n",
    "        )\n",
    "    )\n",
    "    chi_intertial = horizon_data.chi_inertial.interpolate(interp_t)\n",
    "    coord_center_inertial = horizon_data.coord_center_inertial.interpolate(interp_t)\n",
    "    dimensionful_inertial_spin = horizon_data.dimensionful_inertial_spin.interpolate(\n",
    "        interp_t\n",
    "    )\n",
    "\n",
    "    data_dict_A = {\n",
    "        \"A_areal_mass\": np.array(horizon_data.areal_mass.interpolate(interp_t)),\n",
    "        \"A_christodoulou_mass\": np.array(\n",
    "            horizon_data.christodoulou_mass.interpolate(interp_t)\n",
    "        ),\n",
    "        \"A_areal_mass_change\": areal_mass_change,\n",
    "        \"A_christodoulou_mass_change\": christodoulou_mass_change,\n",
    "        \"A_chi_inertial_x\": np.array(chi_intertial[:, 0]),\n",
    "        \"A_chi_inertial_y\": np.array(chi_intertial[:, 1]),\n",
    "        \"A_chi_inertial_z\": np.array(chi_intertial[:, 2]),\n",
    "        \"A_chi_inertial_mag\": np.linalg.norm(chi_intertial, axis=1),\n",
    "        \"A_coord_center_inertial_x\": np.array(coord_center_inertial[:, 0]),\n",
    "        \"A_coord_center_inertial_y\": np.array(coord_center_inertial[:, 1]),\n",
    "        \"A_coord_center_inertial_z\": np.array(coord_center_inertial[:, 2]),\n",
    "        \"A_dimensionful_inertial_spin_x\": np.array(dimensionful_inertial_spin[:, 0]),\n",
    "        \"A_dimensionful_inertial_spin_y\": np.array(dimensionful_inertial_spin[:, 1]),\n",
    "        \"A_dimensionful_inertial_spin_z\": np.array(dimensionful_inertial_spin[:, 2]),\n",
    "        \"A_dimensionful_inertial_spin_mag\": np.linalg.norm(\n",
    "            dimensionful_inertial_spin, axis=1\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    horizon_data = data.B\n",
    "\n",
    "    chi_intertial = horizon_data.chi_inertial.interpolate(interp_t)\n",
    "    coord_center_inertial = horizon_data.coord_center_inertial.interpolate(interp_t)\n",
    "    dimensionful_inertial_spin = horizon_data.dimensionful_inertial_spin.interpolate(\n",
    "        interp_t\n",
    "    )\n",
    "\n",
    "    areal_mass_change = np.array(\n",
    "        horizon_data.areal_mass.interpolate(interp_t) - horizon_data.areal_mass[0]\n",
    "    )\n",
    "    christodoulou_mass_change = np.array(\n",
    "        (\n",
    "            horizon_data.christodoulou_mass.interpolate(interp_t)\n",
    "            - horizon_data.christodoulou_mass[0]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    data_dict_B = {\n",
    "        \"B_areal_mass\": np.array(horizon_data.areal_mass.interpolate(interp_t)),\n",
    "        \"B_christodoulou_mass\": np.array(\n",
    "            horizon_data.christodoulou_mass.interpolate(interp_t)\n",
    "        ),\n",
    "        \"B_areal_mass_change\": areal_mass_change,\n",
    "        \"B_christodoulou_mass_change\": christodoulou_mass_change,\n",
    "        \"B_chi_inertial_x\": np.array(chi_intertial[:, 0]),\n",
    "        \"B_chi_inertial_y\": np.array(chi_intertial[:, 1]),\n",
    "        \"B_chi_inertial_z\": np.array(chi_intertial[:, 2]),\n",
    "        \"B_chi_inertial_mag\": np.linalg.norm(chi_intertial, axis=1),\n",
    "        \"B_coord_center_inertial_x\": np.array(coord_center_inertial[:, 0]),\n",
    "        \"B_coord_center_inertial_y\": np.array(coord_center_inertial[:, 1]),\n",
    "        \"B_coord_center_inertial_z\": np.array(coord_center_inertial[:, 2]),\n",
    "        \"B_dimensionful_inertial_spin_x\": np.array(dimensionful_inertial_spin[:, 0]),\n",
    "        \"B_dimensionful_inertial_spin_y\": np.array(dimensionful_inertial_spin[:, 1]),\n",
    "        \"B_dimensionful_inertial_spin_z\": np.array(dimensionful_inertial_spin[:, 2]),\n",
    "        \"B_dimensionful_inertial_spin_mag\": np.linalg.norm(\n",
    "            dimensionful_inertial_spin, axis=1\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    return {**data_dict_A, **data_dict_B, \"time_to_merger\": time_to_merger}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa241873",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sxs.load(\"dataframe\", tag=\"3.0.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ad0ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdf = df.copy()\n",
    "\n",
    "fdf = fdf[fdf['reference_eccentricity'] < 1e-3]\n",
    "fdf = fdf[fdf['object_types'] == \"BHBH\"]\n",
    "fdf = fdf[fdf['common_horizon_time'] > 6000.0]\n",
    "fdf = fdf[fdf['common_horizon_time'] < 20000.0]\n",
    "fdf = fdf[fdf['reference_mass_ratio'] < 5]\n",
    "fdf = fdf[fdf['reference_dimensionless_spin1_mag'] < 0.1]\n",
    "fdf = fdf[fdf['reference_dimensionless_spin2_mag'] < 0.1]\n",
    "len(fdf['common_horizon_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4517379f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_runs = fdf.index.to_list()\n",
    "data_dict = {}\n",
    "for i in filtered_runs:\n",
    "    try:\n",
    "        data_dict[i] = get_data_dict(sxs.load(i).horizons)\n",
    "        print(f\"Loaded data for {i}, len: {len(data_dict[i]['time_to_merger'])}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data for {i}\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb89deb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join all the data into a single DataFrame\n",
    "\n",
    "rows = []\n",
    "for run_name, subdict in data_dict.items():\n",
    "    df_sub = pd.DataFrame(subdict)            # shape = (M, K)\n",
    "    df_sub[\"run\"] = run_name                  # add a column called “run”\n",
    "    rows.append(df_sub)\n",
    "\n",
    "big_df = pd.concat(rows, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6738cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sxs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
