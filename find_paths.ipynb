{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob, os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage\n",
    "\n",
    "Just select the correct pattern of the file/folders that you want to find and then write the output in a file for using with bash\n",
    "\n",
    "### Example\n",
    "find all the HorizonDump.h5 and output the file paths with a space in between. \n",
    "\n",
    "JoinH5 -o combined.h5 <paste_the_file_content>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"/panfs/ds09/sxs/himanshu/gauge_stuff/debug_gauge/runs_with_different_scale/1804_sph_kerr_deriv_wrt_inertial_25_50_50_amp_0.1\"\n",
    "\n",
    "# # With ringdowns\n",
    "# lev_golb=folder_path+\"/Ev/Lev**\"\n",
    "\n",
    "# Without ringdowns\n",
    "lev_golb=folder_path+\"/Ev/Lev1_??\"\n",
    "\n",
    "\n",
    "\n",
    "checkpoints_glob=lev_golb+\"/Run/Checkpoints/?**\"\n",
    "checkpoints_A0_glob=lev_golb+\"/Run/Checkpoints/?**/Cp-VarsGr_SphereA0**.h5\"\n",
    "\n",
    "horizon_dump_glob=lev_golb+\"/Run/ApparentHorizons/HorizonsDump.h5\"\n",
    "\n",
    "pvd_files = lev_golb+\"/Run/GaugeVis.pvd\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_pattern = horizon_dump_glob\n",
    "path_collection = []\n",
    "\n",
    "\n",
    "for folder_name in glob.iglob(path_pattern, recursive=True):\n",
    "    if os.path.isdir(folder_name) or os.path.isfile(folder_name):\n",
    "        path_collection.append(folder_name)\n",
    "        print(folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./find_paths.ouput\",'w') as f:\n",
    "  for path in path_collection:\n",
    "    f.write(path+\" \")\n",
    "\n",
    "if \"Dump.h5\" in path_pattern:\n",
    "  with open(\"./find_paths.ouput\",'w') as f:\n",
    "    f.write(\"JoinH5 -o combined_horizondump.h5 \")\n",
    "    for path in path_collection:\n",
    "      f.write(path+\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_pattern = checkpoints_A0_glob\n",
    "path_collection = []\n",
    "\n",
    "def find_time(file_path):\n",
    "    \"\"\"\" Reads time from Cp-EvolutionLoopControl.txt\"\"\"\n",
    "    with open(file_path,'r') as f:\n",
    "        a = f.readline()\n",
    "        return float(a.split(\";\")[0].split(\"=\")[1])\n",
    "     \n",
    "\n",
    "\n",
    "for folder_name in glob.iglob(path_pattern, recursive=True):\n",
    "    if os.path.isdir(folder_name) or os.path.isfile(folder_name):\n",
    "        time = find_time(folder_name[:-21]+\"Cp-EvolutionLoopControl.txt\")\n",
    "        time_and_path = [time,folder_name]\n",
    "        path_collection.append(time_and_path)\n",
    "        # print(time_and_path)\n",
    "\n",
    "\n",
    "time_sorted_path_list = list(pd.DataFrame(path_collection,columns=[\"Time\",\"Path\"]).sort_values(by=['Time'])['Path'])\n",
    "time_sorted_path_list\n",
    "\n",
    "\n",
    "with open(\"./find_paths.output\",'w') as f:\n",
    "  for path in time_sorted_path_list:\n",
    "    f.write(path+\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine pvd files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pvd_file(file_path):\n",
    "  with open(file_path) as f:\n",
    "    data = f.readlines()\n",
    "    write_full_vtk_file_path(data,file_path)\n",
    "    return data\n",
    "\n",
    "\n",
    "def write_full_vtk_file_path(read_data,file_path):\n",
    "  vtk_folder_name= file_path.split(\"/\")[-1][:-4]\n",
    "  vtk_folder_path= file_path[:-4]\n",
    "  for i,path in enumerate(read_data):\n",
    "    read_data[i] = path.replace(vtk_folder_name,vtk_folder_path)\n",
    "\n",
    "\n",
    "def add_lists_skip_random(a,b):\n",
    "  for i in b:\n",
    "    if \"timestep\" in i:\n",
    "      a.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = read_pvd_file(path_collection[0])[:4]\n",
    "for i in range(0,len(path_collection)):\n",
    "  add_lists_skip_random(combined_data, read_pvd_file(path_collection[i])[3:-2]) #remove the last two lines and first three lines\n",
    "\n",
    "combined_data = combined_data + read_pvd_file(path_collection[0])[-2:]\n",
    "\n",
    "\n",
    "with open(folder_path+\"/combined.pvd\",'w') as f:\n",
    "  f.writelines(combined_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('anaconda3-2019.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "6c142e1eedd05a31b3ce6f33eecaa5c4d6c5aa38e50fab0202578cc06765ac44"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
